<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:cc="http://web.resource.org/cc/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
	<channel>
		<atom:link href="https://adventofcomputing.com/flop-cast/flop-cast.rss" rel="self" type="application/rss+xml"/>
		<title>Advent of Computing: Lo-Fi Edition</title>
		<pubDate>Sun, 12 Jul 2020 23:30:00 +0000</pubDate>
		<lastBuildDate>Thu, 23 Jul 2020 15:59:01 +0000</lastBuildDate>
		<generator>ViM</generator>
		<link>http://adventofcomputing.com/</link>
		<language>en</language>
		<copyright><![CDATA[Sean Haas 2019]]></copyright>
		<docs>http://adventofcomputing.com/</docs>
		<managingEditor>adventofcomputing@gmail.com (adventofcomputing@gmail.com)</managingEditor>
		<itunes:summary><![CDATA[Do you want to learn about the history of computers? Are MP3 files just to darn big? Can you only listen to audio streamed off a floppy disk? Well, then I have just the podcast for you. Allow me to introduce Advent of Computing: extreme lo-fi edition. Each episode covers an important story from computing's past in just 1.44 MB. I'd highly recomending listening to the normal podcast, complete with better audio quality. You can find that at https://adventofcomputing.com/]]></itunes:summary>
		<image>
			<url>http://adventofcomputing.com/logo_lofi.png</url>
			<title>Advent of Computing</title>
			<link><![CDATA[http://adventofcomputing.com/]]></link>
		</image>
		<itunes:author>Sean Haas</itunes:author>
		<itunes:keywords>computer,computing,history</itunes:keywords>
		<itunes:category text="History"/>
		<itunes:category text="Technology"/>
		<itunes:image href="http://adventofcomputing.com/img/logo-lofi.png" />
		<itunes:explicit>clean</itunes:explicit>
		<itunes:owner>
			<itunes:name><![CDATA[Sean S Haas]]></itunes:name>
			<itunes:email>adventofcomputing@gmail.com</itunes:email>
		</itunes:owner>
		<description><![CDATA[Do you want to learn about the history of computers? Are MP3 files just to darn big? Can you only listen to audio streamed off a floppy disk? Well, then I have just the podcast for you. Allow me to introduce Advent of Computing: extreme lo-fi edition. Each episode covers an important story from computing's past in just 1.44 MB. I'd highly recomending listening to the normal podcast, complete with better audio quality. You can find that at https://adventofcomputing.com/]]></description>
		<itunes:subtitle><![CDATA[]]></itunes:subtitle>
		<itunes:type>episodic</itunes:type>

		<item>
			<title>Episode 35 - Analog Computing and the Automatic Totalisator</title>
			<itunes:title>Analog Computing and the Automatic Totalisator</itunes:title>
			<pubDate>Sun, 26 Jul 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[ce87135f-ed8d-4825-8018-f79b847f3ba9]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-35-analog-computing-and-the-automatic-totalisator]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>A lot of the technology we associate with the modern day started on anachronistic machines. I'm not talking about mainframes, I'm talking older. Today we are looking at George Julius's Automatic Totalisator, an analog computer used to manage betting at horse tracks around the world. These were massively complex machines, some networked over 200 input terminals, and they did it all mechanically.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important Dates:</p> <p>1913: Premier Tote installed in Auckland</p>]]></description>
			<content:encoded><![CDATA[<p>A lot of the technology we associate with the modern day started on anachronistic machines. I'm not talking about mainframes, I'm talking older. Today we are looking at George Julius's Automatic Totalisator, an analog computer used to manage betting at horse tracks around the world. These were massively complex machines, some networked over 200 input terminals, and they did it all mechanically.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important Dates:</p> <p>1913: Premier Tote installed in Auckland</p>]]></content:encoded>
			<enclosure length="93403221" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep35_The_Automated_Totalisator.amr" />
			<itunes:duration>48:32</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,computer,engineering,gambling,analog</itunes:keywords>
			<itunes:subtitle><![CDATA[A lot of the technology we associate with the modern day started on anachronistic machines. I'm not talking about mainframes, I'm talking older. Today we are looking at George Julius's Automatic Totalisator, an analog computer used to manage betting...]]></itunes:subtitle>
			<itunes:episode>35</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 34 - 8080 VS Z80</title>
			<itunes:title>8080 VS Z80</itunes:title>
			<pubDate>Sun, 12 Jul 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[2013de69-8b68-47bc-bdf5-25bd6c2e1339]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-34-8080-vs-z80]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/3/5/7/6/3576a8e70ef8da31/8080.png" />
			<description><![CDATA[<p>In 1974 Intel released the 8080 processor, a chip long in the making. It was the first microprocessor that had the right combination of power and price to make personal computers viable. But that same year a small group of employees defected and formed their own company called Zilog. Among this group were Masatoshi Shima and Federico Faggin, two of the principal architects behind the 8080 as well as Intel's other processors. Zilog would go on to release a better chip, the Z80, that blew Intel out of the water. Today we continue our Intel series with a look into this twisting story.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important Dates:</p> <p>1974: Intel 8080 hits shelves</p> <p>1976: Zilog Z80 goes on sale</p>]]></description>
			<content:encoded><![CDATA[<p>In 1974 Intel released the 8080 processor, a chip long in the making. It was the first microprocessor that had the right combination of power and price to make personal computers viable. But that same year a small group of employees defected and formed their own company called Zilog. Among this group were Masatoshi Shima and Federico Faggin, two of the principal architects behind the 8080 as well as Intel's other processors. Zilog would go on to release a better chip, the Z80, that blew Intel out of the water. Today we continue our Intel series with a look into this twisting story.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important Dates:</p> <p>1974: Intel 8080 hits shelves</p> <p>1976: Zilog Z80 goes on sale</p>]]></content:encoded>
			<enclosure length="88763686" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep34_8080_vs_Z80.amr" />
			<itunes:duration>46:06</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>processor,history,computer,intel,zilog</itunes:keywords>
			<itunes:subtitle><![CDATA[In 1974 Intel released the 8080 processor, a chip long in the making. It was the first microprocessor that had the right combination of power and price to make personal computers viable. But that same year a small group of employees defected and...]]></itunes:subtitle>
			<itunes:episode>34</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 33.5 - Brad Chase Interview, Marketing Lead for Windows 95 and Much More</title>
			<itunes:title>Brad Chase Interview, Marketing Lead for Windows 95 and Much More</itunes:title>
			<pubDate>Sun, 05 Jul 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[3e0cb7ba-4f32-46f4-9f7c-e853b4034b0b]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-335-brad-chase-interview-marketing-lead-for-windows-95-and-much-more]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>I recently got the chance to sit down and talk with Microsoft alumni Brad Chase. He was the product manager for Microsoft Works on the Macintosh, DOS 5, DOS 6, and the marketing lead for Windows 95 as well as much more. We talk about the Apple-Microsoft relationship, the groundbreaking launch of Windows 95, and what it takes to sell software.</p> <p>Editing for this episode was handled by Franck, you can follow him on instagram: <a href="http://www.instagram.com/frc.audio/" target="_blank" rel="noopener" data-saferedirecturl= "https://www.google.com/url?q=http://www.instagram.com/frc.audio/&source=gmail&ust=1593905228049000&usg=AFQjCNE2f2_yJGHtuOKCAv1PVJ1Bg3h4tw"> www.instagram.com/frc.audio/</a></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p>]]></description>
			<content:encoded><![CDATA[<p>I recently got the chance to sit down and talk with Microsoft alumni Brad Chase. He was the product manager for Microsoft Works on the Macintosh, DOS 5, DOS 6, and the marketing lead for Windows 95 as well as much more. We talk about the Apple-Microsoft relationship, the groundbreaking launch of Windows 95, and what it takes to sell software.</p> <p>Editing for this episode was handled by Franck, you can follow him on instagram: <a href="http://www.instagram.com/frc.audio/" target="_blank" rel="noopener" data-saferedirecturl= "https://www.google.com/url?q=http://www.instagram.com/frc.audio/&source=gmail&ust=1593905228049000&usg=AFQjCNE2f2_yJGHtuOKCAv1PVJ1Bg3h4tw"> www.instagram.com/frc.audio/</a></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p>]]></content:encoded>
			<enclosure length="25604829" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep33.5_Brad_chase_Interview.amr" />
			<itunes:duration>26:26</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>interview,windows,history,computers,microsoft</itunes:keywords>
			<itunes:subtitle><![CDATA[I recently got the chance to sit down and talk with Microsoft alumni Brad Chase. He was the product manager for Microsoft Works on the Macintosh, DOS 5, DOS 6, and the marketing lead for Windows 95 as well as much more. We talk about the...]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 33 Notes - Kay's Portable Sketches</title>
			<pubDate>Wed, 01 Jul 2020 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[25bb52a5-e4e4-4b8b-bb51-2c6a2af5a4a7]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-33-notes-kays-portable-sketches]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">In 1972 Alan Kay published a paper called "A Personal Computer for Children of All Ages". In it's pages Kay offers the first description of a portable computer, what he calls the DynaBook. What makes this document so remarkable is that the computer it describes is shockingly modern. Despite being nearly 50 years old the DynaBook is depicted as essentially a tablet computer. What's more, Kay envisioned DynaBook as a user friendly computer that could be used by anyone, from children up to computer experts.</span></p> <p><img src= "https://www.mprove.de/visionreality/media/_media/Kay72p4.gif" alt= "" /></p> <p><span style="font-weight: 400;">The most widely circulated sketch of the DynaBook shows it as a flat slate 12" x 9" slate with a screen and keyboard on its surface. I/O ports, some type of removable storage, and a holder for a stylus would be built into the sides of the computer's case. But Kay is quick to point out that the computer need not be bound to that specific design, rather the sketch was given as one possible form factor for the DynaBook. In Kay's view a personal computer had to be portable and easy to use, the keyboard-and-screen design was just one way to accomplish that goal.</span></p> <p><em><span style="font-weight: 400;">"Once one has gotten used to the idea of no moving parts, he is ready for the idea of no keyboard at all! Suppose the display panel covers the full extent of the notebook surface. Any keyboard arrangement one might wish can then be displayed anywhere on the surface.</span></em></p> <p><em><span style="font-weight: 400;">…</span></em></p> <p><em><span style="font-weight: 400;">The bottom portion of the display panel can be textured in various ways to permit touch typing. This arrangement allows the font in which one is typing to be shown on the keys, special characters can be windowed, and user identifiers can be selected with one touch."</span></em></p> <p><em><span style="font-weight: 400;">~Alan Kay, A Personal Computer for Children of All Ages</span></em></p> <p><span style="font-weight: 400;">So scratching just below the surface Kay does indeed describe a tablet computer almost perfectly. The idea of a textured screen definitely didn't take off, but Kay correctly foresaw that a keyboard could be removed from the equation altogether. On screen keyboards on smart phones and tablets today look a lot like what Kay describes, a keyboard is simply displayed on a portion of the screen as needed. He even identifies the flexibility of this type of system. Since the keyboard is just another image displayed on screen you aren't beholden to any one layout or look.</span></p> <p><span style="font-weight: 400;">The futuristic hardware design is just part of what makes Kay's writing shocking. He brings things to another level by claiming that the DynaBook could be produced using 1972 technology, and that a mass produced DynaBook could be sold for under $500 dollars. Today that has become possible, cheap consumer tablets are readily available. But that was definitely not the case in 1972. Microprocessors were still in their infancy, flat panel displays weren't very much further along in their development. Kay wouldn't build a tablet in the 70s, but the idea of the DynaBook would serve as a goalpost for his future work.</span></p> <p><span style="font-weight: 400;">A few years later, in 1976, Kay took another stab at designing a practical DynaBook. This redesign would eventually lead to the development of the Xerox NoteTaker. Kay's first drawings of what the NoteTaker could be show a more practical attempt at designing a portable computer. This later design drops the slate form factor in favor of something more akin to an actual laptop. The large touchscreen was replaced with a more modest size display, but they keyboard remained relatively unchanged. Kay also sketched the NoteTaker with a folding lid that would cover and protect the device.</span></p> <p><img src= "http://worrydream.com/EarlyHistoryOfSmalltalk/Images/notetaker.png" alt="" width="928" height="327" /></p> <p><span style="font-weight: 400;">While the NoteTaker did materialize the finished prototypes were vastly different from Kay's initial design. These prototypes were some of the first luggable computers, weighing in the neighborhood of 50 pounds. A far cry from the DynaBook concept, and not exactly what Kay had in mind. Ultimately we wouldn't get cheap and portable computers for years to come, but Kay's work did plant the seed of the idea.</span></p> <p><span style="font-weight: 400;">You can read Alan Kay's "A Portable Computer for Children of All Ages" here: <a href= "https://www.mprove.de/visionreality/media/kay72.html">https://www.mprove.de/visionreality/media/kay72.html</a>.</span></p> <p><span style="font-weight: 400;">To learn more about the history of portable computing listen to my episode on the topic:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.com/?guid=bf4cdb64-b9cf-44b7-88a7-56d465901905"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-33-becoming-portable/id1459202600?i=1000480074960&ign-mpt=uo%3D4"> Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/14989271/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>In 1972 Alan Kay published a paper called "A Personal Computer for Children of All Ages". In it's pages Kay offers the first description of a portable computer, what he calls the DynaBook. What makes this document so remarkable is that the computer it describes is shockingly modern. Despite being nearly 50 years old the DynaBook is depicted as essentially a tablet computer. What's more, Kay envisioned DynaBook as a user friendly computer that could be used by anyone, from children up to computer experts.</p> <p></p> <p>The most widely circulated sketch of the DynaBook shows it as a flat slate 12" x 9" slate with a screen and keyboard on its surface. I/O ports, some type of removable storage, and a holder for a stylus would be built into the sides of the computer's case. But Kay is quick to point out that the computer need not be bound to that specific design, rather the sketch was given as one possible form factor for the DynaBook. In Kay's view a personal computer had to be portable and easy to use, the keyboard-and-screen design was just one way to accomplish that goal.</p> <p><em>"Once one has gotten used to the idea of no moving parts, he is ready for the idea of no keyboard at all! Suppose the display panel covers the full extent of the notebook surface. Any keyboard arrangement one might wish can then be displayed anywhere on the surface.</em></p> <p><em>…</em></p> <p><em>The bottom portion of the display panel can be textured in various ways to permit touch typing. This arrangement allows the font in which one is typing to be shown on the keys, special characters can be windowed, and user identifiers can be selected with one touch."</em></p> <p><em>~Alan Kay, A Personal Computer for Children of All Ages</em></p> <p>So scratching just below the surface Kay does indeed describe a tablet computer almost perfectly. The idea of a textured screen definitely didn't take off, but Kay correctly foresaw that a keyboard could be removed from the equation altogether. On screen keyboards on smart phones and tablets today look a lot like what Kay describes, a keyboard is simply displayed on a portion of the screen as needed. He even identifies the flexibility of this type of system. Since the keyboard is just another image displayed on screen you aren't beholden to any one layout or look.</p> <p>The futuristic hardware design is just part of what makes Kay's writing shocking. He brings things to another level by claiming that the DynaBook could be produced using 1972 technology, and that a mass produced DynaBook could be sold for under $500 dollars. Today that has become possible, cheap consumer tablets are readily available. But that was definitely not the case in 1972. Microprocessors were still in their infancy, flat panel displays weren't very much further along in their development. Kay wouldn't build a tablet in the 70s, but the idea of the DynaBook would serve as a goalpost for his future work.</p> <p>A few years later, in 1976, Kay took another stab at designing a practical DynaBook. This redesign would eventually lead to the development of the Xerox NoteTaker. Kay's first drawings of what the NoteTaker could be show a more practical attempt at designing a portable computer. This later design drops the slate form factor in favor of something more akin to an actual laptop. The large touchscreen was replaced with a more modest size display, but they keyboard remained relatively unchanged. Kay also sketched the NoteTaker with a folding lid that would cover and protect the device.</p> <p></p> <p>While the NoteTaker did materialize the finished prototypes were vastly different from Kay's initial design. These prototypes were some of the first luggable computers, weighing in the neighborhood of 50 pounds. A far cry from the DynaBook concept, and not exactly what Kay had in mind. Ultimately we wouldn't get cheap and portable computers for years to come, but Kay's work did plant the seed of the idea.</p> <p>You can read Alan Kay's "A Portable Computer for Children of All Ages" here: <a href= "https://www.mprove.de/visionreality/media/kay72.html">https://www.mprove.de/visionreality/media/kay72.html</a>.</p> <p>To learn more about the history of portable computing listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.com/?guid=bf4cdb64-b9cf-44b7-88a7-56d465901905"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-33-becoming-portable/id1459202600?i=1000480074960&ign-mpt=uo%3D4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[In 1972 Alan Kay published a paper called "A Personal Computer for Children of All Ages". In it's pages Kay offers the first description of a portable computer, what he calls the DynaBook. What makes this document so remarkable is that the computer it...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 33 - Becoming Portable</title>
			<itunes:title>Becoming Portable</itunes:title>
			<pubDate>Sun, 28 Jun 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[bf4cdb64-b9cf-44b7-88a7-56d465901905]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-33-becoming-portable]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/5/f/0/2/5f0298648467ae51/bitmap.png" />
			<description><![CDATA[<p>Portable computing is now totally ubiquitous. There's a good chance you are listening to this episode on a tiny portable computer right now. But where did it all come from? As it turns out the first portable computer was designed all the way back in 1972. This machine, the DynaBook, only ever existed on paper. Despite that handicap, in the coming years it would inspire a huge shift in both personal and portable computing.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1972: DynaBook designed by Alan Kay</p> <p>1976: NoteTaker project starts</p> <p>1982: GRiD Compass released</p>]]></description>
			<content:encoded><![CDATA[<p>Portable computing is now totally ubiquitous. There's a good chance you are listening to this episode on a tiny portable computer right now. But where did it all come from? As it turns out the first portable computer was designed all the way back in 1972. This machine, the DynaBook, only ever existed on paper. Despite that handicap, in the coming years it would inspire a huge shift in both personal and portable computing.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1972: DynaBook designed by Alan Kay</p> <p>1976: NoteTaker project starts</p> <p>1982: GRiD Compass released</p>]]></content:encoded>
			<enclosure length="98379231" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep33_becoming_portable.amr" />
			<itunes:duration>51:15</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>mobile,history,portable,computer,tablet,laptop,dynabook</itunes:keywords>
			<itunes:subtitle><![CDATA[Portable computing is now totally ubiquitous. There's a good chance you are listening to this episode on a tiny portable computer right now. But where did it all come from? As it turns out the first portable computer was designed all the way back in...]]></itunes:subtitle>
			<itunes:episode>33</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 32 - Road to Transistors, Part II</title>
			<itunes:title>Road to Transistors, Part II</itunes:title>
			<pubDate>Sun, 14 Jun 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[092639b9-69a9-42b2-b2ee-80237d1faa26]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-32-road-to-transistors-part-ii]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/1/9/9/2/199247a1e8ac4e82/transistor.png" />
			<description><![CDATA[<p>In this episode we finish up our look at the birth of the transistor. But to do that we have to go back to 1880, the crystal radio detector, and examine the development of semiconductor devices. Once created the transistor would change not just how computers worked, but change how they could be used. That change didn't happen over night, and it would take even longer for the transistor to move from theory to reality.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1939: Russel Ohl Discovers P-N Junction<br /> 1947: Point Contact Transistor Invented at Bell Labs<br /> 1954: TRADIC, First Transistorized Computer, Built</p>]]></description>
			<content:encoded><![CDATA[<p>In this episode we finish up our look at the birth of the transistor. But to do that we have to go back to 1880, the crystal radio detector, and examine the development of semiconductor devices. Once created the transistor would change not just how computers worked, but change how they could be used. That change didn't happen over night, and it would take even longer for the transistor to move from theory to reality.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1939: Russel Ohl Discovers P-N Junction 1947: Point Contact Transistor Invented at Bell Labs 1954: TRADIC, First Transistorized Computer, Built</p>]]></content:encoded>
			<enclosure length="89466024" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep32_transistors_part_ii.amr" />
			<itunes:duration>46:29</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,computer,transistor,semiconductor,belllabs</itunes:keywords>
			<itunes:subtitle><![CDATA[In this episode we finish up our look at the birth of the transistor. But to do that we have to go back to 1880, the crystal radio detector, and examine the development of semiconductor devices. Once created the transistor would change not just how...]]></itunes:subtitle>
			<itunes:episode>32</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 31 Notes - Project Lightning: NSA's Cryotron Computer</title>
			<pubDate>Wed, 03 Jun 2020 22:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[ff3be03b-7340-41a3-9ae1-5de3793c7187]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-31-notes-project-lightning-nsas-cryotron-computer]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The development of computer technology, especially early on, is deeply tied to governmental and military research. Early computers like Colossus and the Harvard Mark Iwere a big part of the Allied war effort. The internet itself is an outgrowth of a collection of US government projects. But not all of these undertakings see the light of day. A great example of this is the not-so-subtly named Project Lightning, the NSA's attempt to create a totally new type of computer in the 1950s. And while Lightning would never lead to any public facing advances, we can see an interesting story emerge from declassified documents.</span></p> <p><span style="font-weight: 400;">One internal report from the late 1950s summarizes Project Lightning:</span></p> <p><em><span style="font-weight: 400;">"Eventually we foresee that natural limitations on speed and size will be encountered, and then the inevitable advances of our opponents will corner us, so that the duel will become one of pure wits. But while we can we must maintain our superior weapons. Project LIGHTNING was set up to preserve our advantage in speed of computation."</span></em></p> <p><em><span style="font-weight: 400;">~Lightning, HOWARD H. CAMPAIGNE</span></em></p> <p><span style="font-weight: 400;">This was in the middle of the Cold War, and the fear at the time was that the USSR would overtake the US's dominance in the field of computing. But there was an issue facing any push to advance computing, the limitations that this document cite. In this era the vacuum tube was the core component used to build computers, and while that worked it wasn't an ideal solution. These tubes ran hot, were pretty large, and didn't operate all that fast. While it would have been possible to just beef up existing computer systems you'd quickly run into diminishing returns. In order to maintain technological superiority a radical change would be needed.</span></p> <p><span style="font-weight: 400;">The plan laid out for Project Lightning is ambitious, to say the least. In that same document the end goal was described as:</span></p> <p><em><span style="font-weight: 400;">"A jet plane can go one hundred times as fast as a man can run. A computer can go ten thousand times as fast as a man can compute. LIGHTNING will go ten million times as fast."</span></em></p> <p><span style="font-weight: 400;">The NSA was trying to build a supercomputer. While not exactly common, supercomputers do exist in the modern day. But in the 1950s this was unprecedented. Keep in mind that this is before the first integrated circuits, and decades before the first microprocessor. The first transistorized computer, TRADIC, was a new and untested technology. This was a strange period where the future of computing wasn't entirely clear. Project Lightning was, broadly speaking, an attempt to find the computing element of the future.</span></p> <p><span style="font-weight: 400;">Lightning would investigate a number of contenders, but one of their early and promising leads was a device known as a cryotron. These were superconductive switches invented by Dudley Allen Buck in 1953. The first prototype cryotrons were simply a core wire wrapped in a coil of a dissimilar metal. Both metals are superconductive at low temperatures, but when a magnetic field is generated by the coil the core wire becomes resistive. The catch is that for this to work the cryotron has to be kept near absolute zero in a bath of liquid helium.</span></p> <p><span style="font-weight: 400;">But Lightning wasn't going to be using these early cryotrons. The NSA wanted to leverage an even more futuristic technology. In the latter half of the 50s Dudley Buck was able to develop a technique for creating superconductive integrated circuits, which he called "thin film cryotrons". </span></p> <p><em><span style="font-weight: 400;">"Using thin films of silicon monoxide as insulation we plate layer over layer until we have a complex assembly on a microscope slide, equivalent to a vacuum tube chassis in information-handling ability but so thin that a finger tip cannot feel its presence. This method  or assembly may not only get us our 1000 megacycles, but get it for us cheap, for in mass production such techniques of assembly are much cheaper than the classical wiring and soldering"</span></em></p> <p><span style="font-weight: 400;">Years before semiconductor chips existed, Buck was able to etch microscopic cryotrons on to silicon chips. A thin-film cryotron chip could switch much faster than a vacuum tube, used a scant fraction of the power, and in theory could be mass produced. The wild thing is, this was within reach. At least one prototype computer was built using thin-film cryotrons. If Project Lightning had survived we may very well have seen a massively parallel supercomputer built from superconductive circuits by the end of the 1950s.</span></p> <p><span style="font-weight: 400;">However, Project Lightning would never reach its end goal. At least not in this iteration. The project would go on for a number of years, burning funding and resources. With the limited sources available it's hard to point to an exact failure point. It's likely that the dreams of a cryotron computer at the NSA fell by the wayside with the success of the transistor, or that Project Lightning transformed into another endeavour that has yet to see the light of day.</span></p> <p><span style="font-weight: 400;">If you want t read more about Project Lightning, there are a number of FOIA released documents floating around. This is the one that talks the most about the cryotron side of the project.</span></p> <p><a href= "https://www.nsa.gov/Portals/70/documents/news-features/declassified-documents/tech-journals/lightning.pdf"> <span style= "font-weight: 400;">https://www.nsa.gov/Portals/70/documents/news-features/declassified-documents/tech-journals/lightning.pdf</span></a></p> <p><span style="font-weight: 400;">To learn more about the cryotron in general I'd recommend checking out "The Cryotron Files" by Douglas Buck and Iain Dey. It's been an invaluable source for me personally, and it's a good read in general.</span></p> <p><span style="font-weight: 400;">To learn more about the early development of the vacuum tube, cryotron, and early computers listen to my episode on the topic:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.com/?guid=0488f6d9-a0fe-4e21-847c-c63310a218f3"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-31-road-to-transistors-part-i/id1459202600?i=1000476372520&ign-mpt=uo%3D4"> Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/14630501/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The development of computer technology, especially early on, is deeply tied to governmental and military research. Early computers like Colossus and the Harvard Mark Iwere a big part of the Allied war effort. The internet itself is an outgrowth of a collection of US government projects. But not all of these undertakings see the light of day. A great example of this is the not-so-subtly named Project Lightning, the NSA's attempt to create a totally new type of computer in the 1950s. And while Lightning would never lead to any public facing advances, we can see an interesting story emerge from declassified documents.</p> <p>One internal report from the late 1950s summarizes Project Lightning:</p> <p><em>"Eventually we foresee that natural limitations on speed and size will be encountered, and then the inevitable advances of our opponents will corner us, so that the duel will become one of pure wits. But while we can we must maintain our superior weapons. Project LIGHTNING was set up to preserve our advantage in speed of computation."</em></p> <p><em>~Lightning, HOWARD H. CAMPAIGNE</em></p> <p>This was in the middle of the Cold War, and the fear at the time was that the USSR would overtake the US's dominance in the field of computing. But there was an issue facing any push to advance computing, the limitations that this document cite. In this era the vacuum tube was the core component used to build computers, and while that worked it wasn't an ideal solution. These tubes ran hot, were pretty large, and didn't operate all that fast. While it would have been possible to just beef up existing computer systems you'd quickly run into diminishing returns. In order to maintain technological superiority a radical change would be needed.</p> <p>The plan laid out for Project Lightning is ambitious, to say the least. In that same document the end goal was described as:</p> <p><em>"A jet plane can go one hundred times as fast as a man can run. A computer can go ten thousand times as fast as a man can compute. LIGHTNING will go ten million times as fast."</em></p> <p>The NSA was trying to build a supercomputer. While not exactly common, supercomputers do exist in the modern day. But in the 1950s this was unprecedented. Keep in mind that this is before the first integrated circuits, and decades before the first microprocessor. The first transistorized computer, TRADIC, was a new and untested technology. This was a strange period where the future of computing wasn't entirely clear. Project Lightning was, broadly speaking, an attempt to find the computing element of the future.</p> <p>Lightning would investigate a number of contenders, but one of their early and promising leads was a device known as a cryotron. These were superconductive switches invented by Dudley Allen Buck in 1953. The first prototype cryotrons were simply a core wire wrapped in a coil of a dissimilar metal. Both metals are superconductive at low temperatures, but when a magnetic field is generated by the coil the core wire becomes resistive. The catch is that for this to work the cryotron has to be kept near absolute zero in a bath of liquid helium.</p> <p>But Lightning wasn't going to be using these early cryotrons. The NSA wanted to leverage an even more futuristic technology. In the latter half of the 50s Dudley Buck was able to develop a technique for creating superconductive integrated circuits, which he called "thin film cryotrons". </p> <p><em>"Using thin films of silicon monoxide as insulation we plate layer over layer until we have a complex assembly on a microscope slide, equivalent to a vacuum tube chassis in information-handling ability but so thin that a finger tip cannot feel its presence. This method  or assembly may not only get us our 1000 megacycles, but get it for us cheap, for in mass production such techniques of assembly are much cheaper than the classical wiring and soldering"</em></p> <p>Years before semiconductor chips existed, Buck was able to etch microscopic cryotrons on to silicon chips. A thin-film cryotron chip could switch much faster than a vacuum tube, used a scant fraction of the power, and in theory could be mass produced. The wild thing is, this was within reach. At least one prototype computer was built using thin-film cryotrons. If Project Lightning had survived we may very well have seen a massively parallel supercomputer built from superconductive circuits by the end of the 1950s.</p> <p>However, Project Lightning would never reach its end goal. At least not in this iteration. The project would go on for a number of years, burning funding and resources. With the limited sources available it's hard to point to an exact failure point. It's likely that the dreams of a cryotron computer at the NSA fell by the wayside with the success of the transistor, or that Project Lightning transformed into another endeavour that has yet to see the light of day.</p> <p>If you want t read more about Project Lightning, there are a number of FOIA released documents floating around. This is the one that talks the most about the cryotron side of the project.</p> <p><a href= "https://www.nsa.gov/Portals/70/documents/news-features/declassified-documents/tech-journals/lightning.pdf"> https://www.nsa.gov/Portals/70/documents/news-features/declassified-documents/tech-journals/lightning.pdf</a></p> <p>To learn more about the cryotron in general I'd recommend checking out "The Cryotron Files" by Douglas Buck and Iain Dey. It's been an invaluable source for me personally, and it's a good read in general.</p> <p>To learn more about the early development of the vacuum tube, cryotron, and early computers listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.com/?guid=0488f6d9-a0fe-4e21-847c-c63310a218f3"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-31-road-to-transistors-part-i/id1459202600?i=1000476372520&ign-mpt=uo%3D4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The development of computer technology, especially early on, is deeply tied to governmental and military research. Early computers like Colossus and the Harvard Mark Iwere a big part of the Allied war effort. The internet itself is an outgrowth of a...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 31 - Road to Transistors: Part I</title>
			<itunes:title>Road to Transistors: Part I</itunes:title>
			<pubDate>Sun, 31 May 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[0488f6d9-a0fe-4e21-847c-c63310a218f3]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-31-road-to-transistors-part-i]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/0/d/f/a/0dfa8b2b3bada6b4/tubes_cryotron.png" />
			<description><![CDATA[<p>The transistor changed the world. It made small, complex, and cheap computing possible. But it wasn't the first attempt to crack the case. There is a long and strange lineage of similar devices leading up to the transistor. In this episode we take a look at two of those devices. First the vacuum tube, one of the first components that made computing possible. Then the cryotron, the first device purpose built for computers.</p> <p>You can find the full audio of Atanasoff's talk here: https://www.youtube.com/watch?v=Yxrcp1QSPvw</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: https://www.patreon.com/adventofcomputing</p> <p>Important dates in this episode:</p> <p>1880: Thomas Edison Rediscovers Thermionic Emission<br /> 1904: Ambrose Fleming Invents the Vacuum Tube<br /> 1906: Lee de Forest Patents the Audion Triode Tube<br /> 1937: George Stibitz Creates First Binary Adding Circuit from Spare Relays<br /> 1938: John Atanasoff Visits a 'Honkey-Tonk'<br /> 1941: ABC, First Vacuum Tube Calculator, is Completed<br /> 1953: Cryotron Invented by Dudley Allen Buck</p>]]></description>
			<content:encoded><![CDATA[<p>The transistor changed the world. It made small, complex, and cheap computing possible. But it wasn't the first attempt to crack the case. There is a long and strange lineage of similar devices leading up to the transistor. In this episode we take a look at two of those devices. First the vacuum tube, one of the first components that made computing possible. Then the cryotron, the first device purpose built for computers.</p> <p>You can find the full audio of Atanasoff's talk here: https://www.youtube.com/watch?v=Yxrcp1QSPvw</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: https://www.patreon.com/adventofcomputing</p> <p>Important dates in this episode:</p> <p>1880: Thomas Edison Rediscovers Thermionic Emission 1904: Ambrose Fleming Invents the Vacuum Tube 1906: Lee de Forest Patents the Audion Triode Tube 1937: George Stibitz Creates First Binary Adding Circuit from Spare Relays 1938: John Atanasoff Visits a 'Honkey-Tonk' 1941: ABC, First Vacuum Tube Calculator, is Completed 1953: Cryotron Invented by Dudley Allen Buck</p>]]></content:encoded>
			<enclosure length="97455523" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep31_transistors_part_i.amr" />
			<itunes:duration>50:35</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,physics,computer,eniac,vacuumtube,cryotron</itunes:keywords>
			<itunes:subtitle><![CDATA[The transistor changed the world. It made small, complex, and cheap computing possible. But it wasn't the first attempt to crack the case. There is a long and strange lineage of similar devices leading up to the transistor. In this episode we take a...]]></itunes:subtitle>
			<itunes:episode>31</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 30 - Coherent Is Not UNIX!</title>
			<itunes:title>Coherent Is Not UNIX!</itunes:title>
			<pubDate>Sun, 17 May 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[f3d26093-e7d8-4f90-8b1c-a81a88b85ca4]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-30-coherent-is-not-unix]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In the current day Linux is the most widely used UNIX-like operating system. It's rise to prominence has been an amazing success story. From it's humble beginnings Linux has grown to power everything from super computers to car stereos. But it's not the first UNIX clone. A much earlier system existed, called Coherent. And as it turns out both Linux and Coherent share a lot of similarities. The biggest difference being that Coherent was closed source.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1973: AT&T UNIX V4 Goes Public<br /> 1949: DOJ Sues AT&T Over Antitrust Violations<br /> 1975: AT&T UNIX V6 Released<br /> 1977: First Version of BSD Circulates<br /> 1977: XYBASIC Released by Mark Williams Company<br /> 1980: Coherent Released for PDP/11<br /> 1983: Coherent Comes to the IBM PC/XT<br /> 1995: Mark Williams Company Closes</p>]]></description>
			<content:encoded><![CDATA[<p>In the current day Linux is the most widely used UNIX-like operating system. It's rise to prominence has been an amazing success story. From it's humble beginnings Linux has grown to power everything from super computers to car stereos. But it's not the first UNIX clone. A much earlier system existed, called Coherent. And as it turns out both Linux and Coherent share a lot of similarities. The biggest difference being that Coherent was closed source.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1973: AT&T UNIX V4 Goes Public 1949: DOJ Sues AT&T Over Antitrust Violations 1975: AT&T UNIX V6 Released 1977: First Version of BSD Circulates 1977: XYBASIC Released by Mark Williams Company 1980: Coherent Released for PDP/11 1983: Coherent Comes to the IBM PC/XT 1995: Mark Williams Company Closes</p>]]></content:encoded>
			<enclosure length="89601464" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep30-Coherent.amr" />
			<itunes:duration>46:33</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>linux,history,computer,unix,coherent</itunes:keywords>
			<itunes:subtitle><![CDATA[In the current day Linux is the most widely used UNIX-like operating system. It's rise to prominence has been an amazing success story. From it's humble beginnings Linux has grown to power everything from super computers to car stereos. But it's not...]]></itunes:subtitle>
			<itunes:episode>30</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 29.5 - A Guided Tour of the Macintosh</title>
			<itunes:title>A Guided Tour of the Macintosh</itunes:title>
			<pubDate>Sun, 10 May 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[b02d2f8a-090d-4125-bb3e-903b29e9512e]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-295-a-guided-tour-of-the-macintosh]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In this byte sized episode I take a look at a pack in that came with the first Macintosh. Along side Apple stickers, manuals, and the computer itself there was a single cassette tape labeled "A Guided Tour of the Macintosh". The purpose? It's a strange addition to the Mac's packing, but a great example of Apple's attention to detail and ingenuity.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p class="p1"><span class="s1">1984: A Guided Tour of the Macintosh Released</span></p>]]></description>
			<content:encoded><![CDATA[<p>In this byte sized episode I take a look at a pack in that came with the first Macintosh. Along side Apple stickers, manuals, and the computer itself there was a single cassette tape labeled "A Guided Tour of the Macintosh". The purpose? It's a strange addition to the Mac's packing, but a great example of Apple's attention to detail and ingenuity.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p class="p1">1984: A Guided Tour of the Macintosh Released</p>]]></content:encoded>
			<enclosure length="18418000" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep29_5_Guided_Tour_of_the_Mac.amr" />
			<itunes:duration>09:28</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,apple,macintosh,computer</itunes:keywords>
			<itunes:subtitle><![CDATA[In this byte sized episode I take a look at a pack in that came with the first Macintosh. Along side Apple stickers, manuals, and the computer itself there was a single cassette tape labeled "A Guided Tour of the Macintosh". The purpose? It's a...]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 29 Notes - PCM Predictions from 1965</title>
			<pubDate>Wed, 06 May 2020 22:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[55a2d0e3-1c9e-4156-8d43-e257132b203d]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-29-notes-pcm-predictions-from-1965]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Pulse Code Modulation, or PCM, is the core technology behind digital audio. Despite being so central to modern day life PCM is actually pretty old. It was originally developed by Alec Reeves, a telecom engineer, all the way back in 1937. From there the technology has slowly gained traction and eventually found its way into computerized audio systems. Decades after its creation Reeves would write out his thoughts on the technology in an article titled "The past, present and future of PCM"(</span><a href= "https://tkhf.adaxas.net/cd1/Reeves2.pdf"><span style= "font-weight: 400;">https://tkhf.adaxas.net/cd1/Reeves2.pdf</span></a><span style="font-weight: 400;">). Despite being written in 1965, more than 50 ago, his predictions for the future are uncannily accurate.</span></p> <p><span style="font-weight: 400;">Reeves uses the year 2000 as a goalpost for most of his long-term predictions. Some of these are pretty mundane: telephone usage will greatly increase, new technology will spread in emerging markets outside the US and Europe. His safest prediction is that larger and more widespread use of telephone systems will make PCM the only suitable option for ferrying audio. But Reeves would go on to describe other causes for widespread adoption of PCM:</span></p> <p><span style="font-weight: 400;">"</span><em><span style= "font-weight: 400;">In my view, this “other reason” by that date will be the necessity for widespread closed-loop television — a necessity, I repeat, not just the urge for a status symbol that is likely to start this kind of demand in the nearer future."</span></em></p> <p><span style="font-weight: 400;">I've struggled a bit to understand exactly what he means by "closed-loop television" here. It's clear he isn't referring to CCTVs, the direct context makes me think he means broadcast television. However, later in the paper when addressing the use of PCM in information retrieval he writes:</span></p> <p><em><span style="font-weight: 400;">"The only adequate answer will be for a few information processing centers to be set up in each large industrialized area, staffed by top-grade people, with the information being made available to the public immediately and automatically when a dialed request is made. An ordinary high-speed data link may be adequate for the next 20 years, but by A.D. 2000 the only way to pass the information fast enough to the caller’s brain will be to use moving pictures."</span></em></p> <p><span style="font-weight: 400;">So it could be that he is trying to describe a teleconferencing-like system. Whatever the case, Reeves is still accurate in predicting the audio side of things. Broadcast television signals switched to digital in most parts of the world during the 2000's, and the audio component of those signals is now encoded as PCM. However, I think the teleconferencing angle has a little more meat to it. In a later passage Reeves writes:</span></p> <p><em><span style="font-weight: 400;">"Commuters will refuse to accept the delays and inconveniences that even a moderate journey to and from their place of work would entail...We shall have to transport the brains, the skills of the staff, not their bodies, to their daily jobs, again involving not merely ordinary data links but a great many private television channels as well."</span></em></p> <p><span style="font-weight: 400;">The language is a little anachronistic, but here Reeves is speculating that video conferencing will become essential as more employees wish to work remotely. Of course today we don't conference using a TV, we use computers. But just like digital television signals, video conferencing software like Skype employs PCM for audio encoding.</span></p> <p><span style="font-weight: 400;">To learn more about the story of PCM, listen to my episode on the topic:</span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/14251976/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.com/?guid=fbe7faa1-c887-43ca-a9ff-818b8a9918d0"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-29-pcm-origins-of-digital-audio/id1459202600?i=1000473456560&ign-mpt=uo%3D4"> Apple Podcasts</a></span></p>]]></description>
			<content:encoded><![CDATA[<p>Pulse Code Modulation, or PCM, is the core technology behind digital audio. Despite being so central to modern day life PCM is actually pretty old. It was originally developed by Alec Reeves, a telecom engineer, all the way back in 1937. From there the technology has slowly gained traction and eventually found its way into computerized audio systems. Decades after its creation Reeves would write out his thoughts on the technology in an article titled "The past, present and future of PCM"(<a href= "https://tkhf.adaxas.net/cd1/Reeves2.pdf">https://tkhf.adaxas.net/cd1/Reeves2.pdf</a>). Despite being written in 1965, more than 50 ago, his predictions for the future are uncannily accurate.</p> <p>Reeves uses the year 2000 as a goalpost for most of his long-term predictions. Some of these are pretty mundane: telephone usage will greatly increase, new technology will spread in emerging markets outside the US and Europe. His safest prediction is that larger and more widespread use of telephone systems will make PCM the only suitable option for ferrying audio. But Reeves would go on to describe other causes for widespread adoption of PCM:</p> <p>"<em>In my view, this “other reason” by that date will be the necessity for widespread closed-loop television — a necessity, I repeat, not just the urge for a status symbol that is likely to start this kind of demand in the nearer future."</em></p> <p>I've struggled a bit to understand exactly what he means by "closed-loop television" here. It's clear he isn't referring to CCTVs, the direct context makes me think he means broadcast television. However, later in the paper when addressing the use of PCM in information retrieval he writes:</p> <p><em>"The only adequate answer will be for a few information processing centers to be set up in each large industrialized area, staffed by top-grade people, with the information being made available to the public immediately and automatically when a dialed request is made. An ordinary high-speed data link may be adequate for the next 20 years, but by A.D. 2000 the only way to pass the information fast enough to the caller’s brain will be to use moving pictures."</em></p> <p>So it could be that he is trying to describe a teleconferencing-like system. Whatever the case, Reeves is still accurate in predicting the audio side of things. Broadcast television signals switched to digital in most parts of the world during the 2000's, and the audio component of those signals is now encoded as PCM. However, I think the teleconferencing angle has a little more meat to it. In a later passage Reeves writes:</p> <p><em>"Commuters will refuse to accept the delays and inconveniences that even a moderate journey to and from their place of work would entail...We shall have to transport the brains, the skills of the staff, not their bodies, to their daily jobs, again involving not merely ordinary data links but a great many private television channels as well."</em></p> <p>The language is a little anachronistic, but here Reeves is speculating that video conferencing will become essential as more employees wish to work remotely. Of course today we don't conference using a TV, we use computers. But just like digital television signals, video conferencing software like Skype employs PCM for audio encoding.</p> <p>To learn more about the story of PCM, listen to my episode on the topic:</p> <p></p> <p><a href= "http://adventofcomputing.com/?guid=fbe7faa1-c887-43ca-a9ff-818b8a9918d0"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-29-pcm-origins-of-digital-audio/id1459202600?i=1000473456560&ign-mpt=uo%3D4"> Apple Podcasts</a></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[Pulse Code Modulation, or PCM, is the core technology behind digital audio. Despite being so central to modern day life PCM is actually pretty old. It was originally developed by Alec Reeves, a telecom engineer, all the way back in 1937. From there...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 29 - PCM, Origins of Digital Audio</title>
			<itunes:title>PCM, Origins of Digital Audio</itunes:title>
			<pubDate>Sun, 03 May 2020 19:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[fbe7faa1-c887-43ca-a9ff-818b8a9918d0]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-29-pcm-origins-of-digital-audio]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/d/f/6/1/df61e3e486a5437b/pcm2.svg.png" />
			<description><![CDATA[<p>Every day we are inundated with digital audio: phone calls, music, even this podcast. Digitized sound has become so ubiquitous that it often fades into the background. What makes this all possible is a technology called Pulse Code Modulation, or PCM. This isn't new technology, its roots trace all the way back to 1937. So how exactly did digital audio come into being well before the first digital computers?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1937: PCM Developed by Alec Reeves<br /> 1941: Germany Cracks A-3 Code<br /> 1943: Bell Labs Develops SIGSALY(aka The Green Hornet)<br /> 1957: First PCM Synthesizer, MUSIC I, Programmed by Max Mathews</p>]]></description>
			<content:encoded><![CDATA[<p>Every day we are inundated with digital audio: phone calls, music, even this podcast. Digitized sound has become so ubiquitous that it often fades into the background. What makes this all possible is a technology called Pulse Code Modulation, or PCM. This isn't new technology, its roots trace all the way back to 1937. So how exactly did digital audio come into being well before the first digital computers?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1937: PCM Developed by Alec Reeves 1941: Germany Cracks A-3 Code 1943: Bell Labs Develops SIGSALY(aka The Green Hornet) 1957: First PCM Synthesizer, MUSIC I, Programmed by Max Mathews</p>]]></content:encoded>
			<enclosure length="87321559" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/pcm.amr" />
			<itunes:duration>45:23</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>music,sound,history,wwii,computer,belllabs</itunes:keywords>
			<itunes:subtitle><![CDATA[Every day we are inundated with digital audio: phone calls, music, even this podcast. Digitized sound has become so ubiquitous that it often fades into the background. What makes this all possible is a technology called Pulse Code Modulation, or PCM....]]></itunes:subtitle>
			<itunes:episode>29</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 28 - Applesoft BASIC, Microsoft and Apple's First Collaboration</title>
			<itunes:title>Applesoft BASIC, Microsoft and Apple's First Collaboration</itunes:title>
			<pubDate>Sun, 19 Apr 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[daaad62a-63fc-4fce-bb63-7fd831b83fa2]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-28-applesoft-basic-microsoft-and-apples-first-collaboration]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>It's easy to think of Apple and Microsoft as bitter rivals, but that's not always the case. The two companies have a very complicated relationship, and a very long history. This connection goes all the way back to the 1970s and a product called Applesoft BASIC. It would become stock software on nearly every Apple II computer ever sold, it kept Apple competitive in the early home computer market, and it may have saved Microsoft from bankruptcy.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1997: Bill Gates saves Apple from Bankruptcy<br /> 1976: Apple I hits shelves, Integer BASIC soon follows<br /> 1977: Apple II Released<br /> 1978: AppleSoft BASIC Ships</p>]]></description>
			<content:encoded><![CDATA[<p>It's easy to think of Apple and Microsoft as bitter rivals, but that's not always the case. The two companies have a very complicated relationship, and a very long history. This connection goes all the way back to the 1970s and a product called Applesoft BASIC. It would become stock software on nearly every Apple II computer ever sold, it kept Apple competitive in the early home computer market, and it may have saved Microsoft from bankruptcy.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1997: Bill Gates saves Apple from Bankruptcy 1976: Apple I hits shelves, Integer BASIC soon follows 1977: Apple II Released 1978: AppleSoft BASIC Ships</p>]]></content:encoded>
			<enclosure length="76606277" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep28_-_Applesoft.amr" />
			<itunes:duration>39:47</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,microsoft,apple,computer,basic</itunes:keywords>
			<itunes:subtitle><![CDATA[It's easy to think of Apple and Microsoft as bitter rivals, but that's not always the case. The two companies have a very complicated relationship, and a very long history. This connection goes all the way back to the 1970s and a product called...]]></itunes:subtitle>
			<itunes:episode>28</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 27 Notes - Vectrex on Launch Day</title>
			<pubDate>Wed, 08 Apr 2020 22:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[9d7e1311-fc9b-45c6-a89e-bf972f11ef8f]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-27-notes-vectrex-on-launch-day]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The Vectrex was a unique and impressive console. It differentiated itself from other home offerings of the time by using vector graphics instead of a more traditional pixelated approach. The machine could handle crude 3D graphics years before the competition, and in the modern day it's become a cult classic. But what were people saying about the Vectrex on release day? Lets take a look at how Byte described the console in a 1982 article(<a href= "https://archive.org/stream/byte-magazine-1982-12/1982_12_BYTE_07-12_Game_Plan_1982#page/n93/mode/2up">https://archive.org/stream/byte-magazine-1982-12/1982_12_BYTE_07-12_Game_Plan_1982#page/n93/mode/2up</a>).</span><img src="https://assets.libsyn.com/secure/show/177941/Screenshot_from_2020-04-07_16-50-43.png" alt="" width="560" height="111" /></p> <p><span style="font-weight: 400;">Overall, the article casts the console in a positive light. The title itself declares the Vectres "brings true arcade adventures into the home". And that headline is mostly correct. Vector games did exist, titles like Asteroids were extremely popular and rendered totally in vectors. In terms of power the Vectrex was pretty on-par with it's arcade counterparts, in some cases the Vectrex outpaced these cabinets. Asteroids, for instance, ran off of a 6502 CPU which was slower and all around less powerful than the Vectrex's 6809. By going for the smaller niche of vector based games this new console was able to accurately recreate arcade games in the home market.</span></p> <p><span style="font-weight: 400;">The article also brings up portability as a major feature of the Vectrex. Since it didn't plug into a television you could play it anywhere with a power outlet. An integrated screen was part of the Vectrex's design due to necessity: it needed to have full control over it's CRT tube so it couldn't work with a standard TV set. But as it turned out not needing a seperate TV was a selling point. And as would be expected the screen is one of the most mentioned features in Byte:</span></p> <p><em><span style="font-weight: 400;">"And the display -- well it almost has to be seen to be believed; imagine playing games at home (or in the office) using vector graphics with three-dimensional rotation and zoom."</span></em></p> <p><span style="font-weight: 400;">Even in 1982 the Vectrex was surprisingly different from every other game console out there. From day one the machine was set apart from competition. Not only did it look different, it was capable of things that other consoles simply couldn't do. Rendering wire-frames in 3D that were easily rotated and scaled was unheard of outside of arcades. But for $200 you could have that in your home with the Vectrex.</span></p> <p><span style="font-weight: 400;">Also included is a brief listing of some launch titles for the console. What surprises me is just how varied the launch line up was. The Vectrex is often known for it's space-themed and 3D games, but the first set of games represent a pretty wide swath of genres. You have Mine Storm, the Asteroids-like game that comes in an internal ROM on every Vectrex. But you also have a port of Berserk, a car racing game, football, and a few different shooters. To round things out is what I'd say is one of the more impressive titles on the console: StarTrek, a fully 3D first person spaceship shooter. Its clear from this 1982 article that people have always been impressed by the Vectrex.</span></p> <p><span style="font-weight: 400;">If you want to experience the Vectrex for yourself, then you're in luck! The Internet Archive has an expensive collection of games that can all be played from your web browser. Check them out here:</span></p> <p><span style="font-weight: 400;"><a href= "https://archive.org/details/vectrex">https://archive.org/details/vectrex</a></span></p> <p><span style="font-weight: 400;">To learn more about the history of the Vectrex, listen to my episode on the topic:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.com/?guid=3e76973e-fc45-4227-8c21-1599aa708a05"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-27-vectrex-playing-with-vectors/id1459202600?i=1000470599065&uo=4"> Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/13846946/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The Vectrex was a unique and impressive console. It differentiated itself from other home offerings of the time by using vector graphics instead of a more traditional pixelated approach. The machine could handle crude 3D graphics years before the competition, and in the modern day it's become a cult classic. But what were people saying about the Vectrex on release day? Lets take a look at how Byte described the console in a 1982 article(<a href= "https://archive.org/stream/byte-magazine-1982-12/1982_12_BYTE_07-12_Game_Plan_1982#page/n93/mode/2up">https://archive.org/stream/byte-magazine-1982-12/1982_12_BYTE_07-12_Game_Plan_1982#page/n93/mode/2up</a>).</p> <p>Overall, the article casts the console in a positive light. The title itself declares the Vectres "brings true arcade adventures into the home". And that headline is mostly correct. Vector games did exist, titles like Asteroids were extremely popular and rendered totally in vectors. In terms of power the Vectrex was pretty on-par with it's arcade counterparts, in some cases the Vectrex outpaced these cabinets. Asteroids, for instance, ran off of a 6502 CPU which was slower and all around less powerful than the Vectrex's 6809. By going for the smaller niche of vector based games this new console was able to accurately recreate arcade games in the home market.</p> <p>The article also brings up portability as a major feature of the Vectrex. Since it didn't plug into a television you could play it anywhere with a power outlet. An integrated screen was part of the Vectrex's design due to necessity: it needed to have full control over it's CRT tube so it couldn't work with a standard TV set. But as it turned out not needing a seperate TV was a selling point. And as would be expected the screen is one of the most mentioned features in Byte:</p> <p><em>"And the display -- well it almost has to be seen to be believed; imagine playing games at home (or in the office) using vector graphics with three-dimensional rotation and zoom."</em></p> <p>Even in 1982 the Vectrex was surprisingly different from every other game console out there. From day one the machine was set apart from competition. Not only did it look different, it was capable of things that other consoles simply couldn't do. Rendering wire-frames in 3D that were easily rotated and scaled was unheard of outside of arcades. But for $200 you could have that in your home with the Vectrex.</p> <p>Also included is a brief listing of some launch titles for the console. What surprises me is just how varied the launch line up was. The Vectrex is often known for it's space-themed and 3D games, but the first set of games represent a pretty wide swath of genres. You have Mine Storm, the Asteroids-like game that comes in an internal ROM on every Vectrex. But you also have a port of Berserk, a car racing game, football, and a few different shooters. To round things out is what I'd say is one of the more impressive titles on the console: StarTrek, a fully 3D first person spaceship shooter. Its clear from this 1982 article that people have always been impressed by the Vectrex.</p> <p>If you want to experience the Vectrex for yourself, then you're in luck! The Internet Archive has an expensive collection of games that can all be played from your web browser. Check them out here:</p> <p><a href= "https://archive.org/details/vectrex">https://archive.org/details/vectrex</a></p> <p>To learn more about the history of the Vectrex, listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.com/?guid=3e76973e-fc45-4227-8c21-1599aa708a05"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-27-vectrex-playing-with-vectors/id1459202600?i=1000470599065&uo=4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The Vectrex was a unique and impressive console. It differentiated itself from other home offerings of the time by using vector graphics instead of a more traditional pixelated approach. The machine could handle crude 3D graphics years before the...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 27 - Vectrex, Playing With Vectors</title>
			<itunes:title>Vectrex, Playing With Vectors</itunes:title>
			<pubDate>Sun, 05 Apr 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[3e76973e-fc45-4227-8c21-1599aa708a05]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-27-vectrex-playing-with-vectors]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>The 1980s were a turbulent and fast-moving decade for the video game industry. There were huge success stories, rapid advancements in technology, and the North American Video Game Crash. Caught up in all of this was an ambitious machine called the Vectrex. In an era dominated by pixelated graphics the Vectrex brought higher resolution vector images and early 3D to market. But ultimately it would be swept away during the market's crash. Today we are taking a dive into the development of the Vectrex, what made it different, and how it survives into the modern day.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p>]]></description>
			<content:encoded><![CDATA[<p>The 1980s were a turbulent and fast-moving decade for the video game industry. There were huge success stories, rapid advancements in technology, and the North American Video Game Crash. Caught up in all of this was an ambitious machine called the Vectrex. In an era dominated by pixelated graphics the Vectrex brought higher resolution vector images and early 3D to market. But ultimately it would be swept away during the market's crash. Today we are taking a dive into the development of the Vectrex, what made it different, and how it survives into the modern day.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p>]]></content:encoded>
			<enclosure length="83587031" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep27_-_Vectrex.amr" />
			<itunes:duration>43:25</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>gaming,history,videogames,computer,retrogames,vectrex</itunes:keywords>
			<itunes:subtitle><![CDATA[The 1980s were a turbulent and fast-moving decade for the video game industry. There were huge success stories, rapid advancements in technology, and the North American Video Game Crash. Caught up in all of this was an ambitious machine called the...]]></itunes:subtitle>
			<itunes:episode>27</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 26 Notes - Other Predictions from Vannevar Bush</title>
			<pubDate>Wed, 25 Mar 2020 10:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[9145607a-d70e-4838-ab93-ee7518750dab]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-26-notes-other-predictions-from-vannevar-bush]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">First published  in the Atlantic Monthly in 1945, As We May Think is often cited as a watershed moment in computer history. In this essay Vannevar Bush laid out his vision for machines of the future, improved interfaces, and better data handling methods. It's most remembered today for it's description of the Memex, a theoretical device that implemented something close to the internet, complete with hyperlinks, using 1940s technology. However, there is more to this paper than just Memex. Some of the predictions and recommendations made by Bush would be realized in the coming years, others wouldn't come to be for decades.</span></p> <p><span style="font-weight: 400;">One of these predictions is not entirely dissimilar to the idea of a computer network, at least if you use a little imagination. A core feature to Memex and some of Bush's earlier works was microfilm, for a long period of time it was the best way to store large amounts of information. Bush devotes a good amount of As We May Think to describing an idea for essentially a melding of a television and fax machine. The device he describes would take images, transfer them over some type of communication lines, and then reproduce them on microfilm. In this way large amounts of data could be requested from a repository of information and then sent to the requester, similar to a UDP request but using microfilm and fax lines.</span></p> <p><span style="font-weight: 400;">One major theme in As We May Think, and Vannevar's writing in general, is an apparent aversion to the pen and paper. To quote from Bush:</span></p> <p><em><span style="font-weight: 400;">"To make the record, we now push a pencil or tap a typewriter. Then comes the process of digestion and correction, followed by an intricate process of typesetting, printing, and distribution. To consider the first stage of the procedure, will the author of the future cease writing by hand or typewriter and talk directly to the record?"</span></em></p> <p><span style="font-weight: 400;">To be clear, he thought the later would be the case in the near future. While As We May Think was being written some of the first "talking machines" were starting to show promise. The Voder, a very primitive device that could turn keystrokes into human-like speech, was shows at the 1939 World's Fair. Bush was in attendance and became instantly fascinated by the device, but he went further with the idea. If a machine could produce speech why not make a machine that can also understand speech? For the time that was a revolutionary idea. Speech recognition has only recently started catching on after considerable effort has been made, but to put forward the idea prior to the widespread use of computers was another matter entirely. But Bush had an interesting stance on the matter.</span></p> <p><span style="font-weight: 400;">I can't underline enough how Voder only sounded roughly human, it was much more robotic and had a limited range of sounds it could produce. Instead of predicting steady progress towards more human-sounding machines Bush looked in the opposite direction. He posited that in the near future human language would adapt to be better understood by machines, thus rendering human speech more machine-like. In his words:</span></p> <p><span style="font-weight: 400;">"</span><em><span style= "font-weight: 400;">Our present languages are not especially adapted to this sort of mechanization, it is true. It is strange that the inventors of universal languages have not seized upon the idea of producing one which better fitted the technique for transmitting and recording speech."</span></em></p> <p><span style="font-weight: 400;">This prediction had at least half come to pass. Today digitized speech and speech recognition have become common place. A large factor in that has not been the adoption of a universal machine-like language spoken by all humans. Instead it has been thanks to a slow, steady progress to machines that can speak and understand existing human language better.</span></p> <p>You can read the full text of As We May Think on <a href= "https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/"> the Atlantic's website</a>.</p> <p>And if you want to hear more about Memex and it's connection to the internet, you can find my episode on the matter here:</p> <p><a href= "http://adventofcomputing.com/?guid=b72aae68-ebcb-4219-91ef-a49d18dd3b65"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-26-memex-and-hyperlinks/id1459202600?i=1000469184166&uo=4"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/13641617/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>First published  in the Atlantic Monthly in 1945, As We May Think is often cited as a watershed moment in computer history. In this essay Vannevar Bush laid out his vision for machines of the future, improved interfaces, and better data handling methods. It's most remembered today for it's description of the Memex, a theoretical device that implemented something close to the internet, complete with hyperlinks, using 1940s technology. However, there is more to this paper than just Memex. Some of the predictions and recommendations made by Bush would be realized in the coming years, others wouldn't come to be for decades.</p> <p>One of these predictions is not entirely dissimilar to the idea of a computer network, at least if you use a little imagination. A core feature to Memex and some of Bush's earlier works was microfilm, for a long period of time it was the best way to store large amounts of information. Bush devotes a good amount of As We May Think to describing an idea for essentially a melding of a television and fax machine. The device he describes would take images, transfer them over some type of communication lines, and then reproduce them on microfilm. In this way large amounts of data could be requested from a repository of information and then sent to the requester, similar to a UDP request but using microfilm and fax lines.</p> <p>One major theme in As We May Think, and Vannevar's writing in general, is an apparent aversion to the pen and paper. To quote from Bush:</p> <p><em>"To make the record, we now push a pencil or tap a typewriter. Then comes the process of digestion and correction, followed by an intricate process of typesetting, printing, and distribution. To consider the first stage of the procedure, will the author of the future cease writing by hand or typewriter and talk directly to the record?"</em></p> <p>To be clear, he thought the later would be the case in the near future. While As We May Think was being written some of the first "talking machines" were starting to show promise. The Voder, a very primitive device that could turn keystrokes into human-like speech, was shows at the 1939 World's Fair. Bush was in attendance and became instantly fascinated by the device, but he went further with the idea. If a machine could produce speech why not make a machine that can also understand speech? For the time that was a revolutionary idea. Speech recognition has only recently started catching on after considerable effort has been made, but to put forward the idea prior to the widespread use of computers was another matter entirely. But Bush had an interesting stance on the matter.</p> <p>I can't underline enough how Voder only sounded roughly human, it was much more robotic and had a limited range of sounds it could produce. Instead of predicting steady progress towards more human-sounding machines Bush looked in the opposite direction. He posited that in the near future human language would adapt to be better understood by machines, thus rendering human speech more machine-like. In his words:</p> <p>"<em>Our present languages are not especially adapted to this sort of mechanization, it is true. It is strange that the inventors of universal languages have not seized upon the idea of producing one which better fitted the technique for transmitting and recording speech."</em></p> <p>This prediction had at least half come to pass. Today digitized speech and speech recognition have become common place. A large factor in that has not been the adoption of a universal machine-like language spoken by all humans. Instead it has been thanks to a slow, steady progress to machines that can speak and understand existing human language better.</p> <p>You can read the full text of As We May Think on <a href= "https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/"> the Atlantic's website</a>.</p> <p>And if you want to hear more about Memex and it's connection to the internet, you can find my episode on the matter here:</p> <p><a href= "http://adventofcomputing.com/?guid=b72aae68-ebcb-4219-91ef-a49d18dd3b65"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-26-memex-and-hyperlinks/id1459202600?i=1000469184166&uo=4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[First published  in the Atlantic Monthly in 1945, As We May Think is often cited as a watershed moment in computer history. In this essay Vannevar Bush laid out his vision for machines of the future, improved interfaces, and better data handling...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 26 - Memex and Hyperlinks</title>
			<itunes:title>Memex and Hyperlinks</itunes:title>
			<pubDate>Sun, 22 Mar 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[b72aae68-ebcb-4219-91ef-a49d18dd3b65]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-26-memex-and-hyperlinks]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>The widespread use of the internet has shaped our world, it's hard do imagine the modern day without it. One of the biggest featured would have to be the hyperlink. But despite the modern net feeling so new, links actually date back as far as the 1930s and the creation of the Memex: a machine that was never built but would influence coming generations of dreamers.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1927: Differential Analyzer Built at MIT<br /> 1938: Rapid Selector Built by Vannevar Bush<br /> 1945: As We May Think Published</p>]]></description>
			<content:encoded><![CDATA[<p>The widespread use of the internet has shaped our world, it's hard do imagine the modern day without it. One of the biggest featured would have to be the hyperlink. But despite the modern net feeling so new, links actually date back as far as the 1930s and the creation of the Memex: a machine that was never built but would influence coming generations of dreamers.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1927: Differential Analyzer Built at MIT 1938: Rapid Selector Built by Vannevar Bush 1945: As We May Think Published</p>]]></content:encoded>
			<enclosure length="80163946" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep26-Memex.amr" />
			<itunes:duration>41:38</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>internet,history,computer,link,memex</itunes:keywords>
			<itunes:subtitle><![CDATA[The widespread use of the internet has shaped our world, it's hard do imagine the modern day without it. One of the biggest featured would have to be the hyperlink. But despite the modern net feeling so new, links actually date back as far as the...]]></itunes:subtitle>
			<itunes:episode>26</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 25 Notes - Hard Sectoring</title>
			<pubDate>Wed, 11 Mar 2020 22:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[fcf90e10-d3ec-4588-b9dc-b211cfebc6f7]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-25-notes-hard-sectoring]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;"><img src= "https://assets.libsyn.com/secure/show/177941/hard-sector.svg.png" alt="Diagram of hard sector floppy disk" width="444" height= "404" /></span></p> <p><span style="font-weight: 400;">The floppy disk has changed very little since it's original development way back at IBM in the late 1960s. That being said there have been incremental improvements, and I'd like to look at one of those early changes. As it turns out early floppy disks came with a pattern of holes punched along their outer edge. Many 8 inch disks, and some 5 ¼ inch disks, had this feature. These types of disks were called hard sectored, and even though this approach didn't last for long I think it's useful to examine as it can give us a better understanding of how floppy drives worked.</span></p> <p><span style="font-weight: 400;">So what exactly is a sector to begin with? To explain that let's take a look at how data is structured on a floppy disk. Data on a floppy drive is laid out in a similar way to a table, but instead of rows and columns you have tracks and sectors. Each of these sections of the disk can store a small chunk of data, so a read head has to be able to move to any location on the floppy disk. The read/write head of a floppy drive is positioned on a sled ad gear mechanism that can move it in and out over the disk, this allows for track selection. Sector selection is where the holes of hard sector disks come into play.</span></p> <p><span style="font-weight: 400;">When in use the disk of a floppy disk spins at a constant velocity. In order to select a specific sector the drive has to wait for that sector to pass under the head. In order to do this the drive has to know which sector it's on, and that's done by reading the</span> <span style= "font-weight: 400;">s on the disk's perimeter. An optical sensor in the floppy drive trips every time a hole passes so, with a little bit of programming, it's able to keep track of what part of the disk is currently under the head. To finish things off another index hole is usually punched on the inner edge of the disk to mark the first sector, that way the drive knows where to start the sector count.</span></p> <p><span style="font-weight: 400;">Programming the controller for a hard sector disk drive is relatively simple. You don't need all that much code or power to count holes passing by. However, this style of floppy disk would pretty quickly fall out of use. I can't find a definitive answer as to why, but it's easy to speculate at a reason. One of the large driving forces behind the development of the floppy disk was price. Disks were cheap, as were disk drives. Punching holes in hard sector disks would have added an extra step and just a little more overhead to manufacturing costs. Another contributing factor cold have simply been the development of more advanced disk controller circuitry. With a little tinkering, and some more complicated software, it was possible to do away with sector holes all together.</span></p> <p><span style="font-weight: 400;">These newer disks, called soft sectored disks, replaced the physical sector holes with magnetic markers. Instead of using a seperate optical detector the same read/write head that read data would pull double-duty, also registering sector markers. By looking for passing magnetic markets, and a little more complicated code, these soft sector capable drives were made to function just as well as their hard sector counterparts. Once 5 ¼ inch disks became the norm hard sectroing fell out of favor. Punched 5 ¼ inch disks did exist, but they were not nearly as common as soft sector disks.</span></p> <p>To learn more you can listen to my series on the floppy disk here:</p> <p>Part 1: <a href= "http://adventofcomputing.com/?guid=f2e89438-f358-45fb-b820-4603c05bc9ab"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-24-making-disks-flexible-part-1/id1459202600?i=1000466463637&uo=4"> iTunes</a></p> <p>Part 2: <a href= "http://adventofcomputing.com/?guid=6d61d90a-69af-4d53-8b7b-89098a4fabe7"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-25-making-disks-flexible-part-2/id1459202600?i=1000467821320&ign-mpt=uo%3D4"> iTunes</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/13451573/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p></p> <p>The floppy disk has changed very little since it's original development way back at IBM in the late 1960s. That being said there have been incremental improvements, and I'd like to look at one of those early changes. As it turns out early floppy disks came with a pattern of holes punched along their outer edge. Many 8 inch disks, and some 5 ¼ inch disks, had this feature. These types of disks were called hard sectored, and even though this approach didn't last for long I think it's useful to examine as it can give us a better understanding of how floppy drives worked.</p> <p>So what exactly is a sector to begin with? To explain that let's take a look at how data is structured on a floppy disk. Data on a floppy drive is laid out in a similar way to a table, but instead of rows and columns you have tracks and sectors. Each of these sections of the disk can store a small chunk of data, so a read head has to be able to move to any location on the floppy disk. The read/write head of a floppy drive is positioned on a sled ad gear mechanism that can move it in and out over the disk, this allows for track selection. Sector selection is where the holes of hard sector disks come into play.</p> <p>When in use the disk of a floppy disk spins at a constant velocity. In order to select a specific sector the drive has to wait for that sector to pass under the head. In order to do this the drive has to know which sector it's on, and that's done by reading the s on the disk's perimeter. An optical sensor in the floppy drive trips every time a hole passes so, with a little bit of programming, it's able to keep track of what part of the disk is currently under the head. To finish things off another index hole is usually punched on the inner edge of the disk to mark the first sector, that way the drive knows where to start the sector count.</p> <p>Programming the controller for a hard sector disk drive is relatively simple. You don't need all that much code or power to count holes passing by. However, this style of floppy disk would pretty quickly fall out of use. I can't find a definitive answer as to why, but it's easy to speculate at a reason. One of the large driving forces behind the development of the floppy disk was price. Disks were cheap, as were disk drives. Punching holes in hard sector disks would have added an extra step and just a little more overhead to manufacturing costs. Another contributing factor cold have simply been the development of more advanced disk controller circuitry. With a little tinkering, and some more complicated software, it was possible to do away with sector holes all together.</p> <p>These newer disks, called soft sectored disks, replaced the physical sector holes with magnetic markers. Instead of using a seperate optical detector the same read/write head that read data would pull double-duty, also registering sector markers. By looking for passing magnetic markets, and a little more complicated code, these soft sector capable drives were made to function just as well as their hard sector counterparts. Once 5 ¼ inch disks became the norm hard sectroing fell out of favor. Punched 5 ¼ inch disks did exist, but they were not nearly as common as soft sector disks.</p> <p>To learn more you can listen to my series on the floppy disk here:</p> <p>Part 1: <a href= "http://adventofcomputing.com/?guid=f2e89438-f358-45fb-b820-4603c05bc9ab"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-24-making-disks-flexible-part-1/id1459202600?i=1000466463637&uo=4"> iTunes</a></p> <p>Part 2: <a href= "http://adventofcomputing.com/?guid=6d61d90a-69af-4d53-8b7b-89098a4fabe7"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-25-making-disks-flexible-part-2/id1459202600?i=1000467821320&ign-mpt=uo%3D4"> iTunes</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The floppy disk has changed very little since it's original development way back at IBM in the late 1960s. That being said there have been incremental improvements, and I'd like to look at one of those early changes. As it turns out early floppy disks...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 25 - Making Disks Flexible, Part 2</title>
			<itunes:title>Making Disks Flexible, Part 2</itunes:title>
			<pubDate>Sun, 08 Mar 2020 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[6d61d90a-69af-4d53-8b7b-89098a4fabe7]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-25-making-disks-flexible-part-2]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/b/f/5/3/bf53182cc5e3bb46/floppy2.png" />
			<description><![CDATA[<p>The floppy disk is one of the most iconic pieces of technology. While not in use in the modern day there was a period of 40 years where the floppy disk was synonymous with data storage. Today we pick up where we finished in the last episode, with the rise and fall of the 5 1/4 inch disk. We will be looking at the creation and spread of the 3 1/2 inch floppy disk. How did Sony, a non-player in the computer market, create this run away success? And how did Apple contribute to it's rise?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1980: Sony Invents Microfloppy Disk<br /> 1983: Apple Builds Prototype MAC with 3 1/2 Inch Floppy</p>]]></description>
			<content:encoded><![CDATA[<p>The floppy disk is one of the most iconic pieces of technology. While not in use in the modern day there was a period of 40 years where the floppy disk was synonymous with data storage. Today we pick up where we finished in the last episode, with the rise and fall of the 5 1/4 inch disk. We will be looking at the creation and spread of the 3 1/2 inch floppy disk. How did Sony, a non-player in the computer market, create this run away success? And how did Apple contribute to it's rise?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1980: Sony Invents Microfloppy Disk 1983: Apple Builds Prototype MAC with 3 1/2 Inch Floppy</p>]]></content:encoded>
			<enclosure length="75319276" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep25_-_Floppy_Disk_Part_2.amr" />
			<itunes:duration>39:07</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,sony,apple,computer,disk,floppy</itunes:keywords>
			<itunes:subtitle><![CDATA[The floppy disk is one of the most iconic pieces of technology. While not in use in the modern day there was a period of 40 years where the floppy disk was synonymous with data storage. Today we pick up where we finished in the last episode, with the...]]></itunes:subtitle>
			<itunes:episode>25</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 24 - Making Disks Flexible, Part 1</title>
			<itunes:title>Making Disks Flexible, Part 1</itunes:title>
			<pubDate>Mon, 24 Feb 2020 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[f2e89438-f358-45fb-b820-4603c05bc9ab]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-24-making-disks-flexible-part-1]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/f/e/1/e/fe1e99697ff0f96c/floppy1.png" />
			<description><![CDATA[<p>The floppy disk was a ubiquitous technology for nearly 40 years. From mainframes to home computers, the plastic disk was everywhere. And in the decades it was around there were very few changes made to how it fundamentally worked. So how did it get so popular? What made the floppy disk so flexible? And how did it finally fall out of favor? In this episode we will look at the technology's early days.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1971: 8 Inch Floppy Disk(Minnow) Created at IBM<br /> 1976: Shugart Invents 5 1/4 Inch Floppy Disk</p>]]></description>
			<content:encoded><![CDATA[<p>The floppy disk was a ubiquitous technology for nearly 40 years. From mainframes to home computers, the plastic disk was everywhere. And in the decades it was around there were very few changes made to how it fundamentally worked. So how did it get so popular? What made the floppy disk so flexible? And how did it finally fall out of favor? In this episode we will look at the technology's early days.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1971: 8 Inch Floppy Disk(Minnow) Created at IBM 1976: Shugart Invents 5 1/4 Inch Floppy Disk</p>]]></content:encoded>
			<enclosure length="82056904" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep24_-_Floppy_Part1.amr" />
			<itunes:duration>42:27</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,computer,storage,ibm,floppy</itunes:keywords>
			<itunes:subtitle><![CDATA[The floppy disk was a ubiquitous technology for nearly 40 years. From mainframes to home computers, the plastic disk was everywhere. And in the decades it was around there were very few changes made to how it fundamentally worked. So how did it get so...]]></itunes:subtitle>
			<itunes:episode>24</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 23 Notes - Artifacts of FORTRAN</title>
			<pubDate>Wed, 12 Feb 2020 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[7de1cb6c-2fa2-4595-b63a-39fa4d8c0fbb]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-23-notes-artifacts-of-fortran]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">In November of 1954 the first preliminary design of FORTRAN was completed. Over the next few years a compiler was built and distributed, various changes were made to the language, and FORTRAN would start down it's path to domination. High level programming languages, starting with FORTRAN, would change what could be done with computers. In the modern day low level languages(such as assembly or machine code) are only used in niche applications, by and large programmers use sophisticated high level languages. And even through the field has come a long way since the 1950s you can still find artifacts of FORTRAN in modern day code. So what can we see in modern programming that was present in the first FORTRAN specification(</span><a href= "https://archive.computerhistory.org/resources/text/Fortran/102679231.05.01.acc.pdf"><span style="font-weight: 400;">https://archive.computerhistory.org/resources/text/Fortran/102679231.05.01.acc.pdf</span></a><span style="font-weight: 400;">)?</span></p> <p><span style="font-weight: 400;">Many of the features of FORTRAN's syntax were adapted from mathematics. For instance, the language has named variables, and simply uses an equals sign for assignment. These are both core features to modern languages, very very few programming languages differ from this convention. The syntax for mathematical expressions is also taken directly from pen-and-paper math. A plus is used for summing two values, and minus for subtracting, and so on. There are good reasons that this basic structure is used in more modern languages, it's clear and easy to understand and use. In that way FORTRAN more set convention than invented the syntax. However, there is one part of FORTRAN's math syntax that strikes me as interesting. The "x" operator is used for multiplication, for exponents it's doubled to the "xx" operator. More than likely this was done due to the limited character set that could be represented on punched cards. What I find interesting is that some modern languages still adhere to this schema. For instance, in Python the multiplication operator is "*" and the exponential operator is "**". More than a direct adaptation, it's more likely that FORTRAN entered the double-multiplication-is-exponent syntax into common convention.</span></p> <p><span style="font-weight: 400;">Named variables are another big feature for FORTRAN, but in early versions of the compiler there were some major limitations. Variable names could be no longer than two characters. There was also some implicit typing tied in with variables names. Any variables that started with i, j, k, l, m, or n were treated as integers while all other variables were treated as floats. On the surface this distinction may seem arbitrary, but there is good reason for this choice. In mathematics it is common to use i, j, k, l, m, or n to represent iterators(such as with the summation operator) or as indexes in vectors of matrices. FORTRAN didn't invent this notation, but it would help codify it as convention for programmers. Today it's almost universally accepted that "i" is just what you call an iterator in loops, and if it's taken then you move to "j" and on down the line.</span></p> <p><span style="font-weight: 400;">Another interesting artifact that has to do with integers is FORTRAN's "do" loops. Later versions of FORTRAN would have relatively modern looking loops, but the preliminary report and early versions offered a different take on the matter. A do loop would look something like this:</span></p> <p><span style="font-weight: 400;">        <em>DO 1, 10, 11</em></span> <em><span style= "font-weight: 400;">i=1, 10, 1</span></em></p> <p><span style="font-weight: 400;">It's a little dense. Basically, that line of FORTRAN will loop over line 1 to 10, and when done looping jump to like 11. The second part of the line sets up the iterator, we will look "i" from values 1 to 10 in steps of 1. Later versions would change to using "do...while" instead. Needless to say programming languages have much more clear loop syntax today. However, loops using the same "do" keyword still exist in many languages including C, C++, JavaScript, PHP, and even Kotlin.</span></p> <p><span style="font-weight: 400;">The final relic I want to touch upon is the infamous "goto" statement. Syntactically, this one is much more simple than "do". It looks like this in the preliminary report:</span></p> <p><span style="font-weight: 400;">        <em>GO TO 100</em></span></p> <p><span style="font-weight: 400;">That statement would jump execution to line 100 of your program. This statement, or at least this type of operation, predates FORTRAN. On the machine code level "goto" is analogous to a jump instruction. In more recent times it has been said that these types of instructions shouldn't be used in high level programming languages, but that hasn't stopped "goto" from making an appearance. It's not as widespread as "do" but some recent languages like Google's Go still support the keyword.</span></p> <p>To learn more about FORTRAN and the early development of programming languages, check out my episode on the matter:</p> <p><a href= "http://adventofcomputing.com/?guid=834b9e04-0477-4d78-9ce6-ee5c0721a8ac"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-23-fortran-compilers-and-early-programming/id1459202600?i=1000465106342&uo=4"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/13070960/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>In November of 1954 the first preliminary design of FORTRAN was completed. Over the next few years a compiler was built and distributed, various changes were made to the language, and FORTRAN would start down it's path to domination. High level programming languages, starting with FORTRAN, would change what could be done with computers. In the modern day low level languages(such as assembly or machine code) are only used in niche applications, by and large programmers use sophisticated high level languages. And even through the field has come a long way since the 1950s you can still find artifacts of FORTRAN in modern day code. So what can we see in modern programming that was present in the first FORTRAN specification(<a href= "https://archive.computerhistory.org/resources/text/Fortran/102679231.05.01.acc.pdf">https://archive.computerhistory.org/resources/text/Fortran/102679231.05.01.acc.pdf</a>)?</p> <p>Many of the features of FORTRAN's syntax were adapted from mathematics. For instance, the language has named variables, and simply uses an equals sign for assignment. These are both core features to modern languages, very very few programming languages differ from this convention. The syntax for mathematical expressions is also taken directly from pen-and-paper math. A plus is used for summing two values, and minus for subtracting, and so on. There are good reasons that this basic structure is used in more modern languages, it's clear and easy to understand and use. In that way FORTRAN more set convention than invented the syntax. However, there is one part of FORTRAN's math syntax that strikes me as interesting. The "x" operator is used for multiplication, for exponents it's doubled to the "xx" operator. More than likely this was done due to the limited character set that could be represented on punched cards. What I find interesting is that some modern languages still adhere to this schema. For instance, in Python the multiplication operator is "*" and the exponential operator is "**". More than a direct adaptation, it's more likely that FORTRAN entered the double-multiplication-is-exponent syntax into common convention.</p> <p>Named variables are another big feature for FORTRAN, but in early versions of the compiler there were some major limitations. Variable names could be no longer than two characters. There was also some implicit typing tied in with variables names. Any variables that started with i, j, k, l, m, or n were treated as integers while all other variables were treated as floats. On the surface this distinction may seem arbitrary, but there is good reason for this choice. In mathematics it is common to use i, j, k, l, m, or n to represent iterators(such as with the summation operator) or as indexes in vectors of matrices. FORTRAN didn't invent this notation, but it would help codify it as convention for programmers. Today it's almost universally accepted that "i" is just what you call an iterator in loops, and if it's taken then you move to "j" and on down the line.</p> <p>Another interesting artifact that has to do with integers is FORTRAN's "do" loops. Later versions of FORTRAN would have relatively modern looking loops, but the preliminary report and early versions offered a different take on the matter. A do loop would look something like this:</p> <p>        <em>DO 1, 10, 11</em> <em>i=1, 10, 1</em></p> <p>It's a little dense. Basically, that line of FORTRAN will loop over line 1 to 10, and when done looping jump to like 11. The second part of the line sets up the iterator, we will look "i" from values 1 to 10 in steps of 1. Later versions would change to using "do...while" instead. Needless to say programming languages have much more clear loop syntax today. However, loops using the same "do" keyword still exist in many languages including C, C++, JavaScript, PHP, and even Kotlin.</p> <p>The final relic I want to touch upon is the infamous "goto" statement. Syntactically, this one is much more simple than "do". It looks like this in the preliminary report:</p> <p>        <em>GO TO 100</em></p> <p>That statement would jump execution to line 100 of your program. This statement, or at least this type of operation, predates FORTRAN. On the machine code level "goto" is analogous to a jump instruction. In more recent times it has been said that these types of instructions shouldn't be used in high level programming languages, but that hasn't stopped "goto" from making an appearance. It's not as widespread as "do" but some recent languages like Google's Go still support the keyword.</p> <p>To learn more about FORTRAN and the early development of programming languages, check out my episode on the matter:</p> <p><a href= "http://adventofcomputing.com/?guid=834b9e04-0477-4d78-9ce6-ee5c0721a8ac"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-23-fortran-compilers-and-early-programming/id1459202600?i=1000465106342&uo=4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[In November of 1954 the first preliminary design of FORTRAN was completed. Over the next few years a compiler was built and distributed, various changes were made to the language, and FORTRAN would start down it's path to domination. High level...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 23 - FORTRAN, Compilers, and Early Programming</title>
			<itunes:title>FORTRAN, Compilers, and Early Programming</itunes:title>
			<pubDate>Mon, 10 Feb 2020 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[834b9e04-0477-4d78-9ce6-ee5c0721a8ac]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-23-fortran-compilers-and-early-programming]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>Our modern world is full of software, it's what makes everything tick. The sheer amount of code that goes into something like keeping the internet running is staggering. Programming isn't the easiest profession, but there was a time when it was much much harder. It took a huge shift in thinking, and some impressive feats of software development, to make complicated programming possible. And that shift started in the 1950s.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1951: Grace Hopper Creates A-0 Compiler<br /> 1954: John Backus Starts FORTRAN Project at IBM<br /> 1957: First FORTARN Compiler Ships</p>]]></description>
			<content:encoded><![CDATA[<p>Our modern world is full of software, it's what makes everything tick. The sheer amount of code that goes into something like keeping the internet running is staggering. Programming isn't the easiest profession, but there was a time when it was much much harder. It took a huge shift in thinking, and some impressive feats of software development, to make complicated programming possible. And that shift started in the 1950s.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1951: Grace Hopper Creates A-0 Compiler 1954: John Backus Starts FORTRAN Project at IBM 1957: First FORTARN Compiler Ships</p>]]></content:encoded>
			<enclosure length="98456347" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep23_-_FORTRAN.amr" />
			<itunes:duration>51:10</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>computer,programming,fortran,hopper,backus</itunes:keywords>
			<itunes:subtitle><![CDATA[Our modern world is full of software, it's what makes everything tick. The sheer amount of code that goes into something like keeping the internet running is staggering. Programming isn't the easiest profession, but there was a time when it was much...]]></itunes:subtitle>
			<itunes:episode>23</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 22 Notes - Playing Rogue Today</title>
			<pubDate>Wed, 29 Jan 2020 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[26170e94-f6a2-4238-ace8-c98c7b623802]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-22-notes-playing-rogue-today]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Rogue is, arguably, one of the most influential video game ever written. It was the first game to make significant use of procedurally generated content. And there is a good chance that most people have never played it. Despite it's important and far-reaching legacy Rogue was never a commercial success. However, games heavily influenced on the 1980 original are still published and played today. Some games like Diablo, Pokemon Mystery Dungeon, Faster Than Light, or Darkest Dungeon borrow heavily from Rogue's design. Still others like Minecraft or No Man's Sky have core gameplay elements such as procedural generation. Even with the plethora of options for modern roguelike games, I think it's worth tracking down the original and giving it a spin. There are a lot of ways to play Rogue today, so I'll go over some of the options at your disposal.</span></p> <p><span style="font-weight: 400;">The easiest way to get into the Dungeon of Doom is probably via the Internet Archive. It really is amazing just everything that the Archive, well, archives. Anyway, thanks to their in-browser emulator you can play Rogue for a number of platforms very easily. The best ports to get started with are probably the <a href= "https://archive.org/details/Rogue_The_Adventure_Game_1986_Epyx">MS-DOS version</a></span> <span style="font-weight: 400;">or the <a href= "https://archive.org/details/mac_Rogue">Macintosh release</a></span><span style="font-weight: 400;">. DOS Rogue is the closest to the original since it's graphics are all rendered using text characters. The major change between the 1980 version and the DOS release is the addition of color and an increased character set, both thanks to the IBM PC. Controls are relatively simple, relying on arrow keys for movement and hotkeys for actions.</span></p> <p><span style="font-weight: 400;">The Macintosh version is quite a bit different, it has the same gameplay as the original but the graphics and controls are another story. As with most Mac software the game is rendered in black and white graphics. Everything is represented by small sprites on screen, from items to monsters to the dungeon map. It retains the same gameplay as all versions do, but the control scheme is a lot different. The entire game is driven by the mouse, a series of menus, and sub-windows. It's reasonably easy to get used to, but navigating dungeons with a mouse just doesn't feel quite the same.</span></p> <p><span style="font-weight: 400;">Another option outside of emulation is to find a copy of rogue for your platform of choice. Luckily, there are plenty to choose from over at the <a href= "https://britzl.github.io/roguearchive/">Roguelike Archive</a></span><span style="font-weight: 400;">. This site hosts a collection of versions of Rogue and early roguelike games. This includes copies of the aforementioned DOS and Mac ports, as well as many other ports, beta releases, and source code. The real draw for me here are the early versions of Rogue, the earliest on this page being version 3.6 from 1981. There are compiled binaries for various platforms with matching source code for the curious. These archives are from the (seemingly defunct) <a href= "http://web.archive.org/web/20160515032831/http://rogue.rogueforge.net/roguelike-restoration-project-2/"> Roguelike Restoration Project</a></span><span style= "font-weight: 400;">.</span></p> <p><span style="font-weight: 400;">Beyond being an interesting relic to explore Rogue still holds up as a fun game today. It presents a stripped down experience, presenting just what's needed to have an engaging RPG with none of the frills. In an era flooded with fancy AAA titles I think Rogue and it's close relatives still have a place. But if the graphics and controls are still a little daunting, if you'd like to just have more options, then there are! I'd also recommend checking out <a href= "http://slashem.sourceforge.net/">Slash'Em</a></span> <span style= "font-weight: 400;">or <a href= "https://www.nethack.org/">NetHack</a></span><span style= "font-weight: 400;">. Both of these games are descendants of Rogue but with many, many, many more features. Each have expanded and new mechanics, character classes, more stats, and optional graphics.</span></p> <p><span style="font-weight: 400;">If you want to learn more about the history of Rogue, then you can listen to my episode on the matter here:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.com/?guid=bf4fe6c4-b3a2-43c5-a937-e1df109d297a"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-22-going-rogue/id1459202600?i=1000463702225&ign-mpt=uo%3D4"> Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/12885713/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>Rogue is, arguably, one of the most influential video game ever written. It was the first game to make significant use of procedurally generated content. And there is a good chance that most people have never played it. Despite it's important and far-reaching legacy Rogue was never a commercial success. However, games heavily influenced on the 1980 original are still published and played today. Some games like Diablo, Pokemon Mystery Dungeon, Faster Than Light, or Darkest Dungeon borrow heavily from Rogue's design. Still others like Minecraft or No Man's Sky have core gameplay elements such as procedural generation. Even with the plethora of options for modern roguelike games, I think it's worth tracking down the original and giving it a spin. There are a lot of ways to play Rogue today, so I'll go over some of the options at your disposal.</p> <p>The easiest way to get into the Dungeon of Doom is probably via the Internet Archive. It really is amazing just everything that the Archive, well, archives. Anyway, thanks to their in-browser emulator you can play Rogue for a number of platforms very easily. The best ports to get started with are probably the <a href= "https://archive.org/details/Rogue_The_Adventure_Game_1986_Epyx">MS-DOS version</a> or the <a href= "https://archive.org/details/mac_Rogue">Macintosh release</a>. DOS Rogue is the closest to the original since it's graphics are all rendered using text characters. The major change between the 1980 version and the DOS release is the addition of color and an increased character set, both thanks to the IBM PC. Controls are relatively simple, relying on arrow keys for movement and hotkeys for actions.</p> <p>The Macintosh version is quite a bit different, it has the same gameplay as the original but the graphics and controls are another story. As with most Mac software the game is rendered in black and white graphics. Everything is represented by small sprites on screen, from items to monsters to the dungeon map. It retains the same gameplay as all versions do, but the control scheme is a lot different. The entire game is driven by the mouse, a series of menus, and sub-windows. It's reasonably easy to get used to, but navigating dungeons with a mouse just doesn't feel quite the same.</p> <p>Another option outside of emulation is to find a copy of rogue for your platform of choice. Luckily, there are plenty to choose from over at the <a href= "https://britzl.github.io/roguearchive/">Roguelike Archive</a>. This site hosts a collection of versions of Rogue and early roguelike games. This includes copies of the aforementioned DOS and Mac ports, as well as many other ports, beta releases, and source code. The real draw for me here are the early versions of Rogue, the earliest on this page being version 3.6 from 1981. There are compiled binaries for various platforms with matching source code for the curious. These archives are from the (seemingly defunct) <a href= "http://web.archive.org/web/20160515032831/http://rogue.rogueforge.net/roguelike-restoration-project-2/"> Roguelike Restoration Project</a>.</p> <p>Beyond being an interesting relic to explore Rogue still holds up as a fun game today. It presents a stripped down experience, presenting just what's needed to have an engaging RPG with none of the frills. In an era flooded with fancy AAA titles I think Rogue and it's close relatives still have a place. But if the graphics and controls are still a little daunting, if you'd like to just have more options, then there are! I'd also recommend checking out <a href= "http://slashem.sourceforge.net/">Slash'Em</a> or <a href= "https://www.nethack.org/">NetHack</a>. Both of these games are descendants of Rogue but with many, many, many more features. Each have expanded and new mechanics, character classes, more stats, and optional graphics.</p> <p>If you want to learn more about the history of Rogue, then you can listen to my episode on the matter here:</p> <p><a href= "http://adventofcomputing.com/?guid=bf4fe6c4-b3a2-43c5-a937-e1df109d297a"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-22-going-rogue/id1459202600?i=1000463702225&ign-mpt=uo%3D4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[Rogue is, arguably, one of the most influential video game ever written. It was the first game to make significant use of procedurally generated content. And there is a good chance that most people have never played it. Despite it's important and...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 22 - Going Rogue</title>
			<itunes:title>Going Rogue</itunes:title>
			<pubDate>Sun, 26 Jan 2020 12:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[bf4fe6c4-b3a2-43c5-a937-e1df109d297a]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-22-going-rogue]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/3/5/f/435f54726fdc6cec/rodney.svg.png" />
			<description><![CDATA[<p>Many video games today make use of randomized content, some more than others. It may seem like an obvious feature, but it turns out that procedural generation didn't really catch on in video games until the 1980 release of Rogue. The game itself never saw much commercial success, but was wildly popular among UNIX users. In this episode we look at Rogue, how it was created, and the legacy that we still see today.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1980: Rogue Written for PDP/11<br /> 1984: Rogue Ported to PC, Macintosh, Atari ST</p>]]></description>
			<content:encoded><![CDATA[<p>Many video games today make use of randomized content, some more than others. It may seem like an obvious feature, but it turns out that procedural generation didn't really catch on in video games until the 1980 release of Rogue. The game itself never saw much commercial success, but was wildly popular among UNIX users. In this episode we look at Rogue, how it was created, and the legacy that we still see today.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1980: Rogue Written for PDP/11 1984: Rogue Ported to PC, Macintosh, Atari ST</p>]]></content:encoded>
			<enclosure length="87049949" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep22_-_Going_Rogue.amr" />
			<itunes:duration>45:15</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,game,computer,videogame,rogue</itunes:keywords>
			<itunes:subtitle><![CDATA[Many video games today make use of randomized content, some more than others. It may seem like an obvious feature, but it turns out that procedural generation didn't really catch on in video games until the 1980 release of Rogue. The game itself never...]]></itunes:subtitle>
			<itunes:episode>22</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 21 Notes - How Capable Was the 8008?</title>
			<pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[d4476309-f580-447a-80c9-69353a7841f0]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-21-notes-how-capable-was-the-8008]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The Intel 8008 was the second microprocessor produced my Intel, but it was the first to have much interesting software written for it. Intel's earlier chip, the 4004, was only ever really used for desktop calculators. So most of the software written for that platform is very special purpose. Things were different for the 8008. It was used in some of the earliest personal computers, so it had relatively complex and flexible software released for it.</span></p> <p><span style="font-weight: 400;">8-bit home computers would come to be known, almost as a cliche, for running BASIC. Well, it turns out that the tradition started early. The 8008 was the first 8-bit microprocessor, and it also had its own dialect of BASIC. One of the first companies to offer an interpreter was SCELBI(SCientific ELectronics BIology), for their own kit computer and other 8008-baed systems. This early microcomputer version of BASIC was called SCELBAL(for SCientific ELementary BAsic Language). This meant that it was possible to program for the 8008 with something other than assembly language, making it a much more immediately useful platform.</span></p> <p><span style="font-weight: 400;">The reason this is possible with the 8008 and not a chip like the earlier 4004 comes down to complexity. The 8008 wasn't the first microprocessor, but it was the first one capable enough to run something as complex as BASIC. For some comparison: the 4004 could address only 640 bytes of memory, whereas the 8008 could handle up to 16 kilobytes. The 4004 also rigidly enforced separate memory segments for code and data, while the 8008 adhered to the more flexible Von Neuman architecture.</span></p> <p><span style="font-weight: 400;">Outside of all of those qualifications is the simple fact that the 4004 was a 4-bit microprocessor. The single internal register, it's accumulator, was only 4-bits wide. While certainly useful for something as simple as a desktop calculator it puts the chip at a major disadvantage when it comes to more intensive tasks. And there is one key application that the 4004 would have had a major problem with: string processing. A 4-bit number can only encode 16 possible values, not enough to encode the full Latin alphabet. That fact alone means that programming something as simple as a string compare would be pretty difficult, or at pretty slow. Add that to the limited memory space and you aren't going to be getting much done with this chip.</span></p> <p><span style="font-weight: 400;">By contract the 8-bit 8008 had plenty of space to handle characters and strings. With seven internal registers, each 8 bits wide, there is a lot of scratch space to work with. And since an 8-bit number can encode 256 possible numbers that means that you can do string processing much more easily with the 8008. Of course, that wasn't the only factor. But the simple fact that the 8008 was able to be programmed to efficiently handle functions like a string compare meant it could run BASIC. And that opens up a much larger world of possibilities.</span></p> <p><span style="font-weight: 400;">To learn more about the Intel 8008, listen to my episode on the topic:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.libsyn.com/episode-21-8008-intels-second-shot"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-21-8008-intels-second-shot/id1459202600?i=1000462307783&ign-mpt=uo%3D4"> Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/12706943/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The Intel 8008 was the second microprocessor produced my Intel, but it was the first to have much interesting software written for it. Intel's earlier chip, the 4004, was only ever really used for desktop calculators. So most of the software written for that platform is very special purpose. Things were different for the 8008. It was used in some of the earliest personal computers, so it had relatively complex and flexible software released for it.</p> <p>8-bit home computers would come to be known, almost as a cliche, for running BASIC. Well, it turns out that the tradition started early. The 8008 was the first 8-bit microprocessor, and it also had its own dialect of BASIC. One of the first companies to offer an interpreter was SCELBI(SCientific ELectronics BIology), for their own kit computer and other 8008-baed systems. This early microcomputer version of BASIC was called SCELBAL(for SCientific ELementary BAsic Language). This meant that it was possible to program for the 8008 with something other than assembly language, making it a much more immediately useful platform.</p> <p>The reason this is possible with the 8008 and not a chip like the earlier 4004 comes down to complexity. The 8008 wasn't the first microprocessor, but it was the first one capable enough to run something as complex as BASIC. For some comparison: the 4004 could address only 640 bytes of memory, whereas the 8008 could handle up to 16 kilobytes. The 4004 also rigidly enforced separate memory segments for code and data, while the 8008 adhered to the more flexible Von Neuman architecture.</p> <p>Outside of all of those qualifications is the simple fact that the 4004 was a 4-bit microprocessor. The single internal register, it's accumulator, was only 4-bits wide. While certainly useful for something as simple as a desktop calculator it puts the chip at a major disadvantage when it comes to more intensive tasks. And there is one key application that the 4004 would have had a major problem with: string processing. A 4-bit number can only encode 16 possible values, not enough to encode the full Latin alphabet. That fact alone means that programming something as simple as a string compare would be pretty difficult, or at pretty slow. Add that to the limited memory space and you aren't going to be getting much done with this chip.</p> <p>By contract the 8-bit 8008 had plenty of space to handle characters and strings. With seven internal registers, each 8 bits wide, there is a lot of scratch space to work with. And since an 8-bit number can encode 256 possible numbers that means that you can do string processing much more easily with the 8008. Of course, that wasn't the only factor. But the simple fact that the 8008 was able to be programmed to efficiently handle functions like a string compare meant it could run BASIC. And that opens up a much larger world of possibilities.</p> <p>To learn more about the Intel 8008, listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-21-8008-intels-second-shot"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-21-8008-intels-second-shot/id1459202600?i=1000462307783&ign-mpt=uo%3D4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The Intel 8008 was the second microprocessor produced my Intel, but it was the first to have much interesting software written for it. Intel's earlier chip, the 4004, was only ever really used for desktop calculators. So most of the software written...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 21 - 8008: Intel's Second Shot</title>
			<itunes:title>8008: Intel's Second Shot</itunes:title>
			<pubDate>Mon, 13 Jan 2020 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[240d52f3-6df0-44f7-a5c9-0ddd16cc8da1]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-21-8008-intels-second-shot]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/1/f/d/9/1fd9e141ac8ac572/8008.png" />
			<description><![CDATA[<p>It's time to continue our deep dive into the legacy of Intel's processors. This episode we will be looking at the 8008, the second microprocessor produced by Intel and the progenitor of the x86 family. Along the way we will see how an innovative terminal from 1969 inspired the chip, how Intel lost a contract, and discuss some of the first personal computes.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1969: CTC Develops First 'Glass-Teletype' Terminal<br /> 1972: 8008 CPU Released by Intel</p>]]></description>
			<content:encoded><![CDATA[<p>It's time to continue our deep dive into the legacy of Intel's processors. This episode we will be looking at the 8008, the second microprocessor produced by Intel and the progenitor of the x86 family. Along the way we will see how an innovative terminal from 1969 inspired the chip, how Intel lost a contract, and discuss some of the first personal computes.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1969: CTC Develops First 'Glass-Teletype' Terminal 1972: 8008 CPU Released by Intel</p>]]></content:encoded>
			<enclosure length="60955148" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep21_-_8008.amr" />
			<itunes:duration>31:35</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>computer,intel,cpu,microprocessor</itunes:keywords>
			<itunes:subtitle><![CDATA[It's time to continue our deep dive into the legacy of Intel's processors. This episode we will be looking at the 8008, the second microprocessor produced by Intel and the progenitor of the x86 family. Along the way we will see how an innovative...]]></itunes:subtitle>
			<itunes:episode>21</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 20.5 - Cooking in Y2K</title>
			<itunes:title>Cooking in Y2K</itunes:title>
			<pubDate>Mon, 06 Jan 2020 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[adb8bb3d-2443-4a6c-8b91-31e58f49b65b]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-205-cooking-in-y2k]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In this mini episode we will look at the Y2K bug, and some of the recipes it spawned. That's right, we are talking about Y2K cookbooks!</p> <p>You can find all more Y2K compliant food here: <a href= "https://web.archive.org/web/19991012032855/http://y2kkitchen.com/"> https://web.archive.org/web/19991012032855/http://y2kkitchen.com/</a></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1999: Y2K Kitchen Hits Shelves</p>]]></description>
			<content:encoded><![CDATA[<p>In this mini episode we will look at the Y2K bug, and some of the recipes it spawned. That's right, we are talking about Y2K cookbooks!</p> <p>You can find all more Y2K compliant food here: <a href= "https://web.archive.org/web/19991012032855/http://y2kkitchen.com/"> https://web.archive.org/web/19991012032855/http://y2kkitchen.com/</a></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1999: Y2K Kitchen Hits Shelves</p>]]></content:encoded>
			<enclosure length="22722791" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep20.5_-_Cooking_in_Y2K.amr" />
			<itunes:duration>11:43</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>cooking,food,history,computer,y2k</itunes:keywords>
			<itunes:subtitle><![CDATA[In this mini episode we will look at the Y2K bug, and some of the recipes it spawned. That's right, we are talking about Y2K cookbooks! You can find all more Y2K compliant food here:  Like the show? Then why not head over and support me on Patreon....]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 20 Notes - Playing with PLATO</title>
			<pubDate>Wed, 01 Jan 2020 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[e233db8e-0525-4975-9a09-18ad6ba76453]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-20-notes-playing-with-plato]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">PLATO was a groundbreaking project that was started at the University of Illinois in 1960. Over its considerable lifespan it pioneer new technology for computer-aided teaching, time-sharing, and graphics just to name a few fields. On the official side of things it was an educational platform, but unofficially it was a fantastic platform for video games.</span></p> <p><span style="font-weight: 400;">The ultimate iteration of the system, PLATO IV, would be unveiled in 1972. It's new terminals sported a marvelous new invention: the monochrome plasma display. These screens packed a resolution of 512 x 512 pixels, which was pretty respectable for the 70s. On the backend of things PLATO IV terminals all connected up to a powerful supercomputer, forming a centralized network of just over 4000 machines. The graphical and networking capabilities of PLATO made it a ready incubator for many a young hacker. Over the year a multitude of videogames, many of them with networked multiplayer modes, popped up on the system. These included some of the earliest RPGs, arena shooters, even flight simulators.</span></p> <p><span style="font-weight: 400;">I hear you ask, can you experience these games today? Well, you are in luck! There is still a way to access a living PLATO system today. The people over at cyber1.org maintain an emulated PLATO server, and you can even request an account for the system. Coupled with pterm, a PLATO IV terminal emulator, it's relatively easy to get connected. Cyber1 offers a wide range of games and other software from the 70s and beyond.</span></p> <p><span style="font-weight: 400;">There are too many programs, and they are far too varied, to give an overview of them all. Instead I want to focus on a game that stuck out for me: Futurewar. The game was written in 1977, and then eventually restored by the team at cyber1 for it's 40th anniversary in 2017. Futurewar is essentially an RPG, your character starts with random attributes for strength, agility, endurance, intellect and so on. As with a lot of early RPGs you spend most of your time traversing a dungeon, finding money, and fighting monsters. What makes Futurewar stand out is its gameplay and setting.</span></p> <p><span style="font-weight: 400;">First off, Futurewar is presented in 3D from the first person perspective. It may come as a shock, but for PLATO games of this era that isn't unique. A lot of RPGs on the system presented their dungeons in 3D. This isn't something on par with later games like DOOM, but it's definitely impressive for the time it was written. Your view of the game world is rendered as a small portion of the screen, but despite that it's definitely playable. What makes Futurewar stand out from other 3D PLATO games is the fact that you wield a gun and as you travel the maze your gun remains visible at the bottom of your view. There's even a little animation of a bullet when you fire. That's right, Futurewar is a very early example of a first person shooter.</span></p> <p><span style="font-weight: 400;">Second we have the setting of the game. Most of the other 3D RPGs on PLATO were designed as high fantasy adventures. However, Futurewar is different. It's set in the far-flung year of 2020. In the aftermath of a catastrophic war you and your team(humans, guerillas, barbarians, martians, or cyborgs) is battling for control of an underground bunker. The bunker is full of hazards, rubble piles will block your way, radioactive waste will hurt you, and monsters will attack you. Enemies suit the setting, at least somewhat. This includes mutants, giant lice, robots, and skeletons. Defeating monsters earns you money and loot, but you can also find random first aid kits scattered throughout the maze.</span></p> <p><span style="font-weight: 400;">It's a fun game, but it's also pretty hard. I usually die on the first level. The first person view can also be disorienting, you have a limited field of view and the levels are built like a maze. There are no textures so walls look the same, making it easy to get lost. There are the occasional doors, brick walls, and some graffiti, but not enough for me to keep track of where I am without pen and paper. The controls also take some getting used to. Movement is tied to the WAXD keys, with S used to shoot. Menus for in game stats are bound to PALATO's special keys, which pterm maps for you so you don't need an archaic keyboard. Reading the help file (with alt-h) gives you everything you need to know, but it does take some getting used to.</span></p> <p><span style="font-weight: 400;"><img style= "display: block; float: left; border-style: hidden; margin: 10px;" src="https://assets.libsyn.com/secure/show/177941/fw6.png" alt= "Fighting a robot in the bunker." width="256" height= "256" /></span></p> <p><span style="font-weight: 400;"><img style= "float: left; margin: 10px;" src= "https://assets.libsyn.com/secure/show/177941/fw4.png" alt= "Me being killed by a monster." width="256" height="256" /><br /> If you are up for a challenge, or want to experience some early computer games, I'd highly suggest giving cyber1 a look. If you want to dive deeper into PLATO's history then you should pick up a copy of "The Friendly Orange Glow" by Brian Dear. It's proved invaluable to me during my research, and beyond that it's just a great book.</span></p> <p><span style="font-weight: 400;">And if you want to hear more of my take on PLATO, then you can listen to my episode on the topic here:</span></p> <p><a href= "http://adventofcomputing.com/?guid=a9783e2e-dec4-4a11-98d5-f78f818f29c0"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-20-plato-part-2-an-online-revolution/id1459202600?i=1000461074865&ign-mpt=uo%3D4"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/12551204/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>PLATO was a groundbreaking project that was started at the University of Illinois in 1960. Over its considerable lifespan it pioneer new technology for computer-aided teaching, time-sharing, and graphics just to name a few fields. On the official side of things it was an educational platform, but unofficially it was a fantastic platform for video games.</p> <p>The ultimate iteration of the system, PLATO IV, would be unveiled in 1972. It's new terminals sported a marvelous new invention: the monochrome plasma display. These screens packed a resolution of 512 x 512 pixels, which was pretty respectable for the 70s. On the backend of things PLATO IV terminals all connected up to a powerful supercomputer, forming a centralized network of just over 4000 machines. The graphical and networking capabilities of PLATO made it a ready incubator for many a young hacker. Over the year a multitude of videogames, many of them with networked multiplayer modes, popped up on the system. These included some of the earliest RPGs, arena shooters, even flight simulators.</p> <p>I hear you ask, can you experience these games today? Well, you are in luck! There is still a way to access a living PLATO system today. The people over at cyber1.org maintain an emulated PLATO server, and you can even request an account for the system. Coupled with pterm, a PLATO IV terminal emulator, it's relatively easy to get connected. Cyber1 offers a wide range of games and other software from the 70s and beyond.</p> <p>There are too many programs, and they are far too varied, to give an overview of them all. Instead I want to focus on a game that stuck out for me: Futurewar. The game was written in 1977, and then eventually restored by the team at cyber1 for it's 40th anniversary in 2017. Futurewar is essentially an RPG, your character starts with random attributes for strength, agility, endurance, intellect and so on. As with a lot of early RPGs you spend most of your time traversing a dungeon, finding money, and fighting monsters. What makes Futurewar stand out is its gameplay and setting.</p> <p>First off, Futurewar is presented in 3D from the first person perspective. It may come as a shock, but for PLATO games of this era that isn't unique. A lot of RPGs on the system presented their dungeons in 3D. This isn't something on par with later games like DOOM, but it's definitely impressive for the time it was written. Your view of the game world is rendered as a small portion of the screen, but despite that it's definitely playable. What makes Futurewar stand out from other 3D PLATO games is the fact that you wield a gun and as you travel the maze your gun remains visible at the bottom of your view. There's even a little animation of a bullet when you fire. That's right, Futurewar is a very early example of a first person shooter.</p> <p>Second we have the setting of the game. Most of the other 3D RPGs on PLATO were designed as high fantasy adventures. However, Futurewar is different. It's set in the far-flung year of 2020. In the aftermath of a catastrophic war you and your team(humans, guerillas, barbarians, martians, or cyborgs) is battling for control of an underground bunker. The bunker is full of hazards, rubble piles will block your way, radioactive waste will hurt you, and monsters will attack you. Enemies suit the setting, at least somewhat. This includes mutants, giant lice, robots, and skeletons. Defeating monsters earns you money and loot, but you can also find random first aid kits scattered throughout the maze.</p> <p>It's a fun game, but it's also pretty hard. I usually die on the first level. The first person view can also be disorienting, you have a limited field of view and the levels are built like a maze. There are no textures so walls look the same, making it easy to get lost. There are the occasional doors, brick walls, and some graffiti, but not enough for me to keep track of where I am without pen and paper. The controls also take some getting used to. Movement is tied to the WAXD keys, with S used to shoot. Menus for in game stats are bound to PALATO's special keys, which pterm maps for you so you don't need an archaic keyboard. Reading the help file (with alt-h) gives you everything you need to know, but it does take some getting used to.</p> <p></p> <p> If you are up for a challenge, or want to experience some early computer games, I'd highly suggest giving cyber1 a look. If you want to dive deeper into PLATO's history then you should pick up a copy of "The Friendly Orange Glow" by Brian Dear. It's proved invaluable to me during my research, and beyond that it's just a great book.</p> <p>And if you want to hear more of my take on PLATO, then you can listen to my episode on the topic here:</p> <p><a href= "http://adventofcomputing.com/?guid=a9783e2e-dec4-4a11-98d5-f78f818f29c0"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-20-plato-part-2-an-online-revolution/id1459202600?i=1000461074865&ign-mpt=uo%3D4"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[PLATO was a groundbreaking project that was started at the University of Illinois in 1960. Over its considerable lifespan it pioneer new technology for computer-aided teaching, time-sharing, and graphics just to name a few fields. On the official side...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 20 - PLATO Part 2: An Online Revolution</title>
			<itunes:title>PLATO Part 2: An Online Revolution</itunes:title>
			<pubDate>Mon, 30 Dec 2019 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[a9783e2e-dec4-4a11-98d5-f78f818f29c0]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-20-plato-part-2-an-online-revolution]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In the conclusion to our discussion of PLATO we look at the final incarnation of the system: PLATO IV. How did an educational machine turn into one of the earliest online communities? What was it like to use PLATO at it's height? Along the way we will look at the software, hardware, and video games that made PLATO so special.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1964: Plasma Display Patented<br /> 1972: PLATO IV Launches at University of Illinois<br /> 1973: Empire, First MMO, Developed for PLATO IV</p>]]></description>
			<content:encoded><![CDATA[<p>In the conclusion to our discussion of PLATO we look at the final incarnation of the system: PLATO IV. How did an educational machine turn into one of the earliest online communities? What was it like to use PLATO at it's height? Along the way we will look at the software, hardware, and video games that made PLATO so special.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1964: Plasma Display Patented 1972: PLATO IV Launches at University of Illinois 1973: Empire, First MMO, Developed for PLATO IV</p>]]></content:encoded>
			<enclosure length="36151590" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep20_-_PLATO_Part_2.amr" />
			<itunes:duration>37:25</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>gaming,education,videogames,computer,plato</itunes:keywords>
			<itunes:subtitle><![CDATA[In the conclusion to our discussion of PLATO we look at the final incarnation of the system: PLATO IV. How did an educational machine turn into one of the earliest online communities? What was it like to use PLATO at it's height? Along the way we will...]]></itunes:subtitle>
			<itunes:episode>20</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 19 Notes - Early PLATO</title>
			<pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[412110ec-bfb2-43ca-8dd7-664e3d041a6c]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-20-notes-early-plato]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">PLATO(Programmed Logic for Automatic Teaching Operations) was an ambitious project started in 1960 with the goal of revolutionizing learning. And despite massive technical advances made by the project it remains relatively obscure today. It started out small, with just one terminal connected to the University of Illinois' ILLIAC computer, but over time PLATO evolved into a robust computerized teaching platform. Over the projects lifespan there were four major interactions: PLATO I, II, III, and IV. The first two versions were essentially prototypes. PLATO I was the single terminal I described above, PLATO II was similar to the first version but allowed up to two terminals connected to ILLIAC to be used simultaneously. PLATO III was the first version to see actual use in classrooms, with some of the first college courses being offered on the platform in 1965.</span></p> <p><span style="font-weight: 400;">What's so remarkable about PLATO is that fact that it was able to offer a markedly modern experience decades before any other computers could. The later PLATO IV would introduce things like plasma displays, touch screen interfaces, and networked applications and game. As impressive as those advances are, I think PLATO III is a shocking achievement in it's own right that should not be overlooked.</span></p> <p><span style="font-weight: 400;">The core of PLATO III is a mix of old and new technology. Terminals, which connected up to a CDC 1604 mainframe, were actually modified TVs with custom built keysets. Signal flow into the mainframe was relatively simple, each keyboard fed into a multiplexer/switcher then into the computer. The output side of things is a lot more convoluted, but makes a good example of what can be done with limited technology. Two sources were combined to make the final image displayed at any given terminal: a computer controlled slide projector and a storage tube. The slide projector was used as a bit of a work around to avoid loading too much data into limited computer memory, static images could just be turned into slides and loaded up. Some clever programming made it easy to select which slide to display at any given moment. The actual image from the slide was picked up using a scanner. That image was mixed with the image on a storage tube, essentially a CRT tube with that could persist a bitmap image for a short period of time. These tubes were used for more dynamic content that actually needed to be rendered by the computer, and there was a tube dedicated to each terminal. Once mixed together the signal was broadcast over a CCTV setup to it's designated terminal. It made for a robust way to combine graphics and text using the limited computers of the time.</span></p> <p><span style="font-weight: 400;">PLATO III was also remarkable for the fact that it was an early time sharing system. Using an operating system called CATORES, written in house, up to 20 terminals could be used simultaneously. This was developed concurrently to other early time-sharing systems like MIT's CTSS, but what I find interesting is that while MIT had an entire project dedicated to time-sharing for PLATO it was simply a step in the road. That seems to be true of a lot of things developed for PLATO, huge advances were made as a matter of convenience.</span></p> <p>If you want to learn more about the development of PLATO, here is my episode on the topic:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-19-plato-part-1-a-revolution-in-teaching"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-19-plato-part-1-a-revolution-in-teaching/id1459202600?i=1000459702408"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/12402935/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>PLATO(Programmed Logic for Automatic Teaching Operations) was an ambitious project started in 1960 with the goal of revolutionizing learning. And despite massive technical advances made by the project it remains relatively obscure today. It started out small, with just one terminal connected to the University of Illinois' ILLIAC computer, but over time PLATO evolved into a robust computerized teaching platform. Over the projects lifespan there were four major interactions: PLATO I, II, III, and IV. The first two versions were essentially prototypes. PLATO I was the single terminal I described above, PLATO II was similar to the first version but allowed up to two terminals connected to ILLIAC to be used simultaneously. PLATO III was the first version to see actual use in classrooms, with some of the first college courses being offered on the platform in 1965.</p> <p>What's so remarkable about PLATO is that fact that it was able to offer a markedly modern experience decades before any other computers could. The later PLATO IV would introduce things like plasma displays, touch screen interfaces, and networked applications and game. As impressive as those advances are, I think PLATO III is a shocking achievement in it's own right that should not be overlooked.</p> <p>The core of PLATO III is a mix of old and new technology. Terminals, which connected up to a CDC 1604 mainframe, were actually modified TVs with custom built keysets. Signal flow into the mainframe was relatively simple, each keyboard fed into a multiplexer/switcher then into the computer. The output side of things is a lot more convoluted, but makes a good example of what can be done with limited technology. Two sources were combined to make the final image displayed at any given terminal: a computer controlled slide projector and a storage tube. The slide projector was used as a bit of a work around to avoid loading too much data into limited computer memory, static images could just be turned into slides and loaded up. Some clever programming made it easy to select which slide to display at any given moment. The actual image from the slide was picked up using a scanner. That image was mixed with the image on a storage tube, essentially a CRT tube with that could persist a bitmap image for a short period of time. These tubes were used for more dynamic content that actually needed to be rendered by the computer, and there was a tube dedicated to each terminal. Once mixed together the signal was broadcast over a CCTV setup to it's designated terminal. It made for a robust way to combine graphics and text using the limited computers of the time.</p> <p>PLATO III was also remarkable for the fact that it was an early time sharing system. Using an operating system called CATORES, written in house, up to 20 terminals could be used simultaneously. This was developed concurrently to other early time-sharing systems like MIT's CTSS, but what I find interesting is that while MIT had an entire project dedicated to time-sharing for PLATO it was simply a step in the road. That seems to be true of a lot of things developed for PLATO, huge advances were made as a matter of convenience.</p> <p>If you want to learn more about the development of PLATO, here is my episode on the topic:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-19-plato-part-1-a-revolution-in-teaching"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-19-plato-part-1-a-revolution-in-teaching/id1459202600?i=1000459702408"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[PLATO(Programmed Logic for Automatic Teaching Operations) was an ambitious project started in 1960 with the goal of revolutionizing learning. And despite massive technical advances made by the project it remains relatively obscure today. It started...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 19 - PLATO Part 1: A Revolution in Teaching</title>
			<itunes:title>PLATO Part 1: A Revolution in Teaching</itunes:title>
			<pubDate>Mon, 16 Dec 2019 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[7040293d-a854-468b-9ede-b118e04d1344]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-19-plato-part-1-a-revolution-in-teaching]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In  the 1960s a small project started at the University of Illinois. This project, called PLATO, would go on to pioneer a truly impressive amount of new technology, including the first plasma screen, MMO video games, and time-sharing. However, PLATO remains relatively unknown today.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1952: ILLIAC Becomes Operational<br /> 1960: PLATO I Developed<br /> 1961: PLATO II Developed<br /> 1969: PLATO III Developed</p> <p><a href= "http://tee.pub/lic/4jnwv7m_ZPw">http://tee.pub/lic/4jnwv7m_ZPw</a></p>]]></description>
			<content:encoded><![CDATA[<p>In  the 1960s a small project started at the University of Illinois. This project, called PLATO, would go on to pioneer a truly impressive amount of new technology, including the first plasma screen, MMO video games, and time-sharing. However, PLATO remains relatively unknown today.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1952: ILLIAC Becomes Operational 1960: PLATO I Developed 1961: PLATO II Developed 1969: PLATO III Developed</p> <p><a href= "http://tee.pub/lic/4jnwv7m_ZPw">http://tee.pub/lic/4jnwv7m_ZPw</a></p>]]></content:encoded>
			<enclosure length="36971626" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep19_-_PLATO_part_1.amr" />
			<itunes:duration>38:16</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[In  the 1960s a small project started at the University of Illinois. This project, called PLATO, would go on to pioneer a truly impressive amount of new technology, including the first plasma screen, MMO video games, and time-sharing. However,...]]></itunes:subtitle>
			<itunes:episode>19</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 18 Notes - Inside the Mouse</title>
			<pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[eb9badb6-a088-44a0-b493-f65815370b77]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-18-notes-inside-the-mouse]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The computer mouse is one of the most ubiquitous devices in the world. It's the primary way we interact with computers. And it's also one of the longest lived computing devices. Since its invention in the early 1960s the overall design of the computer mouse has changed very little. That being said, there has been incremental improvement to the mouse's internals.</span></p> <p><span style="font-weight: 400;"><img src= "https://assets.libsyn.com/secure/show/177941/first-mouse.jpg" alt= "" width="496" height="385" /></span></p> <p>The earliest mouse was developed by Doug Engelbart and Bill English at the Augmentation Research Lab at Stanford. Right off the bat, the mouse looks reasonably similar to what we are familiar with today: a puck that fits in the hand with buttons(or in this case a single button) on top. However, under the hood we have a rodent of a totally different species. The ARC mouse was actually an analog device: it used two perpendicular wheels connected to potentiometers to measure it's movement across a desk.</p> <p><span style="font-weight: 400;"><img src= "https://assets.libsyn.com/secure/show/177941/star-two-button-ball-mouse.jpg" alt="" width="460" height="349" /></span></p> <p>The next update to the mouse came in 1973 at Xerox with the invention of the ball mouse. This new mouse was designed to be used with the Alto, the first GUI-based computer. The largest external change is the fact that this new Xerox mouse uses a single large ball instead of two perpendicular wheels. The other change was a little more hidden, the new Alto mouse was entirely digital. Instead of using potentiometer to measure movement this new mouse used a set of encoding drums and brushes. The surface of each drum alternated between stripes of conductive and nonconductive material. As the drum spun it would alternate between closing and breaking a circuit with the brush, thus creating a stream of binary data.</p> <p><span style="font-weight: 400;"><img src= "https://assets.libsyn.com/secure/show/177941/54d11d84ef56a_-_gadgets-7-0611-xln.jpg" alt="" width="480" height="552" /></span></p> <p>The final big change, which would become the most popular  design, happened in 1980. This new mouse would be built for the Apple Lisa by Hovey-Kelley Design, an industrial design contractor. On the outside is the same familiar mouse, it even glides over a single ball like the earlier Xerox mouse. There were some changes made to make it a more marketable product, a lot of the design of the Lisa mouse came down to making it cost under $35 to produce. However, the largest change was in how it measured movement: the new mouse used slotted encoder disks and optical pickups instead of drums and brushes. These encoder disks are simply plastic wheels with a pattern of slots cut along there edge, as they spin the disk alternated between blocking and letting light through from an infrared source. The light pattern is then read off by an infrared detector on the other side of the disk. The operating principal is the same as the earlier Xerox mouse but the device is much more durable since there is no contact between the encoding disk and the pickups.</p> <p><span style="font-weight: 400;">If you want to learn more about the history of the mouse, listen to my episode on the matter:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.libsyn.com/episode-18-evolution-of-the-mouse"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-18-evolution-of-the-mouse/id1459202600?i=1000458376550"> Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/12232367/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The computer mouse is one of the most ubiquitous devices in the world. It's the primary way we interact with computers. And it's also one of the longest lived computing devices. Since its invention in the early 1960s the overall design of the computer mouse has changed very little. That being said, there has been incremental improvement to the mouse's internals.</p> <p></p> <p>The earliest mouse was developed by Doug Engelbart and Bill English at the Augmentation Research Lab at Stanford. Right off the bat, the mouse looks reasonably similar to what we are familiar with today: a puck that fits in the hand with buttons(or in this case a single button) on top. However, under the hood we have a rodent of a totally different species. The ARC mouse was actually an analog device: it used two perpendicular wheels connected to potentiometers to measure it's movement across a desk.</p> <p></p> <p>The next update to the mouse came in 1973 at Xerox with the invention of the ball mouse. This new mouse was designed to be used with the Alto, the first GUI-based computer. The largest external change is the fact that this new Xerox mouse uses a single large ball instead of two perpendicular wheels. The other change was a little more hidden, the new Alto mouse was entirely digital. Instead of using potentiometer to measure movement this new mouse used a set of encoding drums and brushes. The surface of each drum alternated between stripes of conductive and nonconductive material. As the drum spun it would alternate between closing and breaking a circuit with the brush, thus creating a stream of binary data.</p> <p></p> <p>The final big change, which would become the most popular  design, happened in 1980. This new mouse would be built for the Apple Lisa by Hovey-Kelley Design, an industrial design contractor. On the outside is the same familiar mouse, it even glides over a single ball like the earlier Xerox mouse. There were some changes made to make it a more marketable product, a lot of the design of the Lisa mouse came down to making it cost under $35 to produce. However, the largest change was in how it measured movement: the new mouse used slotted encoder disks and optical pickups instead of drums and brushes. These encoder disks are simply plastic wheels with a pattern of slots cut along there edge, as they spin the disk alternated between blocking and letting light through from an infrared source. The light pattern is then read off by an infrared detector on the other side of the disk. The operating principal is the same as the earlier Xerox mouse but the device is much more durable since there is no contact between the encoding disk and the pickups.</p> <p>If you want to learn more about the history of the mouse, listen to my episode on the matter:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-18-evolution-of-the-mouse"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-18-evolution-of-the-mouse/id1459202600?i=1000458376550"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The computer mouse is one of the most ubiquitous devices in the world. It's the primary way we interact with computers. And it's also one of the longest lived computing devices. Since its invention in the early 1960s the overall design of the computer...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 18 - Evolution of the Mouse</title>
			<itunes:title>Evolution of the Mouse</itunes:title>
			<pubDate>Mon, 02 Dec 2019 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[e3e451fe-7426-42c4-92c0-5a84f26c8282]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-18-evolution-of-the-mouse]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/b/b/3/9/bb39ac2c27a58bb7/mice.png" />
			<description><![CDATA[<p>The computer mouse is a ubiquitous device, it's also one of the least changed devices we use with a computer. The mice we use today have only seen small incremental improvements since the first mouse was developed. So how did such a long lasting design take shape, and how did it travel the decades up to now?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1961: First Mouse Developed at Engelbart's ARC Lab<br /> 1972: Xerox Develops Rollerball Mouse for Alto<br /> 1979: Apple LISA Mouse Designed</p>]]></description>
			<content:encoded><![CDATA[<p>The computer mouse is a ubiquitous device, it's also one of the least changed devices we use with a computer. The mice we use today have only seen small incremental improvements since the first mouse was developed. So how did such a long lasting design take shape, and how did it travel the decades up to now?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1961: First Mouse Developed at Engelbart's ARC Lab 1972: Xerox Develops Rollerball Mouse for Alto 1979: Apple LISA Mouse Designed</p>]]></content:encoded>
			<enclosure length="32158617" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep18_-_Evolution_of_the_Mouse.amr" />
			<itunes:duration>33:10</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,apple,computer,mouse,xerox,nls</itunes:keywords>
			<itunes:subtitle><![CDATA[The computer mouse is a ubiquitous device, it's also one of the least changed devices we use with a computer. The mice we use today have only seen small incremental improvements since the first mouse was developed. So how did such a long lasting...]]></itunes:subtitle>
			<itunes:episode>18</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 17.5 - Bill's Problem with Piracy</title>
			<itunes:title>Bill's Problem with Piracy</itunes:title>
			<pubDate>Mon, 25 Nov 2019 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[4a1a7b5d-1371-4f48-a26f-f2a3a94aff25]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-175-bills-problem-with-piracy]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In this mini-episode we look at a strange event in Microsoft's early history and their first case of piracy. Along the way you will learn about the best advetrizing campaign in history: the MITS MOBILE Computer Caravan!</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1976: 'Open Letter to Hobbyists' Written by Bill Gates</p> <p><a href= "http://tee.pub/lic/4jnwv7m_ZPw">http://tee.pub/lic/4jnwv7m_ZPw</a></p>]]></description>
			<content:encoded><![CDATA[<p>In this mini-episode we look at a strange event in Microsoft's early history and their first case of piracy. Along the way you will learn about the best advetrizing campaign in history: the MITS MOBILE Computer Caravan!</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1976: 'Open Letter to Hobbyists' Written by Bill Gates</p> <p><a href= "http://tee.pub/lic/4jnwv7m_ZPw">http://tee.pub/lic/4jnwv7m_ZPw</a></p>]]></content:encoded>
			<enclosure length="10250241" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep17.5_-_Bills_Problem_with_Piracy.amr" />
			<itunes:duration>10:26</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>technology,history,microsoft,piracy,computer,gates,basic,altair,mits</itunes:keywords>
			<itunes:subtitle><![CDATA[In this mini-episode we look at a strange event in Microsoft's early history and their first case of piracy. Along the way you will learn about the best advetrizing campaign in history: the MITS MOBILE Computer Caravan! Like the show? Then why not...]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 17 Notes - The Domesday Gallery</title>
			<pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[6bb3e29a-c31e-4fc7-ae8f-90cb44799a4e]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-17-notes-the-domesday-gallery]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The BBC Domesday Project, completed in 1986, is a lot of things. Broken up into two LaserDiscs is a massive volunteer-collected survey of Britain, graphable and searchable census data, high resolution maps, and virtualized 3D tours of selected locations. The entire project blurs the line between time capsule and tech demo. Out of all of the varied media that makes up the Domesday Project my favorite part has to be the "Domesday Gallery".</span></p> <p><iframe src="https://www.youtube.com/embed/Dsbg4COkbD4" width= "560" height="315" frameborder="0" allowfullscreen=""></iframe></p> <p><span style="font-weight: 400;">The Domesday Project was distributed on two discs: the Community and National Discs. The Community Disc was comprised of volunteer survey data consisting of images and writings collected from school children and volunteer groups. This made up a view of "Britain by the British", so to speak. The National Disc was the BBC-curated view of the country and was made up of numeric data, images, short videos, and virtual tours(think Google street view) of parts of the country, called "surrogate walks". The Domesday Gallery was the first thing you saw when loading the National Disc, and it served as an interactive menu for that section of the project.</span></p> <p><span style="font-weight: 400;"><img style= "float: left; margin-left: 10px; margin-right: 10px;" src= "http://www.atsf.co.uk/dottext/images/gallery.gif" alt= "Domesday Gallery map, via atsf.co.uk" width="275" height= "272" /></span></p> <p><span style="font-weight: 400;">To access content on the disc users would walk around the figure 8 shaped virtual gallery. Hanging on the walls were images that users could approach, view, and pull up more information about. Also along the walls of the gallery were doors that took users to the aforementioned surrogate walks, making the gallery a sort of "hub" for users to step into other virtual spaces. For 1986 technology this is all pretty impressive. The computer used for the Domesday Project is a BBC Master, an 8-bit microcomputer with 512 Kb of RAM. It's not a powerful machine by any means, so how was it able to display a virtual world? Well, it comes down to some tricks, and a lot of pre-rendered graphics.</span></p> <p><span style="font-weight: 400;">The computer itself acted as a glorified controller for an accompanying LaserDisc player. The LaserDiscs used for Domesday were in a custom format(LV-ROM) that stored analog images along side a separate digital data track. The magic comes down to that analog track. Higher resolution images were stored as analog data, and the computer could switch the LaserDisc player to any given image on the disc. Then when a user was navigating the gallery or a surrogate walk the computer just had to figure out which image corresponded to the user's current location and display it from the LaserDisc. The images for surrogate walks were, of course, just pictures. The Domesday Gallery part of the disc was built up using pre-rendered 3D graphics.</span></p> <p><span style="font-weight: 400;">So how was the Domesday Gallery rendered? Most of the software for the Domesday Project was written by Logica, a UK based IT firm. They also handled 3D modeling and rendering of the Domesday Gallery. Logica's tool of choice for creating the gallery was a Bosch FGS-4000. And, well, that's where things get a little muddy.</span></p> <p><span style="font-weight: 400;">There isn't much information about the FGS-4000 online. The machine is probably best known for being used to render the music video for Dire Straits' "Money for Nothing", but outside of that it seems pretty obscure. I've been able to find sample images and videos produced on the system, forum posts, and one ad for the machine from Bosch themselves. As near as I can tell the FGS-4000 was part of a range of stand-alone 3D modeling systems built around the Motorola 68000 CPU with some kind of custom graphics hardware. There are a few images floating around of the computer's console(like in the ad), but I haven't been able to track down a picture of the whole system. I'd be interested to learn more about the system, but until then I'll have to mark it down as one more mystery surrounding the BBC's Domesday Project.</span></p> <p><span style="font-weight: 400;"><img style= "display: block; margin-left: auto; margin-right: auto;" src= "https://assets.libsyn.com/secure/show/177941/Screenshot_from_2019-11-19_16-26-27.png" alt="" width="512" height="193" /></span></p> <p><span style="font-weight: 400;">To learn more about the Domesday Project, you can listen to my episode on the topic:</span></p> <p><a href= "http://adventofcomputing.libsyn.com/episode-17-the-bbc-domesday-project"> <span style="font-weight: 400;">Website</span></a> // <a href= "https://podcasts.apple.com/us/podcast/episode-17-the-bbc-domesday-project/id1459202600?i=1000457072680"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/12066662/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The BBC Domesday Project, completed in 1986, is a lot of things. Broken up into two LaserDiscs is a massive volunteer-collected survey of Britain, graphable and searchable census data, high resolution maps, and virtualized 3D tours of selected locations. The entire project blurs the line between time capsule and tech demo. Out of all of the varied media that makes up the Domesday Project my favorite part has to be the "Domesday Gallery".</p> <p></p> <p>The Domesday Project was distributed on two discs: the Community and National Discs. The Community Disc was comprised of volunteer survey data consisting of images and writings collected from school children and volunteer groups. This made up a view of "Britain by the British", so to speak. The National Disc was the BBC-curated view of the country and was made up of numeric data, images, short videos, and virtual tours(think Google street view) of parts of the country, called "surrogate walks". The Domesday Gallery was the first thing you saw when loading the National Disc, and it served as an interactive menu for that section of the project.</p> <p></p> <p>To access content on the disc users would walk around the figure 8 shaped virtual gallery. Hanging on the walls were images that users could approach, view, and pull up more information about. Also along the walls of the gallery were doors that took users to the aforementioned surrogate walks, making the gallery a sort of "hub" for users to step into other virtual spaces. For 1986 technology this is all pretty impressive. The computer used for the Domesday Project is a BBC Master, an 8-bit microcomputer with 512 Kb of RAM. It's not a powerful machine by any means, so how was it able to display a virtual world? Well, it comes down to some tricks, and a lot of pre-rendered graphics.</p> <p>The computer itself acted as a glorified controller for an accompanying LaserDisc player. The LaserDiscs used for Domesday were in a custom format(LV-ROM) that stored analog images along side a separate digital data track. The magic comes down to that analog track. Higher resolution images were stored as analog data, and the computer could switch the LaserDisc player to any given image on the disc. Then when a user was navigating the gallery or a surrogate walk the computer just had to figure out which image corresponded to the user's current location and display it from the LaserDisc. The images for surrogate walks were, of course, just pictures. The Domesday Gallery part of the disc was built up using pre-rendered 3D graphics.</p> <p>So how was the Domesday Gallery rendered? Most of the software for the Domesday Project was written by Logica, a UK based IT firm. They also handled 3D modeling and rendering of the Domesday Gallery. Logica's tool of choice for creating the gallery was a Bosch FGS-4000. And, well, that's where things get a little muddy.</p> <p>There isn't much information about the FGS-4000 online. The machine is probably best known for being used to render the music video for Dire Straits' "Money for Nothing", but outside of that it seems pretty obscure. I've been able to find sample images and videos produced on the system, forum posts, and one ad for the machine from Bosch themselves. As near as I can tell the FGS-4000 was part of a range of stand-alone 3D modeling systems built around the Motorola 68000 CPU with some kind of custom graphics hardware. There are a few images floating around of the computer's console(like in the ad), but I haven't been able to track down a picture of the whole system. I'd be interested to learn more about the system, but until then I'll have to mark it down as one more mystery surrounding the BBC's Domesday Project.</p> <p></p> <p>To learn more about the Domesday Project, you can listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-17-the-bbc-domesday-project"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-17-the-bbc-domesday-project/id1459202600?i=1000457072680"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The BBC Domesday Project, completed in 1986, is a lot of things. Broken up into two LaserDiscs is a massive volunteer-collected survey of Britain, graphable and searchable census data, high resolution maps, and virtualized 3D tours of selected...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 17 - The BBC Domesday Project</title>
			<itunes:title>The BBC Domesday Project</itunes:title>
			<pubDate>Mon, 18 Nov 2019 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[820a3fa9-d6cb-4f71-9c6c-545cd7804b6f]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-17-the-bbc-domesday-project]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/a/a/5/9/aa59b2a5e19b9c7e/domesday.png" />
			<description><![CDATA[<p>In 1086 William the Conqueror <span style= "font-weight: 400;">commissioned</span> a survey of England that would come to be known as the Domesday Book. 900 years later the BBC would create a similar survey, called the Domesday Project. This new survey spanned two LaserDiscs holding over a gigabyte of data and 200,000 images, most of which were collected by students. It presets an amazing time capsule of the UK in 1986. Also contained within the disks were 3D virtual walks of the country side, and an entire computer generated gallery. So how did such strange technology come together to commemorate a 900 year old manuscript?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1986: BBC Domesday Project Released</p>]]></description>
			<content:encoded><![CDATA[<p>In 1086 William the Conqueror commissioned a survey of England that would come to be known as the Domesday Book. 900 years later the BBC would create a similar survey, called the Domesday Project. This new survey spanned two LaserDiscs holding over a gigabyte of data and 200,000 images, most of which were collected by students. It presets an amazing time capsule of the UK in 1986. Also contained within the disks were 3D virtual walks of the country side, and an entire computer generated gallery. So how did such strange technology come together to commemorate a 900 year old manuscript?</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1986: BBC Domesday Project Released</p>]]></content:encoded>
			<enclosure length="32207748" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep17_-_Domesday.amr" />
			<itunes:duration>33:05</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>england,computer,bbc,reality,virtual,vr,domesday,laserdic</itunes:keywords>
			<itunes:subtitle><![CDATA[In 1086 William the Conqueror commissioned a survey of England that would come to be known as the Domesday Book. 900 years later the BBC would create a similar survey, called the Domesday Project. This new survey spanned two LaserDiscs holding over a...]]></itunes:subtitle>
			<itunes:episode>17</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 16 Notes - How Capable was the 4004?</title>
			<pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[d230104687b24c49b26a0879be3e4c21]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-16-notes-how-capable-was-the-4004]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The Intel 4004 was the first commercial microprocessor. There is a lot that can be said about this achievement, but what exactly was the chip like to work with? The fact of the matter is that the 4004 would live it's life as a controller for simple devices, but didn't really show up as a CPU powering computers. It's not really possible to make a definitive conclusion as to why this is, you can't prove a negative. However, I think that the underlying architecture of the chip made it more suitable as a microcontroller-like device rather than a general purpose computer.</span></p> <p><span style="font-weight: 400;">First off, the 4004 is a 4-bit processor. That means that it is primarily designed to work with 4-bit binary numbers. That immediately puts limits on what the chip is capable of, and you can see those limits directly in the pinout. The chip only has 16 pins, so there isn't much space to start work with. The data bus is only 4-bits wide. There are an additional 4 pins that are used in multiplex with the data bus to form an address bus for accessing memory. Technically, the address bus is 12-bits wide, the full address is sent out over 2 successive clock ticks, but it only uses 8 pins. The remaining 8 pins are used to provide power to the chip, reset/test triggering, two clock inputs, and semaphore for controlling memory chips.</span></p> <p><span style="font-weight: 400;">To further complicate things the 4004 isn't a Von Neuman architecture computer. This makes the chip somewhat exotic since most modern computers are Von Neuman architecture machines. That means that, among other things, executable code and generic data are both stored in one shared address space. Instead, the 4004 is closer to a Harvard architecture, it has a separate address space for code and data. While there are some side issues caused by this design choice, the largest problem is that it imposes even more limitations on programmers. The limited memory the chip can address is broken into two smaller segments. You only address up to 640 bytes of memory for data, and 4096 bytes for executable code. That segmentation makes the 4004 look a lot more like a microcontroller than a microprocessor.</span></p> <p><span style="font-weight: 400;">Outside the strange memory mapping you get something a little more familiar. The CPU is register based, with 16 general purpose registers. Each are 4-bits wide, and named R0 through R15. There is an additional 4-bit accumulator for storing the result of calculations and a 12-bit program counter for storing the location of the currently executing instruction. That's all pretty standard, later Intel chips would also be register based. If you've used any x86 chips before, you may see what's missing here. There are no pointer registers. That's because the 4004 doesn't implement any real form of a stack. The only thing that comes close is the internal call stack, which is comprised of three 12-bit registers. You aren't going to be getting anything recursive running on here very easily.</span></p> <p><span style="font-weight: 400;">All tolled, the details of this 4004 make it a reasonable controller for computerized machines but not a very capable general purpose processor. The biggest issue that I can see just from the spec sheet would be implementing any kind of interface beyond a simple front panel. Text processing would be exceedingly difficult. In the now standard ASCII scheme a single character is 8-bits which would take up two registers on the 4004. That means that doing a simple operation like a string compare would take a lot of juggling. Then we run into the issue of having limited space for code, each machine code instruction on the 4004 is either 5 or 8 bits wide. For simplicity, if we say a program is totally composed of 8-bit instructions then we can have, at most, 4096 instructions. That isn't really enough to get much done. That being said, the 4004 is still quite a feat for such an early microprocessor. In the coming years, Intel would put out much more capable chips.</span></p> <p><span style="font-weight: 400;">To learn more about the history of the 4004, you can listen to my episode on the topic <a href= "https://link.chtbl.com/rGm8lozc">here</a>.</span> </p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/11887547/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The Intel 4004 was the first commercial microprocessor. There is a lot that can be said about this achievement, but what exactly was the chip like to work with? The fact of the matter is that the 4004 would live it's life as a controller for simple devices, but didn't really show up as a CPU powering computers. It's not really possible to make a definitive conclusion as to why this is, you can't prove a negative. However, I think that the underlying architecture of the chip made it more suitable as a microcontroller-like device rather than a general purpose computer.</p> <p>First off, the 4004 is a 4-bit processor. That means that it is primarily designed to work with 4-bit binary numbers. That immediately puts limits on what the chip is capable of, and you can see those limits directly in the pinout. The chip only has 16 pins, so there isn't much space to start work with. The data bus is only 4-bits wide. There are an additional 4 pins that are used in multiplex with the data bus to form an address bus for accessing memory. Technically, the address bus is 12-bits wide, the full address is sent out over 2 successive clock ticks, but it only uses 8 pins. The remaining 8 pins are used to provide power to the chip, reset/test triggering, two clock inputs, and semaphore for controlling memory chips.</p> <p>To further complicate things the 4004 isn't a Von Neuman architecture computer. This makes the chip somewhat exotic since most modern computers are Von Neuman architecture machines. That means that, among other things, executable code and generic data are both stored in one shared address space. Instead, the 4004 is closer to a Harvard architecture, it has a separate address space for code and data. While there are some side issues caused by this design choice, the largest problem is that it imposes even more limitations on programmers. The limited memory the chip can address is broken into two smaller segments. You only address up to 640 bytes of memory for data, and 4096 bytes for executable code. That segmentation makes the 4004 look a lot more like a microcontroller than a microprocessor.</p> <p>Outside the strange memory mapping you get something a little more familiar. The CPU is register based, with 16 general purpose registers. Each are 4-bits wide, and named R0 through R15. There is an additional 4-bit accumulator for storing the result of calculations and a 12-bit program counter for storing the location of the currently executing instruction. That's all pretty standard, later Intel chips would also be register based. If you've used any x86 chips before, you may see what's missing here. There are no pointer registers. That's because the 4004 doesn't implement any real form of a stack. The only thing that comes close is the internal call stack, which is comprised of three 12-bit registers. You aren't going to be getting anything recursive running on here very easily.</p> <p>All tolled, the details of this 4004 make it a reasonable controller for computerized machines but not a very capable general purpose processor. The biggest issue that I can see just from the spec sheet would be implementing any kind of interface beyond a simple front panel. Text processing would be exceedingly difficult. In the now standard ASCII scheme a single character is 8-bits which would take up two registers on the 4004. That means that doing a simple operation like a string compare would take a lot of juggling. Then we run into the issue of having limited space for code, each machine code instruction on the 4004 is either 5 or 8 bits wide. For simplicity, if we say a program is totally composed of 8-bit instructions then we can have, at most, 4096 instructions. That isn't really enough to get much done. That being said, the 4004 is still quite a feat for such an early microprocessor. In the coming years, Intel would put out much more capable chips.</p> <p>To learn more about the history of the 4004, you can listen to my episode on the topic <a href= "https://link.chtbl.com/rGm8lozc">here</a>. </p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The Intel 4004 was the first commercial microprocessor. There is a lot that can be said about this achievement, but what exactly was the chip like to work with? The fact of the matter is that the 4004 would live it's life as a controller for simple...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 16 - 4004: The First Microprocessor</title>
			<itunes:title>4004: The First Microprocessor </itunes:title>
			<pubDate>Mon, 04 Nov 2019 00:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[4a53522e9ece45b3ac3666ff260657d5]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-16-4004-the-first-microprocessor]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/3/f/6/43f647c46a771c9b/4004.png" />
			<description><![CDATA[<p>Intel is one of the dominant forces in the computer industry today, they may be most well known for their line of microprocessors. These chips have powered computers going back to the early days of microcomputers. How did Intel become so entrenched in the field? Well, it all started with the 4004 CPU, the first "one-chip" computer.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1971: Intel 4004 Released</p>]]></description>
			<content:encoded><![CDATA[<p>Intel is one of the dominant forces in the computer industry today, they may be most well known for their line of microprocessors. These chips have powered computers going back to the early days of microcomputers. How did Intel become so entrenched in the field? Well, it all started with the 4004 CPU, the first "one-chip" computer.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1971: Intel 4004 Released</p>]]></content:encoded>
			<enclosure length="28691248" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep16_-_4004.amr" />
			<itunes:duration>29:37</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>processor,history,computer,intel,4004</itunes:keywords>
			<itunes:subtitle><![CDATA[Intel is one of the dominant forces in the computer industry today, they may be most well known for their line of microprocessors. These chips have powered computers going back to the early days of microcomputers. How did Intel become so entrenched in...]]></itunes:subtitle>
			<itunes:episode>16</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 15 Notes - Playing Colossal Cave</title>
			<pubDate>Wed, 23 Oct 2019 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[28642c69297244e4a860056800347080]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-15-notes-playing-colossal-cave]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">One of the things that makes Colossal Cave Adventure such an fantastic game is that there are so many ways to play it. The game has been ported to just about any computer you can think of, and that development activity isn't limited to the past. There are quite a few recent web-based ports of the game engine. One my favorite web Adventures can be found here:</span> <a href= "https://github.com/mmastrac/adventure"><span style= "font-weight: 400;">https://github.com/mmastrac/adventure</span></a><span style="font-weight: 400;">. This implementation is relatively new, as of posting it </span></p> <p><span style="font-weight: 400;">looks like code was contributed as recently as 16 days ago. It reimplements the Adventure game engine and but not the original data file, so it's a pretty faithful port.</span></p> <p><span style="font-weight: 400;">Another option is, asl awyas, emulation. If you want to go that route then the Internet Archive is a wonderful resource. Archive.org has an impressive and ever expanding catalog of vintage software. And even better, they have a lot of their software archive available to use in-browser vie emulation. You can play Microsoft's port of Adventure on the Internet Archive here:</span> <a href= "https://archive.org/details/msdos_Microsoft_Adventure_1981"><span style="font-weight: 400;"> https://archive.org/details/msdos_Microsoft_Adventure_1981</span></a><span style="font-weight: 400;">.</span></p> <p><span style="font-weight: 400;">If you want something more niche, the Internet Archive actually has a good number of ports of Adventure that you can run in browser:</span></p> <p><span style="font-weight: 400;">Commodore 64:</span> <a href= "https://archive.org/details/Adventure_64_Colossal_Cave_Adventure_1986_The_Guild_Adventure_Software"> <span style= "font-weight: 400;">https://archive.org/details/Adventure_64_Colossal_Cave_Adventure_1986_The_Guild_Adventure_Software</span></a></p> <p><span style="font-weight: 400;">ZX Spectrum:</span> <a href= "https://archive.org/details/zx_Colossal_Cave_Adventure_v2_1985_Anubis_Software"> <span style= "font-weight: 400;">https://archive.org/details/zx_Colossal_Cave_Adventure_v2_1985_Anubis_Software</span></a></p> <p><span style="font-weight: 400;">Classic Macintosh:</span> <span style="font-weight: 400;"><a href= "https://archive.org/details/mac_Adventure_350_point_James">https://archive.org/details/mac_Adventure_350_point_James</a></span></p> <p><br /> <span style="font-weight: 400;">One final option, but this is only for the truly adventurous. A 1977 copy of the FORTRAN source code for Adventure is available. Both the game's engine and data file are direct from the keyboards of Crowther and Woods, making this the definitive way to experience Colossal Cave Adventure. However, you have to compile it first. And gfortran doesn't seem to like it, so there will probably be a lot of work involved with getting it to run. You can find the 1977 source code here:</span> <span style= "font-weight: 400;"><a href= "http://www.icynic.com/~don/jerz/">http://www.icynic.com/~don/jerz/</a></span></p> <p><span style="font-weight: 400;">To learn more about Colossal Cave Adventure, you can listen to my episode on the topic:</span></p> <p><a href= "http://adventofcomputing.libsyn.com/episode-15-lost-in-the-colossal-cave"> <span style="font-weight: 400;">Website</span></a> // <a href= "https://podcasts.apple.com/us/podcast/episode-15-lost-in-the-colossal-cave/id1459202600?i=1000454236579"> Apple Podcasts</a></p> <p> </p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/11711294/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>One of the things that makes Colossal Cave Adventure such an fantastic game is that there are so many ways to play it. The game has been ported to just about any computer you can think of, and that development activity isn't limited to the past. There are quite a few recent web-based ports of the game engine. One my favorite web Adventures can be found here: <a href= "https://github.com/mmastrac/adventure">https://github.com/mmastrac/adventure</a>. This implementation is relatively new, as of posting it </p> <p>looks like code was contributed as recently as 16 days ago. It reimplements the Adventure game engine and but not the original data file, so it's a pretty faithful port.</p> <p>Another option is, asl awyas, emulation. If you want to go that route then the Internet Archive is a wonderful resource. Archive.org has an impressive and ever expanding catalog of vintage software. And even better, they have a lot of their software archive available to use in-browser vie emulation. You can play Microsoft's port of Adventure on the Internet Archive here: <a href= "https://archive.org/details/msdos_Microsoft_Adventure_1981"> https://archive.org/details/msdos_Microsoft_Adventure_1981</a>.</p> <p>If you want something more niche, the Internet Archive actually has a good number of ports of Adventure that you can run in browser:</p> <p>Commodore 64: <a href= "https://archive.org/details/Adventure_64_Colossal_Cave_Adventure_1986_The_Guild_Adventure_Software"> https://archive.org/details/Adventure_64_Colossal_Cave_Adventure_1986_The_Guild_Adventure_Software</a></p> <p>ZX Spectrum: <a href= "https://archive.org/details/zx_Colossal_Cave_Adventure_v2_1985_Anubis_Software"> https://archive.org/details/zx_Colossal_Cave_Adventure_v2_1985_Anubis_Software</a></p> <p>Classic Macintosh: <a href= "https://archive.org/details/mac_Adventure_350_point_James">https://archive.org/details/mac_Adventure_350_point_James</a></p> <p> One final option, but this is only for the truly adventurous. A 1977 copy of the FORTRAN source code for Adventure is available. Both the game's engine and data file are direct from the keyboards of Crowther and Woods, making this the definitive way to experience Colossal Cave Adventure. However, you have to compile it first. And gfortran doesn't seem to like it, so there will probably be a lot of work involved with getting it to run. You can find the 1977 source code here: <a href= "http://www.icynic.com/~don/jerz/">http://www.icynic.com/~don/jerz/</a></p> <p>To learn more about Colossal Cave Adventure, you can listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-15-lost-in-the-colossal-cave"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-15-lost-in-the-colossal-cave/id1459202600?i=1000454236579"> Apple Podcasts</a></p> <p> </p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[One of the things that makes Colossal Cave Adventure such an fantastic game is that there are so many ways to play it. The game has been ported to just about any computer you can think of, and that development activity isn't limited to the past. There...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 15 - Lost in the Colossal Cave</title>
			<itunes:title>Lost in the Colossal Cave</itunes:title>
			<pubDate>Sun, 20 Oct 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[d14d2be6bd564a74bb99e57729f00574]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-15-lost-in-the-colossal-cave]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>Colossal Cave Adventure is one of the most influential video games of all time. Originally written for the DEC PDP-10 mainframe in 1975 the game has not only spread to just about any computer out there, but it has inspired the entire adventure/RPG genera. In this episode we are going to look at how Adventure got it's start, how it evolved into a full game, and how it came to be a lunch title for the IBM PC.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1975: Colossal Cave Adventure Developed</p> <p><a href= "http://tee.pub/lic/MKt4UiBp22g">http://tee.pub/lic/MKt4UiBp22g</a></p>]]></description>
			<content:encoded><![CDATA[<p>Colossal Cave Adventure is one of the most influential video games of all time. Originally written for the DEC PDP-10 mainframe in 1975 the game has not only spread to just about any computer out there, but it has inspired the entire adventure/RPG genera. In this episode we are going to look at how Adventure got it's start, how it evolved into a full game, and how it came to be a lunch title for the IBM PC.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1975: Colossal Cave Adventure Developed</p> <p><a href= "http://tee.pub/lic/MKt4UiBp22g">http://tee.pub/lic/MKt4UiBp22g</a></p>]]></content:encoded>
			<enclosure length="28033569" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep15_-_Lost_In_The_Colossal_Cave.amr" />
			<itunes:duration>28:57</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>adventure,history,game,computer</itunes:keywords>
			<itunes:subtitle><![CDATA[Colossal Cave Adventure is one of the most influential video games of all time. Originally written for the DEC PDP-10 mainframe in 1975 the game has not only spread to just about any computer out there, but it has inspired the entire adventure/RPG...]]></itunes:subtitle>
			<itunes:episode>15</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 14 Notes - Creeping Towards Viruses</title>
			<pubDate>Wed, 09 Oct 2019 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[7c9203582114439fb4d9e28da67025c5]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-14-notes-creeping-towards-viruses]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Computer viruses in 2019 are a real threat, but that wasn't always the case. In fact, some of the earliest viruses were not even that real. A perfect example of this is</span> <em><span style="font-weight: 400;">The Scarred Man</span></em><span style="font-weight: 400;">, a sci-fi short story written in 1969 by Gregory Benford. First published in Venture Science Fiction in 1970,</span> <em><span style= "font-weight: 400;">The Scarred Man</span></em> <span style= "font-weight: 400;">includes the earliest depiction of a computer virus, right down to the name. And when you get right down to the details what Benford describes sounds shockingly like modern viruses. The program, called "VIRUS", starts out as malicious code hidden on a single computer. It then runs at random intervals and attempts to connect to another computer at random(in the story it's via phone lines). The virus is able to spread quickly and infect many computers causing performance issues on affected systems. No one, besides VIRUS's creators, know the true origin of the plague until long after it has spread.</span></p> <p><span style="font-weight: 400;">The interesting twist is that the programers who made VIRUS go into the business of removing their malicious code from computers, for pay of course.</span> <em><span style="font-weight: 400;">The Scarred Man</span></em> <span style="font-weight: 400;">was met with poor reviews, both by critics and Benford himself. It definitely falls into the category of generic pulp sci-fi. Despite that, it still serves as a good prediction of things to come. If you want to read the story for yourself Benford has a copy of it, complete with author's notes, posted on his website(</span><a href= "http://www.gregorybenford.com/extra/the-scarred-man-returns/"><span style="font-weight: 400;">http://www.gregorybenford.com/extra/the-scarred-man-returns/</span></a><span style="font-weight: 400;">).</span><br />  <br /> <span style="font-weight: 400;">Only a year after</span> <em><span style="font-weight: 400;">The Scarred Man</span></em> <span style="font-weight: 400;">hit shelves the first real virus would be written. This first outing, called Creeper, came about not as an attack but rather as a demonstration program. Originally written by Bob Thomas and later modified by Ray Tomlinson, Creeper was part a larger of distributed computing research effort at BBN in the 70s. The program was first meant as a way to test migrating processes from one machine to another. In this iteration Creeper was a traveling program moving from machine to machine across the ARPANET. Soon after, it was modified to stay on machines it traveled through, and thus Creeper became the world's first virus. But what did it actually do to 'infected' machines? Well, not much. It just printed out "I'M THE CREEPER : CATCH ME IF YOU CAN!".</span></p> <p><span style="font-weight: 400;">If you want to learn more about the early days of the computer virus, you can listen to my episode on the topic:</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.libsyn.com/episode-14-creeping-towards-viruses"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-14-creeping-towards-viruses/id1459202600?i=1000452562392">Apple Podcasts</a></span></p> <p> </p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/11532695/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>Computer viruses in 2019 are a real threat, but that wasn't always the case. In fact, some of the earliest viruses were not even that real. A perfect example of this is <em>The Scarred Man</em>, a sci-fi short story written in 1969 by Gregory Benford. First published in Venture Science Fiction in 1970, <em>The Scarred Man</em> includes the earliest depiction of a computer virus, right down to the name. And when you get right down to the details what Benford describes sounds shockingly like modern viruses. The program, called "VIRUS", starts out as malicious code hidden on a single computer. It then runs at random intervals and attempts to connect to another computer at random(in the story it's via phone lines). The virus is able to spread quickly and infect many computers causing performance issues on affected systems. No one, besides VIRUS's creators, know the true origin of the plague until long after it has spread.</p> <p>The interesting twist is that the programers who made VIRUS go into the business of removing their malicious code from computers, for pay of course. <em>The Scarred Man</em> was met with poor reviews, both by critics and Benford himself. It definitely falls into the category of generic pulp sci-fi. Despite that, it still serves as a good prediction of things to come. If you want to read the story for yourself Benford has a copy of it, complete with author's notes, posted on his website(<a href= "http://www.gregorybenford.com/extra/the-scarred-man-returns/">http://www.gregorybenford.com/extra/the-scarred-man-returns/</a>).   Only a year after <em>The Scarred Man</em> hit shelves the first real virus would be written. This first outing, called Creeper, came about not as an attack but rather as a demonstration program. Originally written by Bob Thomas and later modified by Ray Tomlinson, Creeper was part a larger of distributed computing research effort at BBN in the 70s. The program was first meant as a way to test migrating processes from one machine to another. In this iteration Creeper was a traveling program moving from machine to machine across the ARPANET. Soon after, it was modified to stay on machines it traveled through, and thus Creeper became the world's first virus. But what did it actually do to 'infected' machines? Well, not much. It just printed out "I'M THE CREEPER : CATCH ME IF YOU CAN!".</p> <p>If you want to learn more about the early days of the computer virus, you can listen to my episode on the topic:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-14-creeping-towards-viruses"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-14-creeping-towards-viruses/id1459202600?i=1000452562392">Apple Podcasts</a></p> <p> </p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[Computer viruses in 2019 are a real threat, but that wasn't always the case. In fact, some of the earliest viruses were not even that real. A perfect example of this is The Scarred Man, a sci-fi short story written in 1969 by Gregory Benford. First...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 14 - Creeping Towards Viruses</title>
			<itunes:title>Creeping Towards Viruses</itunes:title>
			<pubDate>Sun, 06 Oct 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[f378989b92544c7d8ebd784a44579bca]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-14-creeping-towards-viruses]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>Computer viruses today pose a very real threat. However, it turns out that their origins are actually very non-threatening. Today, we are going to look at some of the first viruses. We will see how they developed from technical writing, to pulp sci-fi, to traveling code.</p> <p>I talk about <em>The Scarred Man</em> by Gregory Benford in this episode, you can read the full short story here: <a href= "http://www.gregorybenford.com/extra/the-scarred-man-returns/">http://www.gregorybenford.com/extra/the-scarred-man-returns/</a></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1949: John Von Neumann Writes 'Theory and Organization of Complex Automata'<br /> 1969: 'The Scarred Man' Written by Gregory Benford, Coined Term 'Virus'<br /> 1971: Creeper Virus Unleashed</p>]]></description>
			<content:encoded><![CDATA[<p>Computer viruses today pose a very real threat. However, it turns out that their origins are actually very non-threatening. Today, we are going to look at some of the first viruses. We will see how they developed from technical writing, to pulp sci-fi, to traveling code.</p> <p>I talk about <em>The Scarred Man</em> by Gregory Benford in this episode, you can read the full short story here: <a href= "http://www.gregorybenford.com/extra/the-scarred-man-returns/">http://www.gregorybenford.com/extra/the-scarred-man-returns/</a></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1949: John Von Neumann Writes 'Theory and Organization of Complex Automata' 1969: 'The Scarred Man' Written by Gregory Benford, Coined Term 'Virus' 1971: Creeper Virus Unleashed</p>]]></content:encoded>
			<enclosure length="28265954" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep14_-_Creeping_Towards_Viruses.amr" />
			<itunes:duration>29:12</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,computer,virus</itunes:keywords>
			<itunes:subtitle><![CDATA[Computer viruses today pose a very real threat. However, it turns out that their origins are actually very non-threatening. Today, we are going to look at some of the first viruses. We will see how they developed from technical writing, to pulp...]]></itunes:subtitle>
			<itunes:episode>14</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 13.5 - Minitel Research Lab Interview, with Julien Mailland and Kevin Driscoll</title>
			<itunes:title>Minitel Research Lab Interview, with Julien Mailland and Kevin Driscoll</itunes:title>
			<pubDate>Sun, 29 Sep 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[93f7fa456d4443fe9aed814e2de4c7d7]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-135-minitel-research-lab-interview-with-julien-mailland-and-kevin-driscoll]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>Today I am joined by Julien Mailland and Kevon Driscoll, co-authors of Minitel: Welcome to the Internet and proprietors of the Minitel Research Lab(minitel.us). We talk about their book, how they first started working on Minitel terminals, and the ongoing work to preserve Minitel.</p>]]></description>
			<content:encoded><![CDATA[<p>Today I am joined by Julien Mailland and Kevon Driscoll, co-authors of Minitel: Welcome to the Internet and proprietors of the Minitel Research Lab(minitel.us). We talk about their book, how they first started working on Minitel terminals, and the ongoing work to preserve Minitel.</p>]]></content:encoded>
			<enclosure length="32952768" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep13.5_-_Minitel_Interview.amr" />
			<itunes:duration>34:05</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>interview,history,france,computer,minitel</itunes:keywords>
			<itunes:subtitle><![CDATA[Today I am joined by Julien Mailland and Kevon Driscoll, co-authors of Minitel: Welcome to the Internet and proprietors of the Minitel Research Lab(minitel.us). We talk about their book, how they first started working on Minitel terminals, and...]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 13 Notes - Minitel in 2019</title>
			<pubDate>Wed, 25 Sep 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[3040dcd7bd7048278e37aae8e206a096]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-13-notes-minitel-in-2019]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">In the 1980s in France there existed a service that was remarkably similar to the later world wide web. That service was called Minitel. It was first launched in 1980 and continued in use all the way until 2012. During that 32 year span Minitel served as both a network to connect the people of France, and a platform for startups and existing businesses to launch new remote services. Minitel was many things to a lot of people, but as of today the network is gone, and the existing terminals and assorted hardware lay dormant. However, there are ways to experience some of Minitel for yourself, thanks to the work of intrepid hackers and historians.</span></p> <p><span style="font-weight: 400;">One approach to preserving Minitel is to find a way to connect the actual terminals up to some more modern tech. There are a few ways to do that, the easiest being simply sending serial data to the terminal. Most models of Minitel terminals actually had a serial port, so a lot of these types of projects focus on adapting the serial port to a USB interface. Once connected you can feed whatever data you want into the Minitel. </span></p> <p><span style="font-weight: 400;">Another approach is to create your own Minitel server. Now, this is obviously much more complicated than just a serial to USB conversion. This is due to the fact that the network interface on a Minitel terminal is a modem, so you can't just use a web server. One such project, Jelora's Minitel server(</span><a href= "https://www.jelora.fr/post/2017/08/27/Serveur-Minitel.html"><span style="font-weight: 400;">https://www.jelora.fr/post/2017/08/27/Serveur-Minitel.html</span></a><span style="font-weight: 400;">), uses a Raspberry Pi, VoIP line, and a lot of reverse engineering, to recreate a fully functional Minitel service.</span></p> <p><span style="font-weight: 400;">On the other end of the spectrum is emulation. Minitel terminals are such simple devices that they are relatively easy to emulate, even inside a web browser. Sites like</span> <a href="http://www.3614hacker.fr/"><span style= "font-weight: 400;">http://www.3614hacker.fr/</span></a> <span style="font-weight: 400;">and</span> <a href= "http://3611.re/"><span style= "font-weight: 400;">http://3611.re/</span></a> <span style= "font-weight: 400;">let you experience using a Minitel service all inside your browser. Both those services are also available over phone lines using an unmodified Minitel terminal.</span></p> <p><span style="font-weight: 400;">If you want to learn more about Minitel, it's history, and preservation, then I highly recommend checking out the Minitel Research Lab at</span> <a href= "http://mintel.us"><span style= "font-weight: 400;">http://mintel.us</span></a><span style= "font-weight: 400;">, and the labs recent book: "Minitel: Welcome to the Internet".</span></p> <p><span style="font-weight: 400;">And for my thoughts on Minitel, you can listen to Advent of Computing's most recent episode:</span></p> <p><a href= "http://adventofcomputing.libsyn.com/episode-13-minitel-the-french-network-connection"> <span style="font-weight: 400;">Website</span></a> // <a href= "https://podcasts.apple.com/us/podcast/episode-13-minitel-the-french-network-connection/id1459202600?i=1000450786556"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/11341001/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>In the 1980s in France there existed a service that was remarkably similar to the later world wide web. That service was called Minitel. It was first launched in 1980 and continued in use all the way until 2012. During that 32 year span Minitel served as both a network to connect the people of France, and a platform for startups and existing businesses to launch new remote services. Minitel was many things to a lot of people, but as of today the network is gone, and the existing terminals and assorted hardware lay dormant. However, there are ways to experience some of Minitel for yourself, thanks to the work of intrepid hackers and historians.</p> <p>One approach to preserving Minitel is to find a way to connect the actual terminals up to some more modern tech. There are a few ways to do that, the easiest being simply sending serial data to the terminal. Most models of Minitel terminals actually had a serial port, so a lot of these types of projects focus on adapting the serial port to a USB interface. Once connected you can feed whatever data you want into the Minitel. </p> <p>Another approach is to create your own Minitel server. Now, this is obviously much more complicated than just a serial to USB conversion. This is due to the fact that the network interface on a Minitel terminal is a modem, so you can't just use a web server. One such project, Jelora's Minitel server(<a href= "https://www.jelora.fr/post/2017/08/27/Serveur-Minitel.html">https://www.jelora.fr/post/2017/08/27/Serveur-Minitel.html</a>), uses a Raspberry Pi, VoIP line, and a lot of reverse engineering, to recreate a fully functional Minitel service.</p> <p>On the other end of the spectrum is emulation. Minitel terminals are such simple devices that they are relatively easy to emulate, even inside a web browser. Sites like <a href="http://www.3614hacker.fr/">http://www.3614hacker.fr/</a> and <a href= "http://3611.re/">http://3611.re/</a> let you experience using a Minitel service all inside your browser. Both those services are also available over phone lines using an unmodified Minitel terminal.</p> <p>If you want to learn more about Minitel, it's history, and preservation, then I highly recommend checking out the Minitel Research Lab at <a href= "http://mintel.us">http://mintel.us</a>, and the labs recent book: "Minitel: Welcome to the Internet".</p> <p>And for my thoughts on Minitel, you can listen to Advent of Computing's most recent episode:</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-13-minitel-the-french-network-connection"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-13-minitel-the-french-network-connection/id1459202600?i=1000450786556"> Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[In the 1980s in France there existed a service that was remarkably similar to the later world wide web. That service was called Minitel. It was first launched in 1980 and continued in use all the way until 2012. During that 32 year span Minitel served...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 13 - Minitel, the French Network Connection</title>
			<itunes:title>Minitel, the French Network Connection</itunes:title>
			<pubDate>Sun, 22 Sep 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[07a65d5b31c7413382ecca1b91cb13cd]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-13-minitel-the-french-network-connection]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Today we are dipping back into the deep and complex history of the proto-internet. We are going to be looking at Minitel, a France-Wide-Web that was built in the 1980s as a way to help the country stay relevant in the digital age.</span></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1980: Minitel Program Networks France</p>]]></description>
			<content:encoded><![CDATA[<p>Today we are dipping back into the deep and complex history of the proto-internet. We are going to be looking at Minitel, a France-Wide-Web that was built in the 1980s as a way to help the country stay relevant in the digital age.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1980: Minitel Program Networks France</p>]]></content:encoded>
			<enclosure length="28305054" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep13_-_Minitel_the_French_Connection.amr" />
			<itunes:duration>29:14</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>networking,history,france,computer,minitel</itunes:keywords>
			<itunes:subtitle><![CDATA[Today we are dipping back into the deep and complex history of the proto-internet. We are going to be looking at Minitel, a France-Wide-Web that was built in the 1980s as a way to help the country stay relevant in the digital age. Like the show? Then...]]></itunes:subtitle>
			<itunes:episode>13</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 12 Notes - Selling the Altair</title>
			<pubDate>Wed, 11 Sep 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[a3c2eeacf4674f56a8067926b04155ff]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-12-notes-selling-the-altair]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The rise of the MITS Altair 8800, and it's connection to Microsoft, has one key event: the January 1975 issue of Popular Electronics. This article was the first real press for the computer, which created a huge buzz around it's release. It was also how Bill Gates and Paul Allen were first introduced to the Altair, an event that would lead to the founding of Microsoft and the creation of MS BASIC. So what was in the article that launched both the Altair 8800 and inspired Microsoft? Turns out that it was full of a lot of imagination and some not-so-true statements. Essentially, the "article" was just a six page long advertisement.</span></p> <p><img src= "https://assets.libsyn.com/secure/show/177941/PE_Jan_1975_Cover_jpg__12751700_.png" alt="PE Jan1975 Cover" width="566" height="494" /></p> <p><span style="font-weight: 400;">This starts at the cover page. The pictured Altair 8800 looks pretty different from the release models. This could be explained away as the photo using a prototype, but that's not the case. The cover photo is actually of a mostly empty cardboard box. MITS had sent a review model of the Altair to Popular Electronics to be photographed, but somewhere along the way the computer was damaged. So a rough model was made using a cardboard box. The only part of the computer pictured is the lights and switches of the front panel, albeit mounted in a cardboard plate.</span></p> <p> <img src= "https://assets.libsyn.com/secure/show/177941/PE_Jan_1975_pg33_jpg__12751650_.png" alt="PE Jan1975 Title" width="528" height="224" /></p> <p><span style="font-weight: 400;">The actual article isn't much more factual than the cover. The title line boasts "The most powerful minicomputer project ever presented -- can be build for under $400". And, well, even for the time that's just not true. If you want to be nit-picky, the base model of the Altair 8800 sold for $439. Outside of the pedantic, there is a bigger issue in this title. The "under $400" Altair came with 256 bytes of RAM. That's barely enough for a usable program. The article admits the small RAM side, but goes on to say that the Altair "can be economically expanded for 65,000 words". Honestly, I can't understand why they would use "economical" to describe that. A 4k RAM expansion board from MITS cost $264. So to get to 64k(for simplicity) of RAM you need 16 expansion boards. That's $4224 just for the extra RAM, just under ten times as much as the base computer. Adding in the cost of that base computer and adjusting for inflation we get a roughly $22,000 computer. </span></p> <p> </p> <p><span style="font-weight: 400;">The rest of the article explains the basics about the computer kit: parts lists, functional block diagram, a short primer on what a computer is, and a description of how an Altair 8800 is assembled. Hiding in that is one of my favorite infoboxes I've ever read: "Some Applications for the Altair 8800". Like it says in the title, this is a list of ideas for what to do with your new Altair computer. What I find interesting and charming about this list is the sharp discrepancy of complexity. Some of the highlights include...</span></p> <p><img style="float: left;" src= "https://assets.libsyn.com/secure/show/177941/PE_Jan_1975_pg38_jpg__12751650_.png" width="186" height="444" /></p> <p><span style="font-weight: 400;">"Programmable scientific calculator"</span></p> <p><span style="font-weight: 400;">"Digital Signal Generator"</span></p> <p><span style="font-weight: 400;">"Navigation Computer"</span></p> <p><span style="font-weight: 400;">"Signal Analyzer"</span></p> <p><span style="font-weight: 400;">"Digital Filter"</span></p> <p><span style="font-weight: 400;">Those all seem pretty sane, and definitely possible with a base 256 byte Altair. Then you have…</span></p> <p><span style="font-weight: 400;">"Time-sharing Computer" -- In the 70s mainframes were only starting to be able to do this.</span></p> <p><span style="font-weight: 400;">"Patter-Recognition Device" -- That's in the realm of MIT AI Lab research at this time.</span></p> <p><span style="font-weight: 400;">"Smart Computer Terminal" -- The Altair doesn't have any way to interface with a screen or keyboard out of the box.</span></p> <p><span style="font-weight: 400;">"Brain for a Robot" -- ...what?</span></p> <p> </p> <p>If you want to read the article in full, there is a scan available here(<a href= "http://www.swtpc.com/mholley/PopularElectronics/Jan1975/PE_Jan1975.htm">http://www.swtpc.com/mholley/PopularElectronics/Jan1975/PE_Jan1975.htm</a>).</p> <p>And if you want to hear more about the story of the Altair 8800 and Microsoft's first product, you can find my podcast on the matter below.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-12-journey-to-altair">Website</a> // <a href="https://podcasts.apple.com/us/podcast/episode-12-journey-to-altair/id1459202600?i=1000449049417">Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/11166911/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>The rise of the MITS Altair 8800, and it's connection to Microsoft, has one key event: the January 1975 issue of Popular Electronics. This article was the first real press for the computer, which created a huge buzz around it's release. It was also how Bill Gates and Paul Allen were first introduced to the Altair, an event that would lead to the founding of Microsoft and the creation of MS BASIC. So what was in the article that launched both the Altair 8800 and inspired Microsoft? Turns out that it was full of a lot of imagination and some not-so-true statements. Essentially, the "article" was just a six page long advertisement.</p> <p></p> <p>This starts at the cover page. The pictured Altair 8800 looks pretty different from the release models. This could be explained away as the photo using a prototype, but that's not the case. The cover photo is actually of a mostly empty cardboard box. MITS had sent a review model of the Altair to Popular Electronics to be photographed, but somewhere along the way the computer was damaged. So a rough model was made using a cardboard box. The only part of the computer pictured is the lights and switches of the front panel, albeit mounted in a cardboard plate.</p> <p> </p> <p>The actual article isn't much more factual than the cover. The title line boasts "The most powerful minicomputer project ever presented -- can be build for under $400". And, well, even for the time that's just not true. If you want to be nit-picky, the base model of the Altair 8800 sold for $439. Outside of the pedantic, there is a bigger issue in this title. The "under $400" Altair came with 256 bytes of RAM. That's barely enough for a usable program. The article admits the small RAM side, but goes on to say that the Altair "can be economically expanded for 65,000 words". Honestly, I can't understand why they would use "economical" to describe that. A 4k RAM expansion board from MITS cost $264. So to get to 64k(for simplicity) of RAM you need 16 expansion boards. That's $4224 just for the extra RAM, just under ten times as much as the base computer. Adding in the cost of that base computer and adjusting for inflation we get a roughly $22,000 computer. </p> <p> </p> <p>The rest of the article explains the basics about the computer kit: parts lists, functional block diagram, a short primer on what a computer is, and a description of how an Altair 8800 is assembled. Hiding in that is one of my favorite infoboxes I've ever read: "Some Applications for the Altair 8800". Like it says in the title, this is a list of ideas for what to do with your new Altair computer. What I find interesting and charming about this list is the sharp discrepancy of complexity. Some of the highlights include...</p> <p></p> <p>"Programmable scientific calculator"</p> <p>"Digital Signal Generator"</p> <p>"Navigation Computer"</p> <p>"Signal Analyzer"</p> <p>"Digital Filter"</p> <p>Those all seem pretty sane, and definitely possible with a base 256 byte Altair. Then you have…</p> <p>"Time-sharing Computer" -- In the 70s mainframes were only starting to be able to do this.</p> <p>"Patter-Recognition Device" -- That's in the realm of MIT AI Lab research at this time.</p> <p>"Smart Computer Terminal" -- The Altair doesn't have any way to interface with a screen or keyboard out of the box.</p> <p>"Brain for a Robot" -- ...what?</p> <p> </p> <p>If you want to read the article in full, there is a scan available here(<a href= "http://www.swtpc.com/mholley/PopularElectronics/Jan1975/PE_Jan1975.htm">http://www.swtpc.com/mholley/PopularElectronics/Jan1975/PE_Jan1975.htm</a>).</p> <p>And if you want to hear more about the story of the Altair 8800 and Microsoft's first product, you can find my podcast on the matter below.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-12-journey-to-altair">Website</a> // <a href="https://podcasts.apple.com/us/podcast/episode-12-journey-to-altair/id1459202600?i=1000449049417">Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The rise of the MITS Altair 8800, and it's connection to Microsoft, has one key event: the January 1975 issue of Popular Electronics. This article was the first real press for the computer, which created a huge buzz around it's release. It was also...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 12 - Journey to Altair</title>
			<itunes:title>Journey to Altair</itunes:title>
			<pubDate>Sun, 08 Sep 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[d74f4e7f18944c6bb12b85c737d259df]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-12-journey-to-altair]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/6/6/f/2/66f2161a9addc785/altair.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Today we are going to be traveling back to the late 1970s to take a look at the early days of the home computer. And specifically how Microsoft found a foothold at just the right time and place. And for Bill Gates and Paul Allen that would come in the form of BASIC.</span></p> <p><span style="font-weight: 400;">Along the way we will cover the Altair 8800, vaporware, and how Bill Gates violated Harvard student conduct.</span></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1974: Altari 8800 Released<br /> 1975: Microsoft BASIC Released</p>]]></description>
			<content:encoded><![CDATA[<p>Today we are going to be traveling back to the late 1970s to take a look at the early days of the home computer. And specifically how Microsoft found a foothold at just the right time and place. And for Bill Gates and Paul Allen that would come in the form of BASIC.</p> <p>Along the way we will cover the Altair 8800, vaporware, and how Bill Gates violated Harvard student conduct.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1974: Altari 8800 Released 1975: Microsoft BASIC Released</p>]]></content:encoded>
			<enclosure length="31322489" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/e12_-_Journey_To_Altair.amr" />
			<itunes:duration>32:20</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,microsoft,computer,altair</itunes:keywords>
			<itunes:subtitle><![CDATA[How Microsoft First Hit Desks]]></itunes:subtitle>
			<itunes:episode>12</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 11 Notes - Spacewar! Lives!</title>
			<pubDate>Wed, 28 Aug 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[e782e565121a4be0bea8fdc7d52a6d0d]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-11-notes-spacewar-lives]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Spacewar is a remarkable game for a large number of reasons. It was one of the first video games ever made, first conceived by Steven Russel and his colleagues at MIT's AI Lab sometime in 1962. And despite the game's age it presents a core experience not that far off from modern video games. There were numerous firsts to come out of Spacewar. However there are factors outside the game itself that make the story of Spacewar so compelling. One of those factors is the continues efforts at preserving the nearly 60 year old game.</span></p> <p><span style="font-weight: 400;">A lot of early video games, or early programs for that matter, have been lost to time. Luckily, due to Spacewar's popularity and the open nature of the computer scene at the time there were a lot of copies of the game floating around. Both source code and paper tape of the game circulated through institutions all over the country in the 60s. And having access to the software does make preservation easier, but that only solves half the equation. To actually play Spacewar you still need either a running PDP-1 or some kind of replacement.</span></p> <p><span style="font-weight: 400;">The problem here is that only 53 PDP-1s were ever produced. That and the age of the machine makes it no small feat to find a machine. Of the production run only 3 are known to have survived to the modern day, and all of those machines are currently housed at the Computer History Museum in Mountain View. Of those machines, one has been fully restored to working order and is on exhibit. Twice a month, or during special events like the Vintage Computer Festival Far West, the machine gets fired up for public demonstrations. So if you can make it to Mountain View you can get a chance to play Spacewar for yourself on it's original hardware.</span></p> <p><span style="font-weight: 400;">If you can't make it to Silicon Valley, there are still plenty of ways to experience Spacewar. One option is to track down a port or adaptation of the game. But while releases like the 1973 Atari 2600 version or the 1985 of the game are similar to the original, they aren't entirely the same game. For the accurate experience, you need to track down an emulator. Luckily, commonly available multi-system emulators like SIMH and MESS can easily run PDP-1 software. By using an emulator you can faithfully run the original version of Spacewar as written in 1926.</span></p> <p><span style="font-weight: 400;">Lets say you don't want to bother installing MESS, well there are even easier options. More recently JavaScript based PDP-1 emulators have started to appear. This means that you can now play Spacewar in your web browser without needing to install anything. There are a few web pages out there running the game(</span><a href= "https://spacewar.oversigma.com/html5/"><span style= "font-weight: 400;">https://spacewar.oversigma.com/html5/</span></a><span style="font-weight: 400;">,</span> <a href="https://www.masswerk.at/spacewar/"><span style= "font-weight: 400;">https://www.masswerk.at/spacewar/</span></a><span style="font-weight: 400;">). Some even allow you to load and play different versions of Spacewar.</span></p> <p><span style="font-weight: 400;">So why not go play a round or two? After playing Spacewar myself I can tell you it feels shockingly modern, and surprisingly fun.</span></p> <p>To learn more about Spacewar and the dawn of video games, listen to my episode on the topic.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-11-spacewar-the-game">Website</a>//<a href="https://podcasts.apple.com/us/podcast/episode-11-spacewar-the-game/id1459202600?i=1000447784948">Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/10990157/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>Spacewar is a remarkable game for a large number of reasons. It was one of the first video games ever made, first conceived by Steven Russel and his colleagues at MIT's AI Lab sometime in 1962. And despite the game's age it presents a core experience not that far off from modern video games. There were numerous firsts to come out of Spacewar. However there are factors outside the game itself that make the story of Spacewar so compelling. One of those factors is the continues efforts at preserving the nearly 60 year old game.</p> <p>A lot of early video games, or early programs for that matter, have been lost to time. Luckily, due to Spacewar's popularity and the open nature of the computer scene at the time there were a lot of copies of the game floating around. Both source code and paper tape of the game circulated through institutions all over the country in the 60s. And having access to the software does make preservation easier, but that only solves half the equation. To actually play Spacewar you still need either a running PDP-1 or some kind of replacement.</p> <p>The problem here is that only 53 PDP-1s were ever produced. That and the age of the machine makes it no small feat to find a machine. Of the production run only 3 are known to have survived to the modern day, and all of those machines are currently housed at the Computer History Museum in Mountain View. Of those machines, one has been fully restored to working order and is on exhibit. Twice a month, or during special events like the Vintage Computer Festival Far West, the machine gets fired up for public demonstrations. So if you can make it to Mountain View you can get a chance to play Spacewar for yourself on it's original hardware.</p> <p>If you can't make it to Silicon Valley, there are still plenty of ways to experience Spacewar. One option is to track down a port or adaptation of the game. But while releases like the 1973 Atari 2600 version or the 1985 of the game are similar to the original, they aren't entirely the same game. For the accurate experience, you need to track down an emulator. Luckily, commonly available multi-system emulators like SIMH and MESS can easily run PDP-1 software. By using an emulator you can faithfully run the original version of Spacewar as written in 1926.</p> <p>Lets say you don't want to bother installing MESS, well there are even easier options. More recently JavaScript based PDP-1 emulators have started to appear. This means that you can now play Spacewar in your web browser without needing to install anything. There are a few web pages out there running the game(<a href= "https://spacewar.oversigma.com/html5/">https://spacewar.oversigma.com/html5/</a>, <a href="https://www.masswerk.at/spacewar/">https://www.masswerk.at/spacewar/</a>). Some even allow you to load and play different versions of Spacewar.</p> <p>So why not go play a round or two? After playing Spacewar myself I can tell you it feels shockingly modern, and surprisingly fun.</p> <p>To learn more about Spacewar and the dawn of video games, listen to my episode on the topic.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-11-spacewar-the-game">Website</a>//<a href="https://podcasts.apple.com/us/podcast/episode-11-spacewar-the-game/id1459202600?i=1000447784948">Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[Spacewar is a remarkable game for a large number of reasons. It was one of the first video games ever made, first conceived by Steven Russel and his colleagues at MIT's AI Lab sometime in 1962. And despite the game's age it presents a core experience...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 11 - Spacewar! (the Game)</title>
			<itunes:title>Spacewar! (the Game)</itunes:title>
			<pubDate>Sun, 25 Aug 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[db477e96954545d9ac2c8896a7b7efb9]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-11-spacewar-the-game]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">It really seems like in the last decade video games have gone from a somewhat niche hobby to a widespread part of our culture. Nowadays, there are a multitude of ways to get out gaming fix. Consoles, handheld game systems, and even smartphones make video games more accessible than ever. But when and how exactly did video games start to creep into the modern consciousness?</span></p> <p><span style="font-weight: 400;">In this episode we look at some of the earliest video games and how they came to be.</span></p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1962: Spacewar! Developed</p>]]></description>
			<content:encoded><![CDATA[<p>It really seems like in the last decade video games have gone from a somewhat niche hobby to a widespread part of our culture. Nowadays, there are a multitude of ways to get out gaming fix. Consoles, handheld game systems, and even smartphones make video games more accessible than ever. But when and how exactly did video games start to creep into the modern consciousness?</p> <p>In this episode we look at some of the earliest video games and how they came to be.</p> <p>Like the show? Then why not head over and support me on Patreon. Perks include early access to future episodes, and stickers: <a href= "https://www.patreon.com/adventofcomputing">https://www.patreon.com/adventofcomputing</a></p> <p>Important dates in this episode:</p> <p>1962: Spacewar! Developed</p>]]></content:encoded>
			<enclosure length="24009040" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep11_-_Spacewar.amr" />
			<itunes:duration>24:46</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,game,computer,videogame,dec</itunes:keywords>
			<itunes:subtitle><![CDATA[It really seems like in the last decade video games have gone from a somewhat niche hobby to a widespread part of our culture. Nowadays, there are a multitude of ways to get out gaming fix. Consoles, handheld game systems, and even smartphones make...]]></itunes:subtitle>
			<itunes:episode>11</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 10.5 - The Jargon File</title>
			<itunes:title>The Jargon File</itunes:title>
			<pubDate>Sun, 18 Aug 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[dfce8e2fc87d4785baea3e4dfe69fe6e]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-105-the-jargon-file]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In this mini-episode we look at the Jargon File, an early primary source about hacker culture.</p> <p>The most recent version of the file lives here: <a href= "http://catb.org/jargon/html/">http://catb.org/jargon/html/</a></p> <p>If you want more of my voice, I was also recently on the What Do You Do With That podcast talking about restoring an IBM PS/2 Model 25. You can find all their episodes here: <a href= "https://wdydwt.blubrry.net/">https://wdydwt.blubrry.net/</a></p>]]></description>
			<content:encoded><![CDATA[<p>In this mini-episode we look at the Jargon File, an early primary source about hacker culture.</p> <p>The most recent version of the file lives here: <a href= "http://catb.org/jargon/html/">http://catb.org/jargon/html/</a></p> <p>If you want more of my voice, I was also recently on the What Do You Do With That podcast talking about restoring an IBM PS/2 Model 25. You can find all their episodes here: <a href= "https://wdydwt.blubrry.net/">https://wdydwt.blubrry.net/</a></p>]]></content:encoded>
			<enclosure length="10485759" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep10.5_-_The_Jargon_File.amr" />
			<itunes:duration>10:56</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[In this mini-episode we look at the Jargon File, an early primary source about hacker culture. The most recent version of the file lives here:  If you want more of my voice, I was also recently on the What Do You Do With That podcast talking...]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 10 Notes - American Networking</title>
			<pubDate>Wed, 14 Aug 2019 14:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[f718787184f54e78a36bfcb725c06fdf]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-10-notes-american-networking]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">There isn't such a thing as a single event we can point to as the "birth of the internet", but we do get close to an event like that during the Cold War. That was when ARPANET, an early iteration of widespread networking, was designed and built. And while there were an uncounted number of contributors to the design of the final network, I think that the work done by Paul Baran at RAND is an interesting mark of the time that ARPANET came from.</span></p> <p><span style="font-weight: 400;">Paul Baran was a computer scientist working on the problem of reliable networking at RAND in the early 1960s. The RAND Corporation is a civilian company that was started as an offshoot of the US Military with the express purpose of carrying out research for the Armed Forces. So it should come at no surprise that the work Baran was doing would have a militant streak to it. The "reliability" part of his research is much better termed as "survivability", that is investigating how to create a network that could survive an upcoming nuclear war with the Soviet Union. Luckily that war never came, but a lot of the choices that ended up forming into the modern internet came from this mindset.</span></p> <p><span style="font-weight: 400;">In 1964 Baran would release his findings in a massive report, spanning multiple volumes. Inside he detailed a network very similar to the modern internet: a distributed net of computers sending data as binary packets. If you are familiar with networking, then that's basically a point for point description of todays internet. But what's interesting about Baran's work is the intent behind a lot of the choices he made. To underline this I want to quickly go over how Baran himself summarized his RAND report on networking. In the final volume he breaks his findings down to 7 bullet points:</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"1) It appears theoretically possible to build large networks able to withstand heavy damage whether caused by unreliability of components or by enemy attack."</span></em></p> <p><span style="font-weight: 400;">The "enemy attack" here is referenced throughout the paper, and it is made clear that the primary concern if for a nuclear-backed attack on American soil. But the fear of failing components is also relevant, you have to remember this is in an age not far removed from vacuum tubes. In both cases, the redundancy of Baran's proposed distributed network add a layer of safety and reliability.</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"2) Highly reliable and error-free digital communication systems using noisy links and unreliable components can be built without exceeding the present-day state-of-the-art of electronic components--provided we use digital modulation."</span></em></p> <p><span style="font-weight: 400;">It was never a given that any network would be digital, an analog network could have just as easily been proposed in the 50s or 60s. However, digital does have some key advantages specifically for long-distance communication. Since digital signals are effected much less by noise they can be carried by worse lines. In this case, the report is talking about using existing, and noisy, phone lines to carry digital data. Analog simply would have degraded too much over any distance on telephone cables.</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"3) We are beginning to understand, or at least to appreciate, the cause of time delays and overloading phenomena in communication systems handling competing users with different levels of importance. There is a basis for hope that one day we may be able to automate highly sophisticated priority systems. Such systems may even be so effective as to provide the operational equivalent of exercised judgment."</span></em></p> <p><span style="font-weight: 400;">Priority messaging isn't something that really exists in the internet today, but a lot of earlier networks had plans for this feature. Basically, this boils down to the fact that any network at this stage in development would be government funded, and any government wanted to be able to jam through priority messages for time-sensitive stuff(think nuclear launch codes).</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"4) it appears that a proper direction in which to move in attacking the secrecy problem in large military and commercial communication systems, is to design the cryptographic provisions as an integral part of the digital switching system."</span></em></p> <p><span style="font-weight: 400;">This part is interesting to me. Today we have security schemes like SSL/TLS that encrypt data as it's sent over a network, but those standards didn't come into being until the 1990s. But that just hides the data being sent, not where the data is going.</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"5) Digital communication systems able to serve highly automated sources can be more readily designed from the viewpoint of bit-transportation systems rather than the conventional approach of a tandem connection of real-time links."</span></em></p> <p><span style="font-weight: 400;">Digital data is better sent as binary chunks than as an unending stream. This is basically the idea of packet-switching, where a large message is broken down into small packets of data as it's sent and then reassembled. Since digital data can be represented as discrete numbers, you can do this easily and it gives you a lot of flexibility.</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"6) One day in the future (and we are not foolhardy enough to predict an exact date), for economic reasons alone in the military environment it may be necessary to break away from existing analog signal communication network concepts in favor of all-digital networks."</span></em></p> <p><span style="font-weight: 400;">We are solidly in the digital future, but I still don't think anyone can exactly put a date on when we fully migrated away from analog systems. It's wild for me to see a paper from the early 60s that is ostensibly about computing talking about the need to stop using analog systems. This feeds back into the point I was making earlier: it was never a given that the future would be digital.</span></p> <p style="padding-left: 30px;"><em><span style= "font-weight: 400;">"7) It is appropriate to redesign user input-output instruments, such as telephones and teletypewriters, for the described system in order to gain the full benefit that accrues to an all-digital communications network."</span></em></p> <p><span style="font-weight: 400;">This may be my favorite part. Here, Baran is basically saying we will need all new technology to fully utilize an all new network. Instead of thinking about how a digital network could be made to work with existing technology, he is phrasing it as we need to change our current paradigm to work with a new digital network.</span></p> <p><span style="font-weight: 400;">If you want to go deeper down the rabbit hole, the whole report is archived at the Internet Archive(</span><a href= "https://web.archive.org/web/20101228070851/http://www.rand.org/about/history/baran-list.html"><span style="font-weight: 400;">https://web.archive.org/web/20101228070851/http://www.rand.org/about/history/baran-list.html</span></a><span style="font-weight: 400;">) And if you want to hear more about the history of ARPANET, and how America first became networked, then check out my latest episode.</span></p> <p><span style="font-weight: 400;"><a href= "http://adventofcomputing.libsyn.com/episode-10-networking-for-a-nuclear-war-the-americans"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-10-networking-for-a-nuclear-war-the-americans/id1459202600?i=1000446665525">Apple Podcasts</a></span></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/10854209/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p>]]></description>
			<content:encoded><![CDATA[<p>There isn't such a thing as a single event we can point to as the "birth of the internet", but we do get close to an event like that during the Cold War. That was when ARPANET, an early iteration of widespread networking, was designed and built. And while there were an uncounted number of contributors to the design of the final network, I think that the work done by Paul Baran at RAND is an interesting mark of the time that ARPANET came from.</p> <p>Paul Baran was a computer scientist working on the problem of reliable networking at RAND in the early 1960s. The RAND Corporation is a civilian company that was started as an offshoot of the US Military with the express purpose of carrying out research for the Armed Forces. So it should come at no surprise that the work Baran was doing would have a militant streak to it. The "reliability" part of his research is much better termed as "survivability", that is investigating how to create a network that could survive an upcoming nuclear war with the Soviet Union. Luckily that war never came, but a lot of the choices that ended up forming into the modern internet came from this mindset.</p> <p>In 1964 Baran would release his findings in a massive report, spanning multiple volumes. Inside he detailed a network very similar to the modern internet: a distributed net of computers sending data as binary packets. If you are familiar with networking, then that's basically a point for point description of todays internet. But what's interesting about Baran's work is the intent behind a lot of the choices he made. To underline this I want to quickly go over how Baran himself summarized his RAND report on networking. In the final volume he breaks his findings down to 7 bullet points:</p> <p style="padding-left: 30px;"><em>"1) It appears theoretically possible to build large networks able to withstand heavy damage whether caused by unreliability of components or by enemy attack."</em></p> <p>The "enemy attack" here is referenced throughout the paper, and it is made clear that the primary concern if for a nuclear-backed attack on American soil. But the fear of failing components is also relevant, you have to remember this is in an age not far removed from vacuum tubes. In both cases, the redundancy of Baran's proposed distributed network add a layer of safety and reliability.</p> <p style="padding-left: 30px;"><em>"2) Highly reliable and error-free digital communication systems using noisy links and unreliable components can be built without exceeding the present-day state-of-the-art of electronic components--provided we use digital modulation."</em></p> <p>It was never a given that any network would be digital, an analog network could have just as easily been proposed in the 50s or 60s. However, digital does have some key advantages specifically for long-distance communication. Since digital signals are effected much less by noise they can be carried by worse lines. In this case, the report is talking about using existing, and noisy, phone lines to carry digital data. Analog simply would have degraded too much over any distance on telephone cables.</p> <p style="padding-left: 30px;"><em>"3) We are beginning to understand, or at least to appreciate, the cause of time delays and overloading phenomena in communication systems handling competing users with different levels of importance. There is a basis for hope that one day we may be able to automate highly sophisticated priority systems. Such systems may even be so effective as to provide the operational equivalent of exercised judgment."</em></p> <p>Priority messaging isn't something that really exists in the internet today, but a lot of earlier networks had plans for this feature. Basically, this boils down to the fact that any network at this stage in development would be government funded, and any government wanted to be able to jam through priority messages for time-sensitive stuff(think nuclear launch codes).</p> <p style="padding-left: 30px;"><em>"4) it appears that a proper direction in which to move in attacking the secrecy problem in large military and commercial communication systems, is to design the cryptographic provisions as an integral part of the digital switching system."</em></p> <p>This part is interesting to me. Today we have security schemes like SSL/TLS that encrypt data as it's sent over a network, but those standards didn't come into being until the 1990s. But that just hides the data being sent, not where the data is going.</p> <p style="padding-left: 30px;"><em>"5) Digital communication systems able to serve highly automated sources can be more readily designed from the viewpoint of bit-transportation systems rather than the conventional approach of a tandem connection of real-time links."</em></p> <p>Digital data is better sent as binary chunks than as an unending stream. This is basically the idea of packet-switching, where a large message is broken down into small packets of data as it's sent and then reassembled. Since digital data can be represented as discrete numbers, you can do this easily and it gives you a lot of flexibility.</p> <p style="padding-left: 30px;"><em>"6) One day in the future (and we are not foolhardy enough to predict an exact date), for economic reasons alone in the military environment it may be necessary to break away from existing analog signal communication network concepts in favor of all-digital networks."</em></p> <p>We are solidly in the digital future, but I still don't think anyone can exactly put a date on when we fully migrated away from analog systems. It's wild for me to see a paper from the early 60s that is ostensibly about computing talking about the need to stop using analog systems. This feeds back into the point I was making earlier: it was never a given that the future would be digital.</p> <p style="padding-left: 30px;"><em>"7) It is appropriate to redesign user input-output instruments, such as telephones and teletypewriters, for the described system in order to gain the full benefit that accrues to an all-digital communications network."</em></p> <p>This may be my favorite part. Here, Baran is basically saying we will need all new technology to fully utilize an all new network. Instead of thinking about how a digital network could be made to work with existing technology, he is phrasing it as we need to change our current paradigm to work with a new digital network.</p> <p>If you want to go deeper down the rabbit hole, the whole report is archived at the Internet Archive(<a href= "https://web.archive.org/web/20101228070851/http://www.rand.org/about/history/baran-list.html">https://web.archive.org/web/20101228070851/http://www.rand.org/about/history/baran-list.html</a>) And if you want to hear more about the history of ARPANET, and how America first became networked, then check out my latest episode.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-10-networking-for-a-nuclear-war-the-americans"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-10-networking-for-a-nuclear-war-the-americans/id1459202600?i=1000446665525">Apple Podcasts</a></p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[There isn't such a thing as a single event we can point to as the "birth of the internet", but we do get close to an event like that during the Cold War. That was when ARPANET, an early iteration of widespread networking, was designed and built. And...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 10 - Networking for a Nuclear War, the Americans</title>
			<itunes:title>Networking for a Nuclear War, the Americans</itunes:title>
			<pubDate>Sun, 11 Aug 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[383b0aecd5f64271a48d4f385e8c2b05]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-10-networking-for-a-nuclear-war-the-americans]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">In this episode we are going to explore the ARPANET. This is a companion to the last episode, which covered contemporary Soviet attempts to create an early internet.</span></p> <p><span style="font-weight: 400;">Like with last time, today we are still in the Cold War era. Now, this won't be a point by point comparison of Soviet to US networks. They are totally different beasts. Instead, what I want to do is look at how ARPANET was developed, what influenced it, and how it would kick start the creation of the internet.</span></p>]]></description>
			<content:encoded><![CDATA[<p>In this episode we are going to explore the ARPANET. This is a companion to the last episode, which covered contemporary Soviet attempts to create an early internet.</p> <p>Like with last time, today we are still in the Cold War era. Now, this won't be a point by point comparison of Soviet to US networks. They are totally different beasts. Instead, what I want to do is look at how ARPANET was developed, what influenced it, and how it would kick start the creation of the internet.</p>]]></content:encoded>
			<enclosure length="26749386" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep10_-_Networking_for_a_Nuclear_War_the_Americans.amr" />
			<itunes:duration>27:52</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>cold,internet,war,history,computer,arpanet,arpa</itunes:keywords>
			<itunes:subtitle><![CDATA[In this episode we are going to explore the ARPANET. This is a companion to the last episode, which covered contemporary Soviet attempts to create an early internet. Like with last time, today we are still in the Cold War era. Now, this won't be a...]]></itunes:subtitle>
			<itunes:episode>10</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 9 Notes - Soviet Networking</title>
			<pubDate>Wed, 31 Jul 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[71e2f0cd877344fab3cab3bee6d1e1df]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-9-notes-soviet-networking]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">ARPANET was the precursor to the modern internet, or at least the network infrastructure we are familiar with today. The design phase of the project started in the early 1960s, with the first infrastructure being placed in '69. Eventually the project would grow into the internet we know today, but there were earlier attempts at large-scale networks. Specifically, the Soviet Union had a series of attempts at creating nation wide networks going as far back as 1959.</span></p> <p><span style="font-weight: 400;">Some of the first of these networks were military defense and monitoring grids built in the US and the USSR just after WWII. These networks are interesting and deserve their own separate discussion, but they weren't general purpose. Part of what makes the modern internet so important is that it can transfer general data, that and the fact that anyone can get access to the entire network.</span></p> <p><span style="font-weight: 400;">Most Soviet network plans hinged on a crisis occurring just as computers started to hit the Russian scene. The nation was based on a planned economy, in which the government controlled all production and distribution. This is counter to the supply and demand driven market economies of capitalist nations. The goal of a planned economy is to, ideally, create a perfectly efficient economy. Or at least an economy that the government can easily shape. As the name suggests, to do this takes a lot of economic planning. And in the 50s it was becoming clear that human power alone could not create a perfect plan.</span></p> <p><span style="font-weight: 400;">This was around the same time the first computers were being constructed in the Soviet Union. The number-crunching potential of computers offered a new avenue of investigation to put the economy back on track. But it turns out that modeling an entire economy, even backed by computer power, is difficult. To create a perfect model of the whole economy you need perfect information on everything that goes on inside the country. Then to process that information you need a lot of computing power.</span></p> <p><span style="font-weight: 400;">One solution to this problem was to create a massive country-wide network. Pretty soon after the introduction of computers in Russia plans for a network started to be made. Starting in 1959 with Kitov's EASU proposal, and continuing on into the early 70s, some of the best minds in the Soviet Union would offer their own designs on a networked nation.</span></p> <p><span style="font-weight: 400;">The most fruitful of these attempts was Glushkov's OGAS. This was planned to be a decentralized network that would span the entire Soviet Union and be used primarily to collect data on and plan for the economy. The network was laid out in a different way to our current internet. Instead of being distributed as ARPANET would later be designed, OGAS was a 3-tier decentralized system. A central node in Moscow would be connected to a series of regional centers. A final lower tier of access points would connect to the nearby regional nodes.</span></p> <p><span style="font-weight: 400;">A key part of the proposal was to automate away the problems the Soviet government faced, by using a network of computers to generate both economic plans and automatically make government decisions. But outside of that, OGAS was also groundbreaking for being a civilian-accessible network. Access points would be spread through the country allowing Soviet citizens to get online decades before the advent of the internet.</span></p> <p><span style="font-weight: 400;">Ultimately, OGAS and all other attempts failed to take hold. This was due to a lot of factors, including factionalism and resistance inside the Soviet government. It's interesting to think what the modern web would look like if any of these projects had succeeded. </span></p> <p><span style="font-weight: 400;">For an idea of what OGAS may have looked like if fully completed, checkout this map made by u/dom_bul from the ImaginaryMaps subreddit. Note how a series of nodes spread around the nation all connect back to a main computing center in Moscow, as opposed to a more spider-web like network we would see today.</span></p> <p><img src="https://i.redd.it/voxvfirrqzw11.png" alt="" width= "1024" height="821" /></p> <p>To learn more about OGAS and other Soviet networking attempts, check out my episode on the matter. If you still want to dig deeper, I'd highly <span style="font-weight: 400;">recommend</span> "<a href= "https://mitpress.mit.edu/books/how-not-network-nation">How Not to Network a Nation</a>" by Benjamin Peters.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-9-networking-for-a-nuclear-war-the-soviets"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-9-networking-for-a-nuclear-war-the-soviets/id1459202600?i=1000445517878">Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/10684079/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p> <p> </p>]]></description>
			<content:encoded><![CDATA[<p>ARPANET was the precursor to the modern internet, or at least the network infrastructure we are familiar with today. The design phase of the project started in the early 1960s, with the first infrastructure being placed in '69. Eventually the project would grow into the internet we know today, but there were earlier attempts at large-scale networks. Specifically, the Soviet Union had a series of attempts at creating nation wide networks going as far back as 1959.</p> <p>Some of the first of these networks were military defense and monitoring grids built in the US and the USSR just after WWII. These networks are interesting and deserve their own separate discussion, but they weren't general purpose. Part of what makes the modern internet so important is that it can transfer general data, that and the fact that anyone can get access to the entire network.</p> <p>Most Soviet network plans hinged on a crisis occurring just as computers started to hit the Russian scene. The nation was based on a planned economy, in which the government controlled all production and distribution. This is counter to the supply and demand driven market economies of capitalist nations. The goal of a planned economy is to, ideally, create a perfectly efficient economy. Or at least an economy that the government can easily shape. As the name suggests, to do this takes a lot of economic planning. And in the 50s it was becoming clear that human power alone could not create a perfect plan.</p> <p>This was around the same time the first computers were being constructed in the Soviet Union. The number-crunching potential of computers offered a new avenue of investigation to put the economy back on track. But it turns out that modeling an entire economy, even backed by computer power, is difficult. To create a perfect model of the whole economy you need perfect information on everything that goes on inside the country. Then to process that information you need a lot of computing power.</p> <p>One solution to this problem was to create a massive country-wide network. Pretty soon after the introduction of computers in Russia plans for a network started to be made. Starting in 1959 with Kitov's EASU proposal, and continuing on into the early 70s, some of the best minds in the Soviet Union would offer their own designs on a networked nation.</p> <p>The most fruitful of these attempts was Glushkov's OGAS. This was planned to be a decentralized network that would span the entire Soviet Union and be used primarily to collect data on and plan for the economy. The network was laid out in a different way to our current internet. Instead of being distributed as ARPANET would later be designed, OGAS was a 3-tier decentralized system. A central node in Moscow would be connected to a series of regional centers. A final lower tier of access points would connect to the nearby regional nodes.</p> <p>A key part of the proposal was to automate away the problems the Soviet government faced, by using a network of computers to generate both economic plans and automatically make government decisions. But outside of that, OGAS was also groundbreaking for being a civilian-accessible network. Access points would be spread through the country allowing Soviet citizens to get online decades before the advent of the internet.</p> <p>Ultimately, OGAS and all other attempts failed to take hold. This was due to a lot of factors, including factionalism and resistance inside the Soviet government. It's interesting to think what the modern web would look like if any of these projects had succeeded. </p> <p>For an idea of what OGAS may have looked like if fully completed, checkout this map made by u/dom_bul from the ImaginaryMaps subreddit. Note how a series of nodes spread around the nation all connect back to a main computing center in Moscow, as opposed to a more spider-web like network we would see today.</p> <p></p> <p>To learn more about OGAS and other Soviet networking attempts, check out my episode on the matter. If you still want to dig deeper, I'd highly recommend "<a href= "https://mitpress.mit.edu/books/how-not-network-nation">How Not to Network a Nation</a>" by Benjamin Peters.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-9-networking-for-a-nuclear-war-the-soviets"> Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-9-networking-for-a-nuclear-war-the-soviets/id1459202600?i=1000445517878">Apple Podcasts</a></p> <p></p> <p> </p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[ARPANET was the precursor to the modern internet, or at least the network infrastructure we are familiar with today. The design phase of the project started in the early 1960s, with the first infrastructure being placed in '69. Eventually the project...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 9 - Networking for a Nuclear War, the Soviets</title>
			<itunes:title>Networking for a Nuclear War, the Soviets</itunes:title>
			<pubDate>Sun, 28 Jul 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[b2e12985f1884e6087a885a752919ec1]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-9-networking-for-a-nuclear-war-the-soviets]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Often times people assume the US is the homeland of the internet. Funded by the US Department of Defence, the first attempts at a large-scale network were started during the height of the Cold War, and a large part of it's design was redundancy and robust-ness. Some of the researchers were quite frank about it's purpose: to create a network that could survive an upcoming nuclear war. This military-hardened infrastructure was known as ARPANET.</span></p> <p><br /> <span style="font-weight: 400;">But that's only part of the story, and the US wasn't the first to the party. The fact is, the internet</span> <em><span style="font-weight: 400;">was</span></em> <span style="font-weight: 400;">born during the Cold War. This was an era that saw huge advancements in science, both for better and for worse. The space race put humans on the moon, and the nuclear arms race put humans dangerously close to annihilation. So it should be no surprise that America's counterpart in this age, the Soviet Union, was working towards their own proto-internet.</span></p>]]></description>
			<content:encoded><![CDATA[<p>Often times people assume the US is the homeland of the internet. Funded by the US Department of Defence, the first attempts at a large-scale network were started during the height of the Cold War, and a large part of it's design was redundancy and robust-ness. Some of the researchers were quite frank about it's purpose: to create a network that could survive an upcoming nuclear war. This military-hardened infrastructure was known as ARPANET.</p> <p> But that's only part of the story, and the US wasn't the first to the party. The fact is, the internet <em>was</em> born during the Cold War. This was an era that saw huge advancements in science, both for better and for worse. The space race put humans on the moon, and the nuclear arms race put humans dangerously close to annihilation. So it should be no surprise that America's counterpart in this age, the Soviet Union, was working towards their own proto-internet.</p>]]></content:encoded>
			<enclosure length="26543750" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep9_-_Netoworking_for_a_Nuclear_War_Part_1.amr" />
			<itunes:duration>27:39</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>internet,history,union,computer,soviet</itunes:keywords>
			<itunes:subtitle><![CDATA[Often times people assume the US is the homeland of the internet. Funded by the US Department of Defence, the first attempts at a large-scale network were started during the height of the Cold War, and a large part of it's design was redundancy and...]]></itunes:subtitle>
			<itunes:episode>9</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 8 Notes - Literate in the BBC Micro</title>
			<pubDate>Tue, 16 Jul 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[7536a229ea9e4f02a7e756311b4cbc33]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-8-notes-literate-in-the-bbc-micro]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">With the recent release of the Raspberry Pi 4, I thought it would be a good time to go back and look at the system that inspired it: the BBC Micro. First released in 1981, the Micro was part of a largest push from the BBC to educate the public about computing. But, this initiative didn't happen in a vacuum. During the 70s it became clear that cheaply available computer chips would fundamentally change the world economy. The invention of the first microprocessors in '71 paved the way for cheap automation, since a full could be built for a few dollars instead of hundreds of thousands. This quickly lead to large scale unemployment, since many humans could be replaced with a single computerized system.</span></p> <p> </p> <p><span style="font-weight: 400;">In the wake of this the BBC started the Computer Literacy Project. The goal of this program was to help the UK shift into the new computerized job market by training the public, both in and out of the classroom. This initiative was composed of educational materials(books, courses, TV and radio series) focused around a central computer. However, as the BBC was planning the project they ran into the issue of choosing a computer. Short on time(from initial proposal to first launch for the Computer Literacy Project was about 2 years) the BBC needed outside help.</span></p> <p> </p> <p><span style="font-weight: 400;">Through a harrowing bid process Acorn Computers became the manufacturer of choice. Part of this process was creating a working prototype of what would become the BBC Micro. Due to timing constraints Acorn's dev team would end up having only four days to go from rough sketches to a functioning demo-able computer. And amazingly, the accomplished just that. On short order, Acorn had a contract for 12,000 units that would eventually grow to over 1.5 Million shipped BBC Micros.</span></p> <p><span style="font-weight: 400;">An interesting side note is that one of the other companies involved in the BBC's bid was Sinclair. Obviously, they didn't get the contract. The computer Sinclair developed during the BBC bid process would go on to become the Sinclair Spectrum and be a wildly successful and iconic computer in it's own right.</span></p> <p><br /> <span style="font-weight: 400;">The Computer Literacy Project hit the public airwaves in 1982 with</span> <em><span style= "font-weight: 400;">The Computer Programme</span></em><span style= "font-weight: 400;">. This 10 part series would serve as a jumping off point for a much larger endeavour. Over the next 9 years the BBC and its collaborators were able to help shape the curriculum both primary and secondary schools as well as colleges around the country. Via this push and the BBC Micro a whole new generation of programmers were minted.</span></p> <p>To hear more about the BBC Micro and Computer Literacy Project, check out my episode on the topic. Special thanks to Neil from <a href= "https://www.youtube.com/channel/UCLEoyoOKZK0idGqSc6Pi23w">Retro Man Cave</a> for sharing a personal perspective on the matter with me.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-8-acorn-and-the-bbc">Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-8-acorn-and-the-bbc/id1459202600?i=1000444456201"> Apple Podcasts</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/10507685/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p> <p>Initial Computer Literacy Project proposal.</p> <p><em>Alburt, Robert, & Allen, D. (1979) Microelectronics</em></p> <p><br /> Original rough specification form BBC Micro.</p> <p><em>Coll, J. A. (n.d.). Outline specification for the BBC MICROCOMPUTER system. Retrieved from http://www.bbcbasic.co.uk/bbcbasic/beebspec.html</em></p> <p><br /> Interviews with BBC Micro development team.</p> <p><em>News.bbc.co.uk. (2019). BBC NEWS | Technology | BBC Micro ignites memories of revolution. [online] Available at: http://news.bbc.co.uk/2/hi/technology/7307636.stm </em></p> <p><br /> Retrospective and analysis of the Computer Literacy Program and BBC Micro.</p> <p><em>Blyth, Tilly (2012) The Legacy of the BBC Micro. Nesta</em></p>]]></description>
			<content:encoded><![CDATA[<p>With the recent release of the Raspberry Pi 4, I thought it would be a good time to go back and look at the system that inspired it: the BBC Micro. First released in 1981, the Micro was part of a largest push from the BBC to educate the public about computing. But, this initiative didn't happen in a vacuum. During the 70s it became clear that cheaply available computer chips would fundamentally change the world economy. The invention of the first microprocessors in '71 paved the way for cheap automation, since a full could be built for a few dollars instead of hundreds of thousands. This quickly lead to large scale unemployment, since many humans could be replaced with a single computerized system.</p> <p> </p> <p>In the wake of this the BBC started the Computer Literacy Project. The goal of this program was to help the UK shift into the new computerized job market by training the public, both in and out of the classroom. This initiative was composed of educational materials(books, courses, TV and radio series) focused around a central computer. However, as the BBC was planning the project they ran into the issue of choosing a computer. Short on time(from initial proposal to first launch for the Computer Literacy Project was about 2 years) the BBC needed outside help.</p> <p> </p> <p>Through a harrowing bid process Acorn Computers became the manufacturer of choice. Part of this process was creating a working prototype of what would become the BBC Micro. Due to timing constraints Acorn's dev team would end up having only four days to go from rough sketches to a functioning demo-able computer. And amazingly, the accomplished just that. On short order, Acorn had a contract for 12,000 units that would eventually grow to over 1.5 Million shipped BBC Micros.</p> <p>An interesting side note is that one of the other companies involved in the BBC's bid was Sinclair. Obviously, they didn't get the contract. The computer Sinclair developed during the BBC bid process would go on to become the Sinclair Spectrum and be a wildly successful and iconic computer in it's own right.</p> <p> The Computer Literacy Project hit the public airwaves in 1982 with <em>The Computer Programme</em>. This 10 part series would serve as a jumping off point for a much larger endeavour. Over the next 9 years the BBC and its collaborators were able to help shape the curriculum both primary and secondary schools as well as colleges around the country. Via this push and the BBC Micro a whole new generation of programmers were minted.</p> <p>To hear more about the BBC Micro and Computer Literacy Project, check out my episode on the topic. Special thanks to Neil from <a href= "https://www.youtube.com/channel/UCLEoyoOKZK0idGqSc6Pi23w">Retro Man Cave</a> for sharing a personal perspective on the matter with me.</p> <p><a href= "http://adventofcomputing.libsyn.com/episode-8-acorn-and-the-bbc">Website</a> // <a href= "https://podcasts.apple.com/us/podcast/episode-8-acorn-and-the-bbc/id1459202600?i=1000444456201"> Apple Podcasts</a></p> <p></p> <p>Initial Computer Literacy Project proposal.</p> <p><em>Alburt, Robert, & Allen, D. (1979) Microelectronics</em></p> <p> Original rough specification form BBC Micro.</p> <p><em>Coll, J. A. (n.d.). Outline specification for the BBC MICROCOMPUTER system. Retrieved from http://www.bbcbasic.co.uk/bbcbasic/beebspec.html</em></p> <p> Interviews with BBC Micro development team.</p> <p><em>News.bbc.co.uk. (2019). BBC NEWS | Technology | BBC Micro ignites memories of revolution. [online] Available at: http://news.bbc.co.uk/2/hi/technology/7307636.stm </em></p> <p> Retrospective and analysis of the Computer Literacy Program and BBC Micro.</p> <p><em>Blyth, Tilly (2012) The Legacy of the BBC Micro. Nesta</em></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[With the recent release of the Raspberry Pi 4, I thought it would be a good time to go back and look at the system that inspired it: the BBC Micro. First released in 1981, the Micro was part of a largest push from the BBC to educate the public about...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 8 - Acorn and the BBC</title>
			<itunes:title>Acorn and the BBC</itunes:title>
			<pubDate>Sun, 14 Jul 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[12d8cb25bffd4f17abbfffe93c89c2d0]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-8-acorn-and-the-bbc]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The Raspberry Pi had been a huge success at its stated goals, and continues to be. But, this isn't the first time a British company would design and develop a computer as an accessible platform for learning programming. In fact, if you've read much about the Pi then you've probably seen people calling it a "BBC Micro 2".</span></p> <p> </p> <p><span style="font-weight: 400;">So what was the BBC Micro? What did the BBC have to do with creating a new computer? And how is any of this connected to the 21st century version?</span></p> <p> </p> <p><span style="font-weight: 400;">Today I want to share the story from a slice of a somewhat forgotten age: BBC's involvement with Acorn Computers and how they worked together to educate a generation of programmers. Along the way we will see how a small UK company created an impressive series of computers who's legacy may not be known in the States, but has had a surprising impact on the world.</span></p> <p> </p> <p><span style="font-weight: 400;">Special thanks to Neil from Retro Man Cave for sharing his memories of the BBC Micro. You can find him on YouTube here: <a href= "https://www.youtube.com/channel/UCLEoyoOKZK0idGqSc6Pi23w">https://www.youtube.com/channel/UCLEoyoOKZK0idGqSc6Pi23w</a></span></p>]]></description>
			<content:encoded><![CDATA[<p>The Raspberry Pi had been a huge success at its stated goals, and continues to be. But, this isn't the first time a British company would design and develop a computer as an accessible platform for learning programming. In fact, if you've read much about the Pi then you've probably seen people calling it a "BBC Micro 2".</p> <p> </p> <p>So what was the BBC Micro? What did the BBC have to do with creating a new computer? And how is any of this connected to the 21st century version?</p> <p> </p> <p>Today I want to share the story from a slice of a somewhat forgotten age: BBC's involvement with Acorn Computers and how they worked together to educate a generation of programmers. Along the way we will see how a small UK company created an impressive series of computers who's legacy may not be known in the States, but has had a surprising impact on the world.</p> <p> </p> <p>Special thanks to Neil from Retro Man Cave for sharing his memories of the BBC Micro. You can find him on YouTube here: <a href= "https://www.youtube.com/channel/UCLEoyoOKZK0idGqSc6Pi23w">https://www.youtube.com/channel/UCLEoyoOKZK0idGqSc6Pi23w</a></p>]]></content:encoded>
			<enclosure length="29447731" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep8_-_Acorn_and_the_BBC.amr" />
			<itunes:duration>30:41</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,computer,bbc,acorn</itunes:keywords>
			<itunes:subtitle><![CDATA[The Raspberry Pi had been a huge success at its stated goals, and continues to be. But, this isn't the first time a British company would design and develop a computer as an accessible platform for learning programming. In fact, if you've read much...]]></itunes:subtitle>
			<itunes:episode>8</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 7 Notes - PC and the Clone</title>
			<pubDate>Wed, 03 Jul 2019 11:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[c0417aba927c4a5e8f4304a51c20f39b]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-8-notes-pc-and-the-clone]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The IBM PC is, undeniably, one of the most influential computers of all time. It spawned a legacy that goes on to today. Nearly all computers in 2019 are descended from the PC architecture designed at IBM in the 1980s. However, a lot of its spread and rise to power came from outside of IBM. I'm speaking, of course, about PC clone hardware.</span></p> <p><span style="font-weight: 400;">Computer manufacturers scrambled to get a slice of the market in the months following the spectacular release of the IBM PC. The PC was an mostly open platform: it used all off the shelf parts, and all the code and hardware design was published by IBM themselves. However, the BIOS firmware used to manage the low-level functions of the PC was copyrighted. So making a PC clone hinged on being able to circumvent the BIOS copywrite.</span></p> <p><span style="font-weight: 400;">One of the issues I ran into while working on this episode was finding which computer was the definitive first PC clone. A lot of systems are touted as such, but I couldn't find much verification. It seems like the main issue is that most early clone manufacturers were startups or small companies, so only the successful ones like Compaq lived long enough to tell their story. Complicating that is the fact that some of the early clones used BIOS versions that weren't 100% PC compatible, but were advertised as compatible. Others just plain copied IBM's BIOS and were sued over it, such as Eagle and Cordata. The closest I could find to an answer was the Columbia Data Products MPC 1600. That machine was announced in June of 1982, and supposedly had a 100% compatible clean room BIOS. You can even find dumps of it's firmware and run/test it yourself. However, I couldn't find sources confirming much for that computer, or information on it's design process.</span></p> <p><span style="font-weight: 400;">In a "history is written by the victors" type of thing, Compaq has really good documentation of it's PC clone. There is a lot of writing on the Compaq Portable's design process from both in and out of the company. FThe book "Open: How Compaq Ended IBM's PC Domination and Helped Invent Modern Computing" written by Rod Canion, Compaq's co-founder, provides a good narrative of the creation of the Portable including the clean-room BIOS development process. However, it may not be the most neutral source since it is from within Compaq. One thing of note that ties into the muddied waters of PC compatibles in this era is that Rob mentions the MPC 1600 in passing as a incompatible PC clone.</span></p> <p><span style="font-weight: 400;">Once we get out of the 1982/1983 era, the clone market starts to be a little easier to parse out. Partly because all the major players are already established. This is also when Phoenix Technologies hits the scene with their licensable BIOS. Phoenix created a similar clean-room BIOS to Compaq but used a few more safety measures. Their BIOS was written by one programmer who wasn't familiar with the x86 architecture, and Phoenix kept a paper trail of memos with all the information that developer had access to. There are also pretty good primary sources on Phoenix, mainly in the form of articles written around the time their BIOS was released(</span><a href= "https://books.google.com/books?id=zzAEAAAAMBAJ&pg=PA8#v=onepage&q&f=false"><span style="font-weight: 400;">https://books.google.com/books?id=zzAEAAAAMBAJ&pg=PA8#v=onepage&q&f=false</span></a><span style="font-weight: 400;">,</span> <a href= "https://books.google.com/books?id=Bwng8NJ5fesC&lpg=PA6&pg=PA56#v=onepage&q&f=false"> <span style= "font-weight: 400;">https://books.google.com/books?id=Bwng8NJ5fesC&lpg=PA6&pg=PA56#v=onepage&q&f=false</span></a><span style="font-weight: 400;">).</span></p> <p><span style="font-weight: 400;">If you want to hear more of my take on the early era of PC clones and how it changed the computer market, here is my episode covering it:</span></p> <p><a href= "https://podcasts.apple.com/us/podcast/episode-7-attack-of-the-pc-clones/id1459202600?i=1000443280365"> iTunes</a> // <a href= "http://adventofcomputing.libsyn.com/episode-7-attack-of-the-pc-clones"> Website</a></p> <p><iframe style="border: none;" src= "//html5-player.libsyn.com/embed/episode/id/10348745/height/90/theme/custom/thumbnail/yes/direction/backward/render-playlist/no/custom-color/87A93A/" width="100%" height="90" scrolling="no" allowfullscreen= ""></iframe></p> <p> </p>]]></description>
			<content:encoded><![CDATA[<p>The IBM PC is, undeniably, one of the most influential computers of all time. It spawned a legacy that goes on to today. Nearly all computers in 2019 are descended from the PC architecture designed at IBM in the 1980s. However, a lot of its spread and rise to power came from outside of IBM. I'm speaking, of course, about PC clone hardware.</p> <p>Computer manufacturers scrambled to get a slice of the market in the months following the spectacular release of the IBM PC. The PC was an mostly open platform: it used all off the shelf parts, and all the code and hardware design was published by IBM themselves. However, the BIOS firmware used to manage the low-level functions of the PC was copyrighted. So making a PC clone hinged on being able to circumvent the BIOS copywrite.</p> <p>One of the issues I ran into while working on this episode was finding which computer was the definitive first PC clone. A lot of systems are touted as such, but I couldn't find much verification. It seems like the main issue is that most early clone manufacturers were startups or small companies, so only the successful ones like Compaq lived long enough to tell their story. Complicating that is the fact that some of the early clones used BIOS versions that weren't 100% PC compatible, but were advertised as compatible. Others just plain copied IBM's BIOS and were sued over it, such as Eagle and Cordata. The closest I could find to an answer was the Columbia Data Products MPC 1600. That machine was announced in June of 1982, and supposedly had a 100% compatible clean room BIOS. You can even find dumps of it's firmware and run/test it yourself. However, I couldn't find sources confirming much for that computer, or information on it's design process.</p> <p>In a "history is written by the victors" type of thing, Compaq has really good documentation of it's PC clone. There is a lot of writing on the Compaq Portable's design process from both in and out of the company. FThe book "Open: How Compaq Ended IBM's PC Domination and Helped Invent Modern Computing" written by Rod Canion, Compaq's co-founder, provides a good narrative of the creation of the Portable including the clean-room BIOS development process. However, it may not be the most neutral source since it is from within Compaq. One thing of note that ties into the muddied waters of PC compatibles in this era is that Rob mentions the MPC 1600 in passing as a incompatible PC clone.</p> <p>Once we get out of the 1982/1983 era, the clone market starts to be a little easier to parse out. Partly because all the major players are already established. This is also when Phoenix Technologies hits the scene with their licensable BIOS. Phoenix created a similar clean-room BIOS to Compaq but used a few more safety measures. Their BIOS was written by one programmer who wasn't familiar with the x86 architecture, and Phoenix kept a paper trail of memos with all the information that developer had access to. There are also pretty good primary sources on Phoenix, mainly in the form of articles written around the time their BIOS was released(<a href= "https://books.google.com/books?id=zzAEAAAAMBAJ&pg=PA8#v=onepage&q&f=false">https://books.google.com/books?id=zzAEAAAAMBAJ&pg=PA8#v=onepage&q&f=false</a>, <a href= "https://books.google.com/books?id=Bwng8NJ5fesC&lpg=PA6&pg=PA56#v=onepage&q&f=false"> https://books.google.com/books?id=Bwng8NJ5fesC&lpg=PA6&pg=PA56#v=onepage&q&f=false</a>).</p> <p>If you want to hear more of my take on the early era of PC clones and how it changed the computer market, here is my episode covering it:</p> <p><a href= "https://podcasts.apple.com/us/podcast/episode-7-attack-of-the-pc-clones/id1459202600?i=1000443280365"> iTunes</a> // <a href= "http://adventofcomputing.libsyn.com/episode-7-attack-of-the-pc-clones"> Website</a></p> <p></p> <p> </p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The IBM PC is, undeniably, one of the most influential computers of all time. It spawned a legacy that goes on to today. Nearly all computers in 2019 are descended from the PC architecture designed at IBM in the 1980s. However, a lot of its spread and...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 7 - Attack of the PC Clones</title>
			<itunes:title>Attack of the PC Clones</itunes:title>
			<pubDate>Sun, 30 Jun 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[d8976cce80c443d7bbb0eb576d110235]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-7-attack-of-the-pc-clones]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Today, I want to share with you the story of the first PC clones and how they cemented the rise of the x86 chipset.</span></p> <p> </p> <p><span style="font-weight: 400;">Most of this story takes place between 1981 and 1984, but I think it's fair to say that these 3 years are some of the most influential for the PC's rise to domination. So lets start the story with a discussion of the IBM PC, how it was special, and then examine how reverse engineering it lead to the current x86 monoculture we see today.</span></p>]]></description>
			<content:encoded><![CDATA[<p>Today, I want to share with you the story of the first PC clones and how they cemented the rise of the x86 chipset.</p> <p> </p> <p>Most of this story takes place between 1981 and 1984, but I think it's fair to say that these 3 years are some of the most influential for the PC's rise to domination. So lets start the story with a discussion of the IBM PC, how it was special, and then examine how reverse engineering it lead to the current x86 monoculture we see today.</p>]]></content:encoded>
			<enclosure length="22530088" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep7_-_Attack_of_the_PC_Clones.amr" />
			<itunes:duration>23:29</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,pc,computer,ibm</itunes:keywords>
			<itunes:subtitle><![CDATA[Today, I want to share with you the story of the first PC clones and how they cemented the rise of the x86 chipset.   Most of this story takes place between 1981 and 1984, but I think it's fair to say that these 3 years are some of the most...]]></itunes:subtitle>
			<itunes:episode>7</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 6.5 - Edge-Notched</title>
			<itunes:title>Edge-Notched</itunes:title>
			<pubDate>Sun, 23 Jun 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[4f6df5dd432d489db6d2a211bdb45403]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-65-edged-notched]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In this byte-sized episode we look at edge-notched cards. A punch card adjacent technology with a strange connection to the early internet.</p>]]></description>
			<content:encoded><![CDATA[<p>In this byte-sized episode we look at edge-notched cards. A punch card adjacent technology with a strange connection to the early internet.</p>]]></content:encoded>
			<enclosure length="6547329" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep6.5_-_Edge-Notched.amr" />
			<itunes:duration>06:50</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[In this byte-sized episode we look at edge-notched cards. A punch card adjacent technology with a strange connection to the early internet.]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 6 Notes - Digital Voices</title>
			<pubDate>Tue, 18 Jun 2019 23:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[c59af38ed1024dc29a2652d897780db7]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-6-notes-digital-voices]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Modern speech synthesis is impressive, that should go without saying. The fact that a pocket-sized computer can create a voice so close to a real life human is truly a feat of programming. But where did that technology come from?</span></p> <p> </p> <p><span style="font-weight: 400;">There is a rich and long history of humans trying to recreate the sound of our own voices, but for my purposes I'm more interested in the electronic age. Some of the first electronic attempts, started in the 1930s, include devices like the Vocoder and the Voder. These were analog devices that were able to recreate a human voice. In the case of the Vocoder, this was done by encoding a sample of speech. The Voder, on the other hand, was used by "playing" a keyboard to build up voice-like sounds. While the Voder was able to create a human-like voice from scratch, it required a lot of skill and training to use.</span></p> <p> </p> <p><span style="font-weight: 400;">This is characteristic of many early speech synthesis devices. In general, these early attempts are not general purpose or easy to use. It wasn't until the 70s that we would start to see general purpose and easy to use speech synthesis solutions.</span></p> <p> </p> <p><span style="font-weight: 400;">The biggest force behind this shift was Dennis Klatt, and MIT Speech and Hearing researcher. He is one of the key researchers responsible for a dramatic change in the field of speech synthesis. This was to switch to creating holistic models of human speech instead of just trying to imitate the sounds of a vocal tract. In doing so Klatt was able to create much more realistic sounding digital voices.</span></p> <p> </p> <p><span style="font-weight: 400;">Klatt gave the field more than a better talking machine. He also created a pretty comprehensive history of speech synthesis. Part of this is outlined in his paper "Review of text-to-speech conversion for English" (</span><a href= "https://pdfs.semanticscholar.org/5657/f5888e198fecf4612ff04c4b0bdef972147c.pdf"><span style="font-weight: 400;">https://pdfs.semanticscholar.org/5657/f5888e198fecf4612ff04c4b0bdef972147c.pdf</span></a><span style="font-weight: 400;">). It's a little dense if you aren't used to reading academic papers, but in it he describes past attempts at speech synthesis as well as his own and his contemporary's work. The other part of hist documentation was a library of recordings of talking devices, ranging from early mechanical machines to the later DECtalk(a machine using Klatt's own algorithms).</span></p> <p><br /> <span style="font-weight: 400;">Some of these archival recordings can be heard in "Klatt's Last Tapes" (</span><a href= "http://communicationaids.info/history-speech-synthesisers/"><span style="font-weight: 400;">http://communicationaids.info/history-speech-synthesisers/</span></a><span style="font-weight: 400;">), a BBC Radio 4 program that goes over the history of speech synthesis and its use as an aide for people with disabilities.</span></p>]]></description>
			<content:encoded><![CDATA[<p>Modern speech synthesis is impressive, that should go without saying. The fact that a pocket-sized computer can create a voice so close to a real life human is truly a feat of programming. But where did that technology come from?</p> <p> </p> <p>There is a rich and long history of humans trying to recreate the sound of our own voices, but for my purposes I'm more interested in the electronic age. Some of the first electronic attempts, started in the 1930s, include devices like the Vocoder and the Voder. These were analog devices that were able to recreate a human voice. In the case of the Vocoder, this was done by encoding a sample of speech. The Voder, on the other hand, was used by "playing" a keyboard to build up voice-like sounds. While the Voder was able to create a human-like voice from scratch, it required a lot of skill and training to use.</p> <p> </p> <p>This is characteristic of many early speech synthesis devices. In general, these early attempts are not general purpose or easy to use. It wasn't until the 70s that we would start to see general purpose and easy to use speech synthesis solutions.</p> <p> </p> <p>The biggest force behind this shift was Dennis Klatt, and MIT Speech and Hearing researcher. He is one of the key researchers responsible for a dramatic change in the field of speech synthesis. This was to switch to creating holistic models of human speech instead of just trying to imitate the sounds of a vocal tract. In doing so Klatt was able to create much more realistic sounding digital voices.</p> <p> </p> <p>Klatt gave the field more than a better talking machine. He also created a pretty comprehensive history of speech synthesis. Part of this is outlined in his paper "Review of text-to-speech conversion for English" (<a href= "https://pdfs.semanticscholar.org/5657/f5888e198fecf4612ff04c4b0bdef972147c.pdf">https://pdfs.semanticscholar.org/5657/f5888e198fecf4612ff04c4b0bdef972147c.pdf</a>). It's a little dense if you aren't used to reading academic papers, but in it he describes past attempts at speech synthesis as well as his own and his contemporary's work. The other part of hist documentation was a library of recordings of talking devices, ranging from early mechanical machines to the later DECtalk(a machine using Klatt's own algorithms).</p> <p> Some of these archival recordings can be heard in "Klatt's Last Tapes" (<a href= "http://communicationaids.info/history-speech-synthesisers/">http://communicationaids.info/history-speech-synthesisers/</a>), a BBC Radio 4 program that goes over the history of speech synthesis and its use as an aide for people with disabilities.</p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[Modern speech synthesis is impressive, that should go without saying. The fact that a pocket-sized computer can create a voice so close to a real life human is truly a feat of programming. But where did that technology come from?   There is a...]]></itunes:subtitle>
		</item>
		<item>
			<title>Episode 6 - Digital Voices</title>
			<itunes:title>Digital Voices</itunes:title>
			<pubDate>Sun, 16 Jun 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[0a280886745e4dc39686053dd91f535e]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-6-digital-voices]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>What are the origins of our modern day text-to-speech systems? In this episode we will dive into the rich history of electronic talking machines. Along the way I will tell you the story of the vocoder, the first singing computer, and a little about the father of modern synthesized speech.</p>]]></description>
			<content:encoded><![CDATA[<p>What are the origins of our modern day text-to-speech systems? In this episode we will dive into the rich history of electronic talking machines. Along the way I will tell you the story of the vocoder, the first singing computer, and a little about the father of modern synthesized speech.</p>]]></content:encoded>
			<enclosure length="24442252" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep6_-_Digital_Voices.amr" />
			<itunes:duration>25:28</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>technology,history,computer,dectalk</itunes:keywords>
			<itunes:subtitle><![CDATA[What are the origins of our modern day text-to-speech systems? In this episode we will dive into the rich history of electronic talking machines. Along the way I will tell you the story of the vocoder, the first singing computer, and a little about...]]></itunes:subtitle>
			<itunes:episode>6</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 5 Notes - How much has UNIX changed?</title>
			<pubDate>Mon, 03 Jun 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[a50b98d617ee4890b2173db9718707d9]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-5-notes-how-much-has-unix-changed]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">UNIX-like systems have dominated computing for decades, and with the rise of the internet and mobile devices their reach has become even larger. True, most systems now use more modern OSs like Linux, but how much has the UNIX-like landscape changed since the early days?</span></p> <p><span style="font-weight: 400;">So, my question was this: how close is a modern *NIX userland to some of the earliest UNIX releases? To do this I'm going to compare a few key points of a modern Linux system with the earliest UNIX documentation I can get my hands on. The doc I am going to be covering(</span><a href= "https://www.tuhs.org/Archive/Distributions/Research/Dennis_v1/UNIX_ProgrammersManual_Nov71.pdf"><span style="font-weight: 400;">https://www.tuhs.org/Archive/Distributions/Research/Dennis_v1/UNIX_ProgrammersManual_Nov71.pdf</span></a><span style="font-weight: 400;">) is from November 1971, predating v1 of the system.</span></p> <p><span style="font-weight: 400;">I think the best place to start this comparison is to look at one of the highest-profile parts of the OS, that being the file system. Under the hood modern EXT file systems are completely different from the early UNIX file systems. However, they are still presented in basically the same way, as a heirerarchicat structure of directories with device files. So paths still look identical, and navigating the file system still functions the same. Often used commands like `ls`, `cp`, `mv`, `du`, and `df` function the same. So are `mount` and `umount`. But, there are some key differences. For instance, `cd` didn't exist, yet instead `chdir` filled its place. Also, `chmod` is somewhat different. Instead of the usual 3-digit octal codes for permissions, this older version only uses 2 digits. Really, that difference is due to the underlying file system using a different permission set than modern systems. For the most part, all the file handling is actually pretty close to a Linux system from 2019.</span></p> <p><span style="font-weight: 400;">The other really high-profile part of any *NIX system in the shell. This '71 version of UNIX already has a user-land shell: `sh`. A lot of Linux distros actually still default to using a much newer version of `sh`. But, the question is how much of that shell was already set in stone in the early 70s? Surprisingly, a lot. The basic layout of commands is totally unchanges: command followed by arguments and switches. Both `;` and `&` still function as command separators. File input and output redirects are still represented with `<` and `>` respectively. The biggest difference is there are no pipes, those won't appear on UNIX until at least 1973. Also, `sh` can already run script files in '71. Overall, I'm shocked by how similar the shell seems to today's version.</span></p> <p><span style="font-weight: 400;">So superficially, this pre-release of UNIX looks remarkably close to a modern system. But what about programming utilities? This is where some big changes start to appear. First off, you won't find any C compiler here. UNIX wouldn't switch from assembly to C for another few years. I decided for this comparison to take a look at a fresh Debian 9.9.0 install(released April, 2019). The assembler, `as` still exists, but obviously for a different target than the PDP-11 used in '71. A liniker, `ld`, is still present and accounted for today. However, text editor, `ed`, is nowhere to be found in Debian. The same goes for the FORTRAN compiler `for`, nowadays `for` is used for loops instead of compiling mathematics programs. Something that surprised me to even see in the UNIX documentation was `bas`, a basic interpreter. Obviously, `bas` is not in the standard Debian install list today. Another relic is the `B` compiler described in the documentation(Just as a side note, in the command index it shows a lowercase `b` but capitalizes it in the actual man page).</span></p> <p><span style="font-weight: 400;">Overall, it would appear that the core UNIX-like experience has changed little. A lot of the tech under the hood has been completely revamped many times over, but the core way we interact with the system and most of the commands that come stock have remained the same since the 1970s. As a final note, I was blown away by just how much the very earliest man pages resemble current man pages. As an example, here is a side-by-side of `ls` from 1971 on the left, and `man ls` from Debian 9.9.0 on the right.</span></p> <p> </p> <p><img src= "https://assets.libsyn.com/secure/show/177941/ls_1971.png" alt="" width="1000" height="473" /></p>]]></description>
			<content:encoded><![CDATA[<p>UNIX-like systems have dominated computing for decades, and with the rise of the internet and mobile devices their reach has become even larger. True, most systems now use more modern OSs like Linux, but how much has the UNIX-like landscape changed since the early days?</p> <p>So, my question was this: how close is a modern *NIX userland to some of the earliest UNIX releases? To do this I'm going to compare a few key points of a modern Linux system with the earliest UNIX documentation I can get my hands on. The doc I am going to be covering(<a href= "https://www.tuhs.org/Archive/Distributions/Research/Dennis_v1/UNIX_ProgrammersManual_Nov71.pdf">https://www.tuhs.org/Archive/Distributions/Research/Dennis_v1/UNIX_ProgrammersManual_Nov71.pdf</a>) is from November 1971, predating v1 of the system.</p> <p>I think the best place to start this comparison is to look at one of the highest-profile parts of the OS, that being the file system. Under the hood modern EXT file systems are completely different from the early UNIX file systems. However, they are still presented in basically the same way, as a heirerarchicat structure of directories with device files. So paths still look identical, and navigating the file system still functions the same. Often used commands like `ls`, `cp`, `mv`, `du`, and `df` function the same. So are `mount` and `umount`. But, there are some key differences. For instance, `cd` didn't exist, yet instead `chdir` filled its place. Also, `chmod` is somewhat different. Instead of the usual 3-digit octal codes for permissions, this older version only uses 2 digits. Really, that difference is due to the underlying file system using a different permission set than modern systems. For the most part, all the file handling is actually pretty close to a Linux system from 2019.</p> <p>The other really high-profile part of any *NIX system in the shell. This '71 version of UNIX already has a user-land shell: `sh`. A lot of Linux distros actually still default to using a much newer version of `sh`. But, the question is how much of that shell was already set in stone in the early 70s? Surprisingly, a lot. The basic layout of commands is totally unchanges: command followed by arguments and switches. Both `;` and `&` still function as command separators. File input and output redirects are still represented with `` respectively. The biggest difference is there are no pipes, those won't appear on UNIX until at least 1973. Also, `sh` can already run script files in '71. Overall, I'm shocked by how similar the shell seems to today's version.</p> <p>So superficially, this pre-release of UNIX looks remarkably close to a modern system. But what about programming utilities? This is where some big changes start to appear. First off, you won't find any C compiler here. UNIX wouldn't switch from assembly to C for another few years. I decided for this comparison to take a look at a fresh Debian 9.9.0 install(released April, 2019). The assembler, `as` still exists, but obviously for a different target than the PDP-11 used in '71. A liniker, `ld`, is still present and accounted for today. However, text editor, `ed`, is nowhere to be found in Debian. The same goes for the FORTRAN compiler `for`, nowadays `for` is used for loops instead of compiling mathematics programs. Something that surprised me to even see in the UNIX documentation was `bas`, a basic interpreter. Obviously, `bas` is not in the standard Debian install list today. Another relic is the `B` compiler described in the documentation(Just as a side note, in the command index it shows a lowercase `b` but capitalizes it in the actual man page).</p> <p>Overall, it would appear that the core UNIX-like experience has changed little. A lot of the tech under the hood has been completely revamped many times over, but the core way we interact with the system and most of the commands that come stock have remained the same since the 1970s. As a final note, I was blown away by just how much the very earliest man pages resemble current man pages. As an example, here is a side-by-side of `ls` from 1971 on the left, and `man ls` from Debian 9.9.0 on the right.</p> <p> </p> <p></p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[UNIX-like systems have dominated computing for decades, and with the rise of the internet and mobile devices their reach has become even larger. True, most systems now use more modern OSs like Linux, but how much has the UNIX-like landscape changed...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 5 - Unix for the People, Part 2</title>
			<itunes:title>Unix for the People, Part 2</itunes:title>
			<pubDate>Sun, 02 Jun 2019 23:30:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[a93ec83c74084b2ca5144a83da017f6e]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-5-unix-for-the-people-part-2]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Now, as the name suggests this is the second part of a series on the history of UNIX. Part 1 mainly covers the background leading up to UNIX. If you haven't listened to it yet, I strongly suggest you go do that now. A lot of what was covered in part 1 provides needed context for our discussion today.</span></p> <p> </p> <p><span style="font-weight: 400;">Just as a quick recap, last time I told you about CTSS and Multics, two of the earliest time-sharing operating systems. Today, we are going to be picking up where we left off: Bell Labs just left Project MAC and decided to start their own time-sharing project. What they didn't realize was that this new project, called UNIX, would soon outshine all of its predecessors. But when this all started, in 1969 on a spare mainframe at Bell Labs, there was no hint at it's amazing future.</span></p>]]></description>
			<content:encoded><![CDATA[<p>Now, as the name suggests this is the second part of a series on the history of UNIX. Part 1 mainly covers the background leading up to UNIX. If you haven't listened to it yet, I strongly suggest you go do that now. A lot of what was covered in part 1 provides needed context for our discussion today.</p> <p> </p> <p>Just as a quick recap, last time I told you about CTSS and Multics, two of the earliest time-sharing operating systems. Today, we are going to be picking up where we left off: Bell Labs just left Project MAC and decided to start their own time-sharing project. What they didn't realize was that this new project, called UNIX, would soon outshine all of its predecessors. But when this all started, in 1969 on a spare mainframe at Bell Labs, there was no hint at it's amazing future.</p>]]></content:encoded>
			<enclosure length="28745559" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep5_-_Unix_for_the_people_Part_2.amr" />
			<itunes:duration>29:57</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>linux,history,computer,unix</itunes:keywords>
			<itunes:subtitle><![CDATA[Now, as the name suggests this is the second part of a series on the history of UNIX. Part 1 mainly covers the background leading up to UNIX. If you haven't listened to it yet, I strongly suggest you go do that now. A lot of what was covered in part 1...]]></itunes:subtitle>
			<itunes:episode>5</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 4.5 - Space Travel!</title>
			<itunes:title>Space Travel!</itunes:title>
			<pubDate>Mon, 27 May 2019 11:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[cc66051270b44671860e17be39361e7d]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-45-space-travel]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>In this mini-episode we talk about Space Travel, an obscure video game from 1969.</p>]]></description>
			<content:encoded><![CDATA[<p>In this mini-episode we talk about Space Travel, an obscure video game from 1969.</p>]]></content:encoded>
			<enclosure length="5625729" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep4.5_Space_Travel.amr" />
			<itunes:duration>05:52</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>history,videogames,computer</itunes:keywords>
			<itunes:subtitle><![CDATA[A byte-sized episode]]></itunes:subtitle>
			<itunes:episodeType>bonus</itunes:episodeType>
		</item>
		<item>
			<title>Episode 4 Notes - Timesharing</title>
			<pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[3bd3668f843b42309ec22292da64e29d]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-4-notes-timesharing]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">If you've read much about the early spread of computer use, then you have probably heard the of "time-sharing systems". But what exactly is time-sharing, and what has it turned into in the modern day? To put it simply, time-sharing is one method that was used to allow multiple users to share a single computer. So, why was this idea a big deal?</span></p> <p> </p> <p><span style="font-weight: 400;">At the dawn of the computing era all systems were mainframes: prohibitively expensive machines the size of entire rooms. To use one of these computers you would have to load up your program on punch cards and go down to the computer department at your institution or business. Once there your stack of punch cards would be submitted to another person who would schedule out on a calendar when your program could run and when you could expect it's outputs. Not really a streamlined or very interactive process. This did change somewhat  as teletype terminals started to hit the scene, but this still just let one user on the system at a time.</span></p> <p> </p> <p><span style="font-weight: 400;">Time-sharing had been talked about as early as 1954 by Jack Backus at the MIT Summer Session. Backus posited that "by time sharing, a big computer could be used as several small ones; there would need to be a reading station for each user". However, time-sharing wasn't actually implemented until MIT's CTSS hit the scene in 1962. From there, many more systems started cropping up, leading to Multics, Unix, and eventually embedding itself into more modern systems.</span></p> <p> </p> <p><span style="font-weight: 400;">A system like time-sharing is impressive when you realize one thing: a computer can only even run one instruction at a time. Time-sharing just makes it</span> <em><span style="font-weight: 400;">look</span></em> <span style= "font-weight: 400;">like a computer can do two or more things at once. It accomplishes this by being able to pause, store the current program running and it's state, and then restoring the next program state to run. If you work much with modern operating systems, then this should sound familiar. Essentially, time-sharing is the same as multitasking today. Instead of switching between states, modern multitasking systems do "context swaps".</span></p> <p> </p> <p><span style="font-weight: 400;">One of the other changes as time-sharing evolved into a normal part of computer operation has to do with computers themselves. As multitasking became more and more important, processors started to support it as a feature in hardware. By the time you hit the 1990s, multitasking has become ubiquitous even in personal computers.</span></p>]]></description>
			<content:encoded><![CDATA[<p>If you've read much about the early spread of computer use, then you have probably heard the of "time-sharing systems". But what exactly is time-sharing, and what has it turned into in the modern day? To put it simply, time-sharing is one method that was used to allow multiple users to share a single computer. So, why was this idea a big deal?</p> <p> </p> <p>At the dawn of the computing era all systems were mainframes: prohibitively expensive machines the size of entire rooms. To use one of these computers you would have to load up your program on punch cards and go down to the computer department at your institution or business. Once there your stack of punch cards would be submitted to another person who would schedule out on a calendar when your program could run and when you could expect it's outputs. Not really a streamlined or very interactive process. This did change somewhat  as teletype terminals started to hit the scene, but this still just let one user on the system at a time.</p> <p> </p> <p>Time-sharing had been talked about as early as 1954 by Jack Backus at the MIT Summer Session. Backus posited that "by time sharing, a big computer could be used as several small ones; there would need to be a reading station for each user". However, time-sharing wasn't actually implemented until MIT's CTSS hit the scene in 1962. From there, many more systems started cropping up, leading to Multics, Unix, and eventually embedding itself into more modern systems.</p> <p> </p> <p>A system like time-sharing is impressive when you realize one thing: a computer can only even run one instruction at a time. Time-sharing just makes it <em>look</em> like a computer can do two or more things at once. It accomplishes this by being able to pause, store the current program running and it's state, and then restoring the next program state to run. If you work much with modern operating systems, then this should sound familiar. Essentially, time-sharing is the same as multitasking today. Instead of switching between states, modern multitasking systems do "context swaps".</p> <p> </p> <p>One of the other changes as time-sharing evolved into a normal part of computer operation has to do with computers themselves. As multitasking became more and more important, processors started to support it as a feature in hardware. By the time you hit the 1990s, multitasking has become ubiquitous even in personal computers.</p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[If you've read much about the early spread of computer use, then you have probably heard the of "time-sharing systems". But what exactly is time-sharing, and what has it turned into in the modern day? To put it simply, time-sharing is one method that...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 4 - Unix for the People, Part 1</title>
			<itunes:title>Unix for the People, Part 1</itunes:title>
			<pubDate>Mon, 20 May 2019 04:24:32 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[997b39637ebc4c428d715ae6e11271bb]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-4-unix-for-the-people-part-1]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p>Many people have never even heard of Unix, an operating system first released in the early 1970s. But that doesn't change the fact that all of the internet, and nearly every computer or smart device you interact with is based on some variant of Unix. So, how was such an important project created, and how did it revolutionize computing?</p> <p>Today we will dive into the story leading up to Unix: time-sharing computers in the 1960s. This is really just the background for part 2 where we will discuss the creation and rise of Unix itself. However, the history of early multi-user computers is itself deeply interesting and impactful on the evolution of computing.</p>]]></description>
			<content:encoded><![CDATA[<p>Many people have never even heard of Unix, an operating system first released in the early 1970s. But that doesn't change the fact that all of the internet, and nearly every computer or smart device you interact with is based on some variant of Unix. So, how was such an important project created, and how did it revolutionize computing?</p> <p>Today we will dive into the story leading up to Unix: time-sharing computers in the 1960s. This is really just the background for part 2 where we will discuss the creation and rise of Unix itself. However, the history of early multi-user computers is itself deeply interesting and impactful on the evolution of computing.</p>]]></content:encoded>
			<enclosure length="22583587" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep4_-_Unix_for_the_People_Part_1.amr" />
			<itunes:duration>23:32</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords>unix,ctss,multics</itunes:keywords>
			<itunes:subtitle><![CDATA[Many people have never even heard of Unix, an operating system first released in the early 1970s. But that doesn't change the fact that all of the internet, and nearly every computer or smart device you interact with is based on some variant of Unix....]]></itunes:subtitle>
			<itunes:episode>4</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 3 Notes - Myth of the Macintosh</title>
			<pubDate>Tue, 14 May 2019 02:22:35 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[61be7a0459e14250b1ce13e4d531fb6f]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/myth-of-the-macintosh]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The original Macintosh is undeniably iconic. A lot of people were introduced to computing through the machine, and it helped launch Apple as a company into the stratosphere. There are also a lot of myths that circulate around the Macintosh. The larger story that I run into most often is that Apple created the idea of a GUI. While I'd like to just dismiss these ideas wholesale, there is actually a complicated story underneath the surface.</span></p> <p> </p> <p><span style="font-weight: 400;">First off, the Mac wasn't the "original GUI system". In fact, it wasn't even Apple's first GUI. The Apple LISA came to market nearly a year before the Mac, and had a very similar GUI to the later Finder. (Low End Mac has a good write up on the LISA: </span><span style= "font-weight: 400;"><a href= "http://lowendmac.com/2005/history-of-apples-lisa/">http://lowendmac.com/2005/history-of-apples-lisa/</a>)</span></p> <p> </p> <p><span style="font-weight: 400;">Going deeper, there were systems before even the LISA that used a GUI. Xerox's Alto workstation was completed before the LISA, and both had remarkably modern looking interfaces: windows, icons, dropdown menus, and a mouse pointer all layered over a desktop.</span></p> <p><span style="font-weight: 400;">The final nail in the coffin of the idea that Apple created the desktop computing experience from scratch is this: in 1968 Doug Engelbart showcased the first GUI system. That software was called NLS. It may not look modern by any stretch, but it was the first system to use a mouse, as well as the first system to have fully realized hypertext(something that wouldn't come back in a big way until the internet age). And beyond all that, the first tech demo of NLS was recorded and is still archived today. (</span><span style="font-weight: 400;"><a href= "http://www.dougengelbart.org/content/view/209/448/">http://www.dougengelbart.org/content/view/209/448/</a>)</span></p> <p> </p> <p><span style="font-weight: 400;">That being said, Apple did bring new innovation to the table. The biggest new feature they created was the idea of a uniform user interface. Apple developed a uniform design language and a set of tools to enforce it's ideas. This let 3rd party programs on the Macintosh present the same style interface, which made computing much more accessible to every day users. In the current day we don't even think about the fact that each application we interact with uses the same set of menus, scroll bars, form elements, and fonts. But in the 1980s, that change helped bring many people who otherwise wouldn't be computer users into the fray. While Apple didn't invent the GUI, they did add an important piece to the puzzle.</span></p>]]></description>
			<content:encoded><![CDATA[<p>The original Macintosh is undeniably iconic. A lot of people were introduced to computing through the machine, and it helped launch Apple as a company into the stratosphere. There are also a lot of myths that circulate around the Macintosh. The larger story that I run into most often is that Apple created the idea of a GUI. While I'd like to just dismiss these ideas wholesale, there is actually a complicated story underneath the surface.</p> <p> </p> <p>First off, the Mac wasn't the "original GUI system". In fact, it wasn't even Apple's first GUI. The Apple LISA came to market nearly a year before the Mac, and had a very similar GUI to the later Finder. (Low End Mac has a good write up on the LISA: <a href= "http://lowendmac.com/2005/history-of-apples-lisa/">http://lowendmac.com/2005/history-of-apples-lisa/</a>)</p> <p> </p> <p>Going deeper, there were systems before even the LISA that used a GUI. Xerox's Alto workstation was completed before the LISA, and both had remarkably modern looking interfaces: windows, icons, dropdown menus, and a mouse pointer all layered over a desktop.</p> <p>The final nail in the coffin of the idea that Apple created the desktop computing experience from scratch is this: in 1968 Doug Engelbart showcased the first GUI system. That software was called NLS. It may not look modern by any stretch, but it was the first system to use a mouse, as well as the first system to have fully realized hypertext(something that wouldn't come back in a big way until the internet age). And beyond all that, the first tech demo of NLS was recorded and is still archived today. (<a href= "http://www.dougengelbart.org/content/view/209/448/">http://www.dougengelbart.org/content/view/209/448/</a>)</p> <p> </p> <p>That being said, Apple did bring new innovation to the table. The biggest new feature they created was the idea of a uniform user interface. Apple developed a uniform design language and a set of tools to enforce it's ideas. This let 3rd party programs on the Macintosh present the same style interface, which made computing much more accessible to every day users. In the current day we don't even think about the fact that each application we interact with uses the same set of menus, scroll bars, form elements, and fonts. But in the 1980s, that change helped bring many people who otherwise wouldn't be computer users into the fray. While Apple didn't invent the GUI, they did add an important piece to the puzzle.</p>]]></content:encoded>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The original Macintosh is undeniably iconic. A lot of people were introduced to computing through the machine, and it helped launch Apple as a company into the stratosphere. There are also a lot of myths that circulate around the Macintosh. The larger...]]></itunes:subtitle>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 3 - Mythic Macintosh</title>
			<itunes:title>Mythic Macintosh</itunes:title>
			<pubDate>Sun, 05 May 2019 23:48:21 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[3f6d8094650a4509902862b7ea15bb29]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-3-mythic-macintosh]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">The original Apple Macintosh, later rebranded the Macintosh 128k, is inarguably one of the most recognizable vintage computers. Even it's design has become iconic: a single 3 ½ inch floppy drive and 9 inch black-and-white CRT built into one small rounded beige box. Even on its release in 1984 it was heralded as a visionary and groundbreaking machine that could even rival the success of the IBM PC. Today, we are going to look at the enduring legacy of the Macintosh and answer the questions: what did Apple invent and what did they borrow, and are all interfaces that follow clones of the Macintosh.</span></p>]]></description>
			<content:encoded><![CDATA[<p>The original Apple Macintosh, later rebranded the Macintosh 128k, is inarguably one of the most recognizable vintage computers. Even it's design has become iconic: a single 3 ½ inch floppy drive and 9 inch black-and-white CRT built into one small rounded beige box. Even on its release in 1984 it was heralded as a visionary and groundbreaking machine that could even rival the success of the IBM PC. Today, we are going to look at the enduring legacy of the Macintosh and answer the questions: what did Apple invent and what did they borrow, and are all interfaces that follow clones of the Macintosh.</p>]]></content:encoded>
			<enclosure length="25615463" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep3_-_Mythic_Macintosh.amr" />
			<itunes:duration>26:41</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[The original Apple Macintosh, later rebranded the Macintosh 128k, is inarguably one of the most recognizable vintage computers. Even it's design has become iconic: a single 3 ½ inch floppy drive and 9 inch black-and-white CRT built into one small...]]></itunes:subtitle>
			<itunes:episode>3</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 2 - The Demo</title>
			<itunes:title>The Demo</itunes:title>
			<pubDate>Mon, 22 Apr 2019 03:50:11 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[3a1d7af237bb48bb985e795c21f56bc3]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/the-demo]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">A lot of newer technology doesn't expressly say it's going to "revolutionize the human experience", but sometimes, that line may actually be closer to the truth than you would expect. Today, I am going to tell you about a time when that was very much the case. Today we go back to 1968 to look at Doug Engelbart's "The Mother of all Demos"</span></p> <p>You can watch the entite archve of the demo here: <a href= "http://www.dougengelbart.org/content/view/209/448/">http://www.dougengelbart.org/content/view/209/448/</a></p>]]></description>
			<content:encoded><![CDATA[<p>A lot of newer technology doesn't expressly say it's going to "revolutionize the human experience", but sometimes, that line may actually be closer to the truth than you would expect. Today, I am going to tell you about a time when that was very much the case. Today we go back to 1968 to look at Doug Engelbart's "The Mother of all Demos"</p> <p>You can watch the entite archve of the demo here: <a href= "http://www.dougengelbart.org/content/view/209/448/">http://www.dougengelbart.org/content/view/209/448/</a></p>]]></content:encoded>
			<enclosure length="22115891" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep2_-_The_Demo.amr" />
			<itunes:duration>23:03</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[A lot of newer technology doesn't expressly say it's going to "revolutionize the human experience", but sometimes, that line may actually be closer to the truth than you would expect. Today, I am going to tell you about a time when that was very much...]]></itunes:subtitle>
			<itunes:episode>2</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
		<item>
			<title>Episode 1 - Folded Spindled and Mutilated</title>
			<itunes:title>Folded Spindled and Mutilated</itunes:title>
			<pubDate>Tue, 09 Apr 2019 19:00:00 +0000</pubDate>
			<guid isPermaLink="false"><![CDATA[7726ec1459e84777a6024fd89fc6ebb9]]></guid>
			<link><![CDATA[https://adventofcomputing.libsyn.com/episode-1-folded-spindled-and-mutilated-0]]></link>
			<itunes:image href="https://ssl-static.libsyn.com/p/assets/4/e/2/5/4e25bc8089f88907/logo5.png" />
			<description><![CDATA[<p><span style="font-weight: 400;">Today, I want to share with you a technology that shambles among us as a corpse that refuses to die. That is, of course, the punch card. In this episode, we will be talking about the storied history and influence from beyond the grave of the punch card.</span></p>]]></description>
			<content:encoded><![CDATA[<p>Today, I want to share with you a technology that shambles among us as a corpse that refuses to die. That is, of course, the punch card. In this episode, we will be talking about the storied history and influence from beyond the grave of the punch card.</p>]]></content:encoded>
			<enclosure length="25578790" type="audio/mpeg" url="https://adventofcomputing.com/flop-cast/audio/ep1_-_fold_spindle_and_mutilate.amr" />
			<itunes:duration>26:39</itunes:duration>
			<itunes:explicit>clean</itunes:explicit>
			<itunes:keywords />
			<itunes:subtitle><![CDATA[Today, I want to share with you a technology that shambles among us as a corpse that refuses to die. That is, of course, the punch card. In this episode, we will be talking about the storied history and influence from beyond the grave of the punch card.]]></itunes:subtitle>
			<itunes:episode>1</itunes:episode>
			<itunes:episodeType>full</itunes:episodeType>
		</item>
	</channel>
</rss>
